{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b386774a",
   "metadata": {},
   "source": [
    "Problem Statement¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c263035",
   "metadata": {},
   "source": [
    "Problem Statement¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4181681c",
   "metadata": {},
   "source": [
    "Problem Statement¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa240ec1",
   "metadata": {},
   "source": [
    "Problem Statement¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c6068b",
   "metadata": {},
   "source": [
    "Problem Statement¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a38b039",
   "metadata": {},
   "source": [
    "Business Context¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d7826",
   "metadata": {},
   "source": [
    "Business Context¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7544f257",
   "metadata": {},
   "source": [
    "Business Context¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073fee8",
   "metadata": {},
   "source": [
    "Business Context¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb758bf0",
   "metadata": {},
   "source": [
    "Business Context¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f17f5",
   "metadata": {},
   "source": [
    "Renewable energy sources play an increasingly important role in the global energy mix, as the effort to reduce the environmental impact of energy production increases.Out of all the renewable energy alternatives, wind energy is one of the most developed technologies worldwide. The U.S Department of Energy has put together a guide to achieving operational efficiency using predictive maintenance practices.Predictive maintenance uses sensor information and analysis methods to measure and predict degradation and future component capability. The idea behind predictive maintenance is that failure patterns are predictable and if component failure can be predicted accurately and the component is replaced before it fails, the costs of operation and maintenance will be much lower.The sensors fitted across different machines involved in the process of energy generation collect data related to various environmental factors (temperature, humidity, wind speed, etc.) and additional features related to various parts of the wind turbine (gearbox, tower, blades, break, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f4fa9",
   "metadata": {},
   "source": [
    "Renewable energy sources play an increasingly important role in the global energy mix, as the effort to reduce the environmental impact of energy production increases.Out of all the renewable energy alternatives, wind energy is one of the most developed technologies worldwide. The U.S Department of Energy has put together a guide to achieving operational efficiency using predictive maintenance practices.Predictive maintenance uses sensor information and analysis methods to measure and predict degradation and future component capability. The idea behind predictive maintenance is that failure patterns are predictable and if component failure can be predicted accurately and the component is replaced before it fails, the costs of operation and maintenance will be much lower.The sensors fitted across different machines involved in the process of energy generation collect data related to various environmental factors (temperature, humidity, wind speed, etc.) and additional features related to various parts of the wind turbine (gearbox, tower, blades, break, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434c5cf",
   "metadata": {},
   "source": [
    "Renewable energy sources play an increasingly important role in the global energy mix, as the effort to reduce the environmental impact of energy production increases.Out of all the renewable energy alternatives, wind energy is one of the most developed technologies worldwide. The U.S Department of Energy has put together a guide to achieving operational efficiency using predictive maintenance practices.Predictive maintenance uses sensor information and analysis methods to measure and predict degradation and future component capability. The idea behind predictive maintenance is that failure patterns are predictable and if component failure can be predicted accurately and the component is replaced before it fails, the costs of operation and maintenance will be much lower.The sensors fitted across different machines involved in the process of energy generation collect data related to various environmental factors (temperature, humidity, wind speed, etc.) and additional features related to various parts of the wind turbine (gearbox, tower, blades, break, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c52355",
   "metadata": {},
   "source": [
    "Renewable energy sources play an increasingly important role in the global energy mix, as the effort to reduce the environmental impact of energy production increases.Out of all the renewable energy alternatives, wind energy is one of the most developed technologies worldwide. The U.S Department of Energy has put together a guide to achieving operational efficiency using predictive maintenance practices.Predictive maintenance uses sensor information and analysis methods to measure and predict degradation and future component capability. The idea behind predictive maintenance is that failure patterns are predictable and if component failure can be predicted accurately and the component is replaced before it fails, the costs of operation and maintenance will be much lower.The sensors fitted across different machines involved in the process of energy generation collect data related to various environmental factors (temperature, humidity, wind speed, etc.) and additional features related to various parts of the wind turbine (gearbox, tower, blades, break, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db53dc",
   "metadata": {},
   "source": [
    "Renewable energy sources play an increasingly important role in the global energy mix, as the effort to reduce the environmental impact of energy production increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05815d0b",
   "metadata": {},
   "source": [
    "Out of all the renewable energy alternatives, wind energy is one of the most developed technologies worldwide. The U.S Department of Energy has put together a guide to achieving operational efficiency using predictive maintenance practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f403dbb",
   "metadata": {},
   "source": [
    "Predictive maintenance uses sensor information and analysis methods to measure and predict degradation and future component capability. The idea behind predictive maintenance is that failure patterns are predictable and if component failure can be predicted accurately and the component is replaced before it fails, the costs of operation and maintenance will be much lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2ac75",
   "metadata": {},
   "source": [
    "The sensors fitted across different machines involved in the process of energy generation collect data related to various environmental factors (temperature, humidity, wind speed, etc.) and additional features related to various parts of the wind turbine (gearbox, tower, blades, break, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deec91c",
   "metadata": {},
   "source": [
    "Objective¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f782f",
   "metadata": {},
   "source": [
    "Objective¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2ecff",
   "metadata": {},
   "source": [
    "Objective¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3177d",
   "metadata": {},
   "source": [
    "Objective¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f748b2",
   "metadata": {},
   "source": [
    "Objective¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ec194e",
   "metadata": {},
   "source": [
    "“ReneWind” is a company working on improving the machinery/processes involved in the production of wind energy using machine learning and has collected data of generator failure of wind turbines using sensors. They have shared a ciphered version of the data, as the data collected through sensors is confidential (the type of data collected varies with companies). Data has 40 predictors, 20000 observations in the training set and 5000 in the test set.The objective is to build various classification models, tune them, and find the best one that will help identify failures so that the generators could be repaired before failing/breaking to reduce the overall maintenance cost.\n",
    "The nature of predictions made by the classification model will translate as follows:True positives (TP) are failures correctly predicted by the model. These will result in repairing costs.False negatives (FN) are real failures where there is no detection by the model. These will result in replacement costs.False positives (FP) are detections where there is no failure. These will result in inspection costs.It is given that the cost of repairing a generator is much less than the cost of replacing it, and the cost of inspection is less than the cost of repair.“1” in the target variables should be considered as “failure” and “0” represents “No failure”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a773f5",
   "metadata": {},
   "source": [
    "“ReneWind” is a company working on improving the machinery/processes involved in the production of wind energy using machine learning and has collected data of generator failure of wind turbines using sensors. They have shared a ciphered version of the data, as the data collected through sensors is confidential (the type of data collected varies with companies). Data has 40 predictors, 20000 observations in the training set and 5000 in the test set.The objective is to build various classification models, tune them, and find the best one that will help identify failures so that the generators could be repaired before failing/breaking to reduce the overall maintenance cost.\n",
    "The nature of predictions made by the classification model will translate as follows:True positives (TP) are failures correctly predicted by the model. These will result in repairing costs.False negatives (FN) are real failures where there is no detection by the model. These will result in replacement costs.False positives (FP) are detections where there is no failure. These will result in inspection costs.It is given that the cost of repairing a generator is much less than the cost of replacing it, and the cost of inspection is less than the cost of repair.“1” in the target variables should be considered as “failure” and “0” represents “No failure”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5f3af",
   "metadata": {},
   "source": [
    "“ReneWind” is a company working on improving the machinery/processes involved in the production of wind energy using machine learning and has collected data of generator failure of wind turbines using sensors. They have shared a ciphered version of the data, as the data collected through sensors is confidential (the type of data collected varies with companies). Data has 40 predictors, 20000 observations in the training set and 5000 in the test set.The objective is to build various classification models, tune them, and find the best one that will help identify failures so that the generators could be repaired before failing/breaking to reduce the overall maintenance cost.\n",
    "The nature of predictions made by the classification model will translate as follows:True positives (TP) are failures correctly predicted by the model. These will result in repairing costs.False negatives (FN) are real failures where there is no detection by the model. These will result in replacement costs.False positives (FP) are detections where there is no failure. These will result in inspection costs.It is given that the cost of repairing a generator is much less than the cost of replacing it, and the cost of inspection is less than the cost of repair.“1” in the target variables should be considered as “failure” and “0” represents “No failure”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea598c28",
   "metadata": {},
   "source": [
    "“ReneWind” is a company working on improving the machinery/processes involved in the production of wind energy using machine learning and has collected data of generator failure of wind turbines using sensors. They have shared a ciphered version of the data, as the data collected through sensors is confidential (the type of data collected varies with companies). Data has 40 predictors, 20000 observations in the training set and 5000 in the test set.The objective is to build various classification models, tune them, and find the best one that will help identify failures so that the generators could be repaired before failing/breaking to reduce the overall maintenance cost.\n",
    "The nature of predictions made by the classification model will translate as follows:True positives (TP) are failures correctly predicted by the model. These will result in repairing costs.False negatives (FN) are real failures where there is no detection by the model. These will result in replacement costs.False positives (FP) are detections where there is no failure. These will result in inspection costs.It is given that the cost of repairing a generator is much less than the cost of replacing it, and the cost of inspection is less than the cost of repair.“1” in the target variables should be considered as “failure” and “0” represents “No failure”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3176d7",
   "metadata": {},
   "source": [
    "“ReneWind” is a company working on improving the machinery/processes involved in the production of wind energy using machine learning and has collected data of generator failure of wind turbines using sensors. They have shared a ciphered version of the data, as the data collected through sensors is confidential (the type of data collected varies with companies). Data has 40 predictors, 20000 observations in the training set and 5000 in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b93189",
   "metadata": {},
   "source": [
    "The objective is to build various classification models, tune them, and find the best one that will help identify failures so that the generators could be repaired before failing/breaking to reduce the overall maintenance cost.\n",
    "The nature of predictions made by the classification model will translate as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4de2d1",
   "metadata": {},
   "source": [
    "True positives (TP) are failures correctly predicted by the model. These will result in repairing costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67436b5",
   "metadata": {},
   "source": [
    "False negatives (FN) are real failures where there is no detection by the model. These will result in replacement costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6e51e",
   "metadata": {},
   "source": [
    "False positives (FP) are detections where there is no failure. These will result in inspection costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2737e892",
   "metadata": {},
   "source": [
    "It is given that the cost of repairing a generator is much less than the cost of replacing it, and the cost of inspection is less than the cost of repair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b68a1",
   "metadata": {},
   "source": [
    "“1” in the target variables should be considered as “failure” and “0” represents “No failure”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618ec00",
   "metadata": {},
   "source": [
    "Data Description¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f9905",
   "metadata": {},
   "source": [
    "Data Description¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2c379",
   "metadata": {},
   "source": [
    "Data Description¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb00b72",
   "metadata": {},
   "source": [
    "Data Description¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f20a1",
   "metadata": {},
   "source": [
    "Data Description¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79abde0a",
   "metadata": {},
   "source": [
    "The data provided is a transformed version of the original data which was collected using sensors.Train.csv - To be used for training and tuning of models.Test.csv - To be used only for testing the performance of the final best model.Both the datasets consist of 40 predictor variables and 1 target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5c389",
   "metadata": {},
   "source": [
    "The data provided is a transformed version of the original data which was collected using sensors.Train.csv - To be used for training and tuning of models.Test.csv - To be used only for testing the performance of the final best model.Both the datasets consist of 40 predictor variables and 1 target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f99eb",
   "metadata": {},
   "source": [
    "The data provided is a transformed version of the original data which was collected using sensors.Train.csv - To be used for training and tuning of models.Test.csv - To be used only for testing the performance of the final best model.Both the datasets consist of 40 predictor variables and 1 target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691bd87c",
   "metadata": {},
   "source": [
    "The data provided is a transformed version of the original data which was collected using sensors.Train.csv - To be used for training and tuning of models.Test.csv - To be used only for testing the performance of the final best model.Both the datasets consist of 40 predictor variables and 1 target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c49bf",
   "metadata": {},
   "source": [
    "The data provided is a transformed version of the original data which was collected using sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77cce26",
   "metadata": {},
   "source": [
    "Train.csv - To be used for training and tuning of models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770983a",
   "metadata": {},
   "source": [
    "Test.csv - To be used only for testing the performance of the final best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c21800",
   "metadata": {},
   "source": [
    "Both the datasets consist of 40 predictor variables and 1 target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc4f75",
   "metadata": {},
   "source": [
    "Installing and Importing the necessary libraries¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ca1d1",
   "metadata": {},
   "source": [
    "Installing and Importing the necessary libraries¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f2526",
   "metadata": {},
   "source": [
    "Installing and Importing the necessary libraries¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0e459",
   "metadata": {},
   "source": [
    "Installing and Importing the necessary libraries¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce1212b",
   "metadata": {},
   "source": [
    "Installing and Importing the necessary libraries¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ef442",
   "metadata": {},
   "source": [
    "In [1]:# Installing the libraries with the specified version!pipinstall--no-depstensorflow==2.18.0scikit-learn==1.3.2matplotlib===3.8.3seaborn==0.13.2numpy==1.26.4pandas==2.2.2-q--user--no-warn-script-location━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━61.0/61.0 kB3.0 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━10.9/10.9 MB53.4 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━11.6/11.6 MB70.4 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━18.3/18.3 MB67.4 MB/seta0:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c28402",
   "metadata": {},
   "source": [
    "In [1]:# Installing the libraries with the specified version!pipinstall--no-depstensorflow==2.18.0scikit-learn==1.3.2matplotlib===3.8.3seaborn==0.13.2numpy==1.26.4pandas==2.2.2-q--user--no-warn-script-location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2398c4",
   "metadata": {},
   "source": [
    "In [1]:# Installing the libraries with the specified version!pipinstall--no-depstensorflow==2.18.0scikit-learn==1.3.2matplotlib===3.8.3seaborn==0.13.2numpy==1.26.4pandas==2.2.2-q--user--no-warn-script-location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc2889",
   "metadata": {},
   "source": [
    "In [1]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1415b57d",
   "metadata": {},
   "source": [
    "# Installing the libraries with the specified version!pipinstall--no-depstensorflow==2.18.0scikit-learn==1.3.2matplotlib===3.8.3seaborn==0.13.2numpy==1.26.4pandas==2.2.2-q--user--no-warn-script-location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ea6da",
   "metadata": {},
   "source": [
    "# Installing the libraries with the specified version!pipinstall--no-depstensorflow==2.18.0scikit-learn==1.3.2matplotlib===3.8.3seaborn==0.13.2numpy==1.26.4pandas==2.2.2-q--user--no-warn-script-location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a13444",
   "metadata": {},
   "source": [
    "# Installing the libraries with the specified version!pipinstall--no-depstensorflow==2.18.0scikit-learn==1.3.2matplotlib===3.8.3seaborn==0.13.2numpy==1.26.4pandas==2.2.2-q--user--no-warn-script-location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b57f3b0",
   "metadata": {},
   "source": [
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━61.0/61.0 kB3.0 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━10.9/10.9 MB53.4 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━11.6/11.6 MB70.4 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━18.3/18.3 MB67.4 MB/seta0:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2725f",
   "metadata": {},
   "source": [
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━61.0/61.0 kB3.0 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━10.9/10.9 MB53.4 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━11.6/11.6 MB70.4 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━18.3/18.3 MB67.4 MB/seta0:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e40c7c",
   "metadata": {},
   "source": [
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━61.0/61.0 kB3.0 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━10.9/10.9 MB53.4 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━11.6/11.6 MB70.4 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━18.3/18.3 MB67.4 MB/seta0:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8b0b8",
   "metadata": {},
   "source": [
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━61.0/61.0 kB3.0 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━10.9/10.9 MB53.4 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━11.6/11.6 MB70.4 MB/seta0:00:00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━18.3/18.3 MB67.4 MB/seta0:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4195d",
   "metadata": {},
   "source": [
    "Note:After running the above cell, kindly restart the runtime (for Google Colab) or notebook kernel (for Jupyter Notebook), and run all cells sequentially from the next cell.On executing the above line of code, you might see a warning regarding package dependencies. This error message can be ignored as the above code ensures that all necessary libraries and their dependencies are maintained to successfully execute the code inthis notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f90cfd",
   "metadata": {},
   "source": [
    "Note:After running the above cell, kindly restart the runtime (for Google Colab) or notebook kernel (for Jupyter Notebook), and run all cells sequentially from the next cell.On executing the above line of code, you might see a warning regarding package dependencies. This error message can be ignored as the above code ensures that all necessary libraries and their dependencies are maintained to successfully execute the code inthis notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b498b30",
   "metadata": {},
   "source": [
    "Note:After running the above cell, kindly restart the runtime (for Google Colab) or notebook kernel (for Jupyter Notebook), and run all cells sequentially from the next cell.On executing the above line of code, you might see a warning regarding package dependencies. This error message can be ignored as the above code ensures that all necessary libraries and their dependencies are maintained to successfully execute the code inthis notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de38e2",
   "metadata": {},
   "source": [
    "Note:After running the above cell, kindly restart the runtime (for Google Colab) or notebook kernel (for Jupyter Notebook), and run all cells sequentially from the next cell.On executing the above line of code, you might see a warning regarding package dependencies. This error message can be ignored as the above code ensures that all necessary libraries and their dependencies are maintained to successfully execute the code inthis notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c09e006",
   "metadata": {},
   "source": [
    "Note:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fd228d",
   "metadata": {},
   "source": [
    "After running the above cell, kindly restart the runtime (for Google Colab) or notebook kernel (for Jupyter Notebook), and run all cells sequentially from the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf00c1",
   "metadata": {},
   "source": [
    "On executing the above line of code, you might see a warning regarding package dependencies. This error message can be ignored as the above code ensures that all necessary libraries and their dependencies are maintained to successfully execute the code inthis notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e469850e",
   "metadata": {},
   "source": [
    "Loading the Data¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e6585",
   "metadata": {},
   "source": [
    "Loading the Data¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db4315",
   "metadata": {},
   "source": [
    "Loading the Data¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70b291c",
   "metadata": {},
   "source": [
    "Loading the Data¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc95df",
   "metadata": {},
   "source": [
    "Loading the Data¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019622c4",
   "metadata": {},
   "source": [
    "In [2]:# uncomment and run the following lines for Google Colabfromgoogle.colabimportdrivedrive.mount('/content/drive')Mounted at /content/drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786ce2c",
   "metadata": {},
   "source": [
    "In [2]:# uncomment and run the following lines for Google Colabfromgoogle.colabimportdrivedrive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212a27b",
   "metadata": {},
   "source": [
    "In [2]:# uncomment and run the following lines for Google Colabfromgoogle.colabimportdrivedrive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b6176",
   "metadata": {},
   "source": [
    "In [2]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2da2dd",
   "metadata": {},
   "source": [
    "# uncomment and run the following lines for Google Colabfromgoogle.colabimportdrivedrive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1483150",
   "metadata": {},
   "source": [
    "# uncomment and run the following lines for Google Colabfromgoogle.colabimportdrivedrive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b450a8c",
   "metadata": {},
   "source": [
    "# uncomment and run the following lines for Google Colabfromgoogle.colabimportdrivedrive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51204b3",
   "metadata": {},
   "source": [
    "Mounted at /content/drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7ecfe",
   "metadata": {},
   "source": [
    "Mounted at /content/drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb13df",
   "metadata": {},
   "source": [
    "Mounted at /content/drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef06e34",
   "metadata": {},
   "source": [
    "Mounted at /content/drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b32fec",
   "metadata": {},
   "source": [
    "Imports all necessary libraries for data manipulation (Pandas, NumPy), visualization (Matplotlib, Seaborn),\n",
    "machine learning (Scikit-learn), and deep learning (TensorFlow/Keras). Also suppresses warnings for cleaner output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed1150",
   "metadata": {},
   "source": [
    "Imports all necessary libraries for data manipulation (Pandas, NumPy), visualization (Matplotlib, Seaborn),\n",
    "machine learning (Scikit-learn), and deep learning (TensorFlow/Keras). Also suppresses warnings for cleaner output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b2927",
   "metadata": {},
   "source": [
    "Imports all necessary libraries for data manipulation (Pandas, NumPy), visualization (Matplotlib, Seaborn),\n",
    "machine learning (Scikit-learn), and deep learning (TensorFlow/Keras). Also suppresses warnings for cleaner output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6a7e6",
   "metadata": {},
   "source": [
    "Imports all necessary libraries for data manipulation (Pandas, NumPy), visualization (Matplotlib, Seaborn),\n",
    "machine learning (Scikit-learn), and deep learning (TensorFlow/Keras). Also suppresses warnings for cleaner output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a303ab",
   "metadata": {},
   "source": [
    "Imports all necessary libraries for data manipulation (Pandas, NumPy), visualization (Matplotlib, Seaborn),\n",
    "machine learning (Scikit-learn), and deep learning (TensorFlow/Keras). Also suppresses warnings for cleaner output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bfe537",
   "metadata": {},
   "source": [
    "In [14]:# Library for data manipulation and analysis.importpandasaspd# Fundamental package for scientific computing.importnumpyasnp#splitting datasets into training and testing sets.fromsklearn.model_selectionimporttrain_test_split#Imports tools for data preprocessing including label encoding, one-hot encoding, and standard scalingfromsklearn.preprocessingimportLabelEncoder,OneHotEncoder,StandardScaler#Imports a class for imputing missing values in datasets.fromsklearn.imputeimportSimpleImputer#Imports the Matplotlib library for creating visualizations.fromsklearn.metricsimportconfusion_matriximportmatplotlib.pyplotasplt# Imports the Seaborn library for statistical data visualization.importseabornassns# Time related functions.importtime#Imports functions for evaluating the performance of machine learning modelsfromsklearn.metricsimportconfusion_matrix,f1_score,accuracy_score,recall_score,precision_score,classification_report#Imports metrics fromfromsklearnimportmetrics#Imports the tensorflow,keras and layers.importtensorflowimporttensorflowastffromtensorflow.keras.modelsimportSequentialfromtensorflow.keras.layersimportDensefromtensorflow.keras.layersimportDense,Input,Dropout,BatchNormalizationfromtensorflow.kerasimportbackend# to suppress unnecessary warningsimportwarningswarnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14825dff",
   "metadata": {},
   "source": [
    "In [14]:# Library for data manipulation and analysis.importpandasaspd# Fundamental package for scientific computing.importnumpyasnp#splitting datasets into training and testing sets.fromsklearn.model_selectionimporttrain_test_split#Imports tools for data preprocessing including label encoding, one-hot encoding, and standard scalingfromsklearn.preprocessingimportLabelEncoder,OneHotEncoder,StandardScaler#Imports a class for imputing missing values in datasets.fromsklearn.imputeimportSimpleImputer#Imports the Matplotlib library for creating visualizations.fromsklearn.metricsimportconfusion_matriximportmatplotlib.pyplotasplt# Imports the Seaborn library for statistical data visualization.importseabornassns# Time related functions.importtime#Imports functions for evaluating the performance of machine learning modelsfromsklearn.metricsimportconfusion_matrix,f1_score,accuracy_score,recall_score,precision_score,classification_report#Imports metrics fromfromsklearnimportmetrics#Imports the tensorflow,keras and layers.importtensorflowimporttensorflowastffromtensorflow.keras.modelsimportSequentialfromtensorflow.keras.layersimportDensefromtensorflow.keras.layersimportDense,Input,Dropout,BatchNormalizationfromtensorflow.kerasimportbackend# to suppress unnecessary warningsimportwarningswarnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba651267",
   "metadata": {},
   "source": [
    "In [14]:# Library for data manipulation and analysis.importpandasaspd# Fundamental package for scientific computing.importnumpyasnp#splitting datasets into training and testing sets.fromsklearn.model_selectionimporttrain_test_split#Imports tools for data preprocessing including label encoding, one-hot encoding, and standard scalingfromsklearn.preprocessingimportLabelEncoder,OneHotEncoder,StandardScaler#Imports a class for imputing missing values in datasets.fromsklearn.imputeimportSimpleImputer#Imports the Matplotlib library for creating visualizations.fromsklearn.metricsimportconfusion_matriximportmatplotlib.pyplotasplt# Imports the Seaborn library for statistical data visualization.importseabornassns# Time related functions.importtime#Imports functions for evaluating the performance of machine learning modelsfromsklearn.metricsimportconfusion_matrix,f1_score,accuracy_score,recall_score,precision_score,classification_report#Imports metrics fromfromsklearnimportmetrics#Imports the tensorflow,keras and layers.importtensorflowimporttensorflowastffromtensorflow.keras.modelsimportSequentialfromtensorflow.keras.layersimportDensefromtensorflow.keras.layersimportDense,Input,Dropout,BatchNormalizationfromtensorflow.kerasimportbackend# to suppress unnecessary warningsimportwarningswarnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d87b5d",
   "metadata": {},
   "source": [
    "In [14]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd825c",
   "metadata": {},
   "source": [
    "# Library for data manipulation and analysis.importpandasaspd# Fundamental package for scientific computing.importnumpyasnp#splitting datasets into training and testing sets.fromsklearn.model_selectionimporttrain_test_split#Imports tools for data preprocessing including label encoding, one-hot encoding, and standard scalingfromsklearn.preprocessingimportLabelEncoder,OneHotEncoder,StandardScaler#Imports a class for imputing missing values in datasets.fromsklearn.imputeimportSimpleImputer#Imports the Matplotlib library for creating visualizations.fromsklearn.metricsimportconfusion_matriximportmatplotlib.pyplotasplt# Imports the Seaborn library for statistical data visualization.importseabornassns# Time related functions.importtime#Imports functions for evaluating the performance of machine learning modelsfromsklearn.metricsimportconfusion_matrix,f1_score,accuracy_score,recall_score,precision_score,classification_report#Imports metrics fromfromsklearnimportmetrics#Imports the tensorflow,keras and layers.importtensorflowimporttensorflowastffromtensorflow.keras.modelsimportSequentialfromtensorflow.keras.layersimportDensefromtensorflow.keras.layersimportDense,Input,Dropout,BatchNormalizationfromtensorflow.kerasimportbackend# to suppress unnecessary warningsimportwarningswarnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d7e95",
   "metadata": {},
   "source": [
    "# Library for data manipulation and analysis.importpandasaspd# Fundamental package for scientific computing.importnumpyasnp#splitting datasets into training and testing sets.fromsklearn.model_selectionimporttrain_test_split#Imports tools for data preprocessing including label encoding, one-hot encoding, and standard scalingfromsklearn.preprocessingimportLabelEncoder,OneHotEncoder,StandardScaler#Imports a class for imputing missing values in datasets.fromsklearn.imputeimportSimpleImputer#Imports the Matplotlib library for creating visualizations.fromsklearn.metricsimportconfusion_matriximportmatplotlib.pyplotasplt# Imports the Seaborn library for statistical data visualization.importseabornassns# Time related functions.importtime#Imports functions for evaluating the performance of machine learning modelsfromsklearn.metricsimportconfusion_matrix,f1_score,accuracy_score,recall_score,precision_score,classification_report#Imports metrics fromfromsklearnimportmetrics#Imports the tensorflow,keras and layers.importtensorflowimporttensorflowastffromtensorflow.keras.modelsimportSequentialfromtensorflow.keras.layersimportDensefromtensorflow.keras.layersimportDense,Input,Dropout,BatchNormalizationfromtensorflow.kerasimportbackend# to suppress unnecessary warningsimportwarningswarnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9e3d7",
   "metadata": {},
   "source": [
    "# Library for data manipulation and analysis.importpandasaspd# Fundamental package for scientific computing.importnumpyasnp#splitting datasets into training and testing sets.fromsklearn.model_selectionimporttrain_test_split#Imports tools for data preprocessing including label encoding, one-hot encoding, and standard scalingfromsklearn.preprocessingimportLabelEncoder,OneHotEncoder,StandardScaler#Imports a class for imputing missing values in datasets.fromsklearn.imputeimportSimpleImputer#Imports the Matplotlib library for creating visualizations.fromsklearn.metricsimportconfusion_matriximportmatplotlib.pyplotasplt# Imports the Seaborn library for statistical data visualization.importseabornassns# Time related functions.importtime#Imports functions for evaluating the performance of machine learning modelsfromsklearn.metricsimportconfusion_matrix,f1_score,accuracy_score,recall_score,precision_score,classification_report#Imports metrics fromfromsklearnimportmetrics#Imports the tensorflow,keras and layers.importtensorflowimporttensorflowastffromtensorflow.keras.modelsimportSequentialfromtensorflow.keras.layersimportDensefromtensorflow.keras.layersimportDense,Input,Dropout,BatchNormalizationfromtensorflow.kerasimportbackend# to suppress unnecessary warningsimportwarningswarnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48afbf48",
   "metadata": {},
   "source": [
    "Data Overview¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc860b",
   "metadata": {},
   "source": [
    "Data Overview¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7be9c3",
   "metadata": {},
   "source": [
    "Data Overview¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9bdeb",
   "metadata": {},
   "source": [
    "Data Overview¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4125653",
   "metadata": {},
   "source": [
    "Data Overview¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f766d84",
   "metadata": {},
   "source": [
    "Loads the training data into a Pandas DataFrame usingpd.read_csv. This is the first step in data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eacbcf8",
   "metadata": {},
   "source": [
    "Loads the training data into a Pandas DataFrame usingpd.read_csv. This is the first step in data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd46cb92",
   "metadata": {},
   "source": [
    "Loads the training data into a Pandas DataFrame usingpd.read_csv. This is the first step in data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7faa3ce",
   "metadata": {},
   "source": [
    "Loads the training data into a Pandas DataFrame usingpd.read_csv. This is the first step in data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16386ea3",
   "metadata": {},
   "source": [
    "Loads the training data into a Pandas DataFrame usingpd.read_csv. This is the first step in data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9482b",
   "metadata": {},
   "source": [
    "In [6]:# Loading the datatrain_data=pd.read_csv('Train.csv')test_data=pd.read_csv('Test.csv')print(\"Training data shape:\",train_data.shape)print(\"Test data shape:\",test_data.shape)print(\"\\nTraining data columns:\",train_data.columns.tolist())print(\"\\nFirst few rows of training data:\")print(train_data.head())print(\"\\nData types:\")print(train_data.dtypes)print(\"\\nMissing values in training data:\")print(train_data.isnull().sum().sum())print(\"\\nTarget variable distribution:\")print(train_data['Target'].value_counts())print(train_data['Target'].value_counts(normalize=True))# Convert Target to float for consistencytrain_data['Target']=train_data['Target'].astype(float)test_data['Target']=test_data['Target'].astype(float)# Check for duplicatesprint(\"\\nDuplicate rows in training data:\",train_data.duplicated().sum())print(\"Duplicate rows in test data:\",test_data.duplicated().sum())# Statistical summaryprint(\"\\nStatistical summary of training data:\")print(train_data.describe())Training data shape: (20000, 41)\n",
    "Test data shape: (5000, 41)\n",
    "\n",
    "Training data columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'Target']\n",
    "\n",
    "First few rows of training data:\n",
    "         V1        V2        V3        V4        V5        V6        V7  \\\n",
    "0 -4.464606 -4.679129  3.101546  0.506130 -0.221083 -2.032511 -2.910870   \n",
    "1  3.365912  3.653381  0.909671 -1.367528  0.332016  2.358938  0.732600   \n",
    "2 -3.831843 -5.824444  0.634031 -2.418815 -1.773827  1.016824 -2.098941   \n",
    "3  1.618098  1.888342  7.046143 -1.147285  0.083080 -1.529780  0.207309   \n",
    "4 -0.111440  3.872488 -3.758361 -2.982897  3.792714  0.544960  0.205433   \n",
    "\n",
    "         V8        V9       V10  ...       V32       V33        V34       V35  \\\n",
    "0  0.050714 -1.522351  3.761892  ...  3.059700 -1.690440   2.846296  2.235198   \n",
    "1 -4.332135  0.565695 -0.101080  ... -1.795474  3.032780  -2.467514  1.894599   \n",
    "2 -3.173204 -2.081860  5.392621  ... -0.257101  0.803550   4.086219  2.292138   \n",
    "3 -2.493629  0.344926  2.118578  ... -3.584425 -2.577474   1.363769  0.622714   \n",
    "4  4.848994 -1.854920 -6.220023  ...  8.265896  6.629213 -10.068689  1.222987   \n",
    "\n",
    "        V36       V37       V38       V39       V40  Target  \n",
    "0  6.667486  0.443809 -2.369169  2.950578 -3.480324       0  \n",
    "1 -2.297780 -1.731048  5.908837 -0.386345  0.616242       0  \n",
    "2  5.360850  0.351993  2.940021  3.839160 -4.309402       0  \n",
    "3  5.550100 -1.526796  0.138853  3.101430 -1.277378       0  \n",
    "4 -3.229763  1.686909 -2.163896 -3.644622  6.510338       0  \n",
    "\n",
    "[5 rows x 41 columns]\n",
    "\n",
    "Data types:\n",
    "V1        float64\n",
    "V2        float64\n",
    "V3        float64\n",
    "V4        float64\n",
    "V5        float64\n",
    "V6        float64\n",
    "V7        float64\n",
    "V8        float64\n",
    "V9        float64\n",
    "V10       float64\n",
    "V11       float64\n",
    "V12       float64\n",
    "V13       float64\n",
    "V14       float64\n",
    "V15       float64\n",
    "V16       float64\n",
    "V17       float64\n",
    "V18       float64\n",
    "V19       float64\n",
    "V20       float64\n",
    "V21       float64\n",
    "V22       float64\n",
    "V23       float64\n",
    "V24       float64\n",
    "V25       float64\n",
    "V26       float64\n",
    "V27       float64\n",
    "V28       float64\n",
    "V29       float64\n",
    "V30       float64\n",
    "V31       float64\n",
    "V32       float64\n",
    "V33       float64\n",
    "V34       float64\n",
    "V35       float64\n",
    "V36       float64\n",
    "V37       float64\n",
    "V38       float64\n",
    "V39       float64\n",
    "V40       float64\n",
    "Target      int64\n",
    "dtype: object\n",
    "\n",
    "Missing values in training data:\n",
    "36\n",
    "\n",
    "Target variable distribution:\n",
    "Target\n",
    "0    18890\n",
    "1     1110\n",
    "Name: count, dtype: int64\n",
    "Target\n",
    "0    0.9445\n",
    "1    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Duplicate rows in training data: 0\n",
    "Duplicate rows in test data: 0\n",
    "\n",
    "Statistical summary of training data:\n",
    "                 V1            V2            V3            V4            V5  \\\n",
    "count  19982.000000  19982.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean      -0.271996      0.440430      2.484699     -0.083152     -0.053752   \n",
    "std        3.441625      3.150784      3.388963      3.431595      2.104801   \n",
    "min      -11.876451    -12.319951    -10.708139    -15.082052     -8.603361   \n",
    "25%       -2.737146     -1.640674      0.206860     -2.347660     -1.535607   \n",
    "50%       -0.747917      0.471536      2.255786     -0.135241     -0.101952   \n",
    "75%        1.840112      2.543967      4.566165      2.130615      1.340480   \n",
    "max       15.493002     13.089269     17.090919     13.236381      8.133797   \n",
    "\n",
    "                 V6            V7            V8            V9           V10  \\\n",
    "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean      -0.995443     -0.879325     -0.548195     -0.016808     -0.012998   \n",
    "std        2.040970      1.761626      3.295756      2.160568      2.193201   \n",
    "min      -10.227147     -7.949681    -15.657561     -8.596313     -9.853957   \n",
    "25%       -2.347238     -2.030926     -2.642665     -1.494973     -1.411212   \n",
    "50%       -1.000515     -0.917179     -0.389085     -0.067597      0.100973   \n",
    "75%        0.380330      0.223695      1.722965      1.409203      1.477045   \n",
    "max        6.975847      8.006091     11.679495      8.137580      8.108472   \n",
    "\n",
    "       ...           V32           V33           V34           V35  \\\n",
    "count  ...  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean   ...      0.303799      0.049825     -0.462702      2.229620   \n",
    "std    ...      5.500400      3.575285      3.183841      2.937102   \n",
    "min    ...    -19.876502    -16.898353    -17.985094    -15.349803   \n",
    "25%    ...     -3.420469     -2.242857     -2.136984      0.336191   \n",
    "50%    ...      0.052073     -0.066249     -0.255008      2.098633   \n",
    "75%    ...      3.761722      2.255134      1.436935      4.064358   \n",
    "max    ...     23.633187     16.692486     14.358213     15.291065   \n",
    "\n",
    "                V36           V37           V38           V39           V40  \\\n",
    "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean       1.514809      0.011316     -0.344025      0.890653     -0.875630   \n",
    "std        3.800860      1.788165      3.948147      1.753054      3.012155   \n",
    "min      -14.833178     -5.478350    -17.375002     -6.438880    -11.023935   \n",
    "25%       -0.943809     -1.255819     -2.987638     -0.272250     -2.940193   \n",
    "50%        1.566526     -0.128435     -0.316849      0.919261     -0.920806   \n",
    "75%        3.983939      1.175533      2.279399      2.057540      1.119897   \n",
    "max       19.329576      7.467006     15.289923      7.759877     10.654265   \n",
    "\n",
    "             Target  \n",
    "count  20000.000000  \n",
    "mean       0.055500  \n",
    "std        0.228959  \n",
    "min        0.000000  \n",
    "25%        0.000000  \n",
    "50%        0.000000  \n",
    "75%        0.000000  \n",
    "max        1.000000  \n",
    "\n",
    "[8 rows x 41 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761687e2",
   "metadata": {},
   "source": [
    "In [6]:# Loading the datatrain_data=pd.read_csv('Train.csv')test_data=pd.read_csv('Test.csv')print(\"Training data shape:\",train_data.shape)print(\"Test data shape:\",test_data.shape)print(\"\\nTraining data columns:\",train_data.columns.tolist())print(\"\\nFirst few rows of training data:\")print(train_data.head())print(\"\\nData types:\")print(train_data.dtypes)print(\"\\nMissing values in training data:\")print(train_data.isnull().sum().sum())print(\"\\nTarget variable distribution:\")print(train_data['Target'].value_counts())print(train_data['Target'].value_counts(normalize=True))# Convert Target to float for consistencytrain_data['Target']=train_data['Target'].astype(float)test_data['Target']=test_data['Target'].astype(float)# Check for duplicatesprint(\"\\nDuplicate rows in training data:\",train_data.duplicated().sum())print(\"Duplicate rows in test data:\",test_data.duplicated().sum())# Statistical summaryprint(\"\\nStatistical summary of training data:\")print(train_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98834760",
   "metadata": {},
   "source": [
    "In [6]:# Loading the datatrain_data=pd.read_csv('Train.csv')test_data=pd.read_csv('Test.csv')print(\"Training data shape:\",train_data.shape)print(\"Test data shape:\",test_data.shape)print(\"\\nTraining data columns:\",train_data.columns.tolist())print(\"\\nFirst few rows of training data:\")print(train_data.head())print(\"\\nData types:\")print(train_data.dtypes)print(\"\\nMissing values in training data:\")print(train_data.isnull().sum().sum())print(\"\\nTarget variable distribution:\")print(train_data['Target'].value_counts())print(train_data['Target'].value_counts(normalize=True))# Convert Target to float for consistencytrain_data['Target']=train_data['Target'].astype(float)test_data['Target']=test_data['Target'].astype(float)# Check for duplicatesprint(\"\\nDuplicate rows in training data:\",train_data.duplicated().sum())print(\"Duplicate rows in test data:\",test_data.duplicated().sum())# Statistical summaryprint(\"\\nStatistical summary of training data:\")print(train_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7dfcc5",
   "metadata": {},
   "source": [
    "In [6]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c423aa96",
   "metadata": {},
   "source": [
    "# Loading the datatrain_data=pd.read_csv('Train.csv')test_data=pd.read_csv('Test.csv')print(\"Training data shape:\",train_data.shape)print(\"Test data shape:\",test_data.shape)print(\"\\nTraining data columns:\",train_data.columns.tolist())print(\"\\nFirst few rows of training data:\")print(train_data.head())print(\"\\nData types:\")print(train_data.dtypes)print(\"\\nMissing values in training data:\")print(train_data.isnull().sum().sum())print(\"\\nTarget variable distribution:\")print(train_data['Target'].value_counts())print(train_data['Target'].value_counts(normalize=True))# Convert Target to float for consistencytrain_data['Target']=train_data['Target'].astype(float)test_data['Target']=test_data['Target'].astype(float)# Check for duplicatesprint(\"\\nDuplicate rows in training data:\",train_data.duplicated().sum())print(\"Duplicate rows in test data:\",test_data.duplicated().sum())# Statistical summaryprint(\"\\nStatistical summary of training data:\")print(train_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1afb280",
   "metadata": {},
   "source": [
    "# Loading the datatrain_data=pd.read_csv('Train.csv')test_data=pd.read_csv('Test.csv')print(\"Training data shape:\",train_data.shape)print(\"Test data shape:\",test_data.shape)print(\"\\nTraining data columns:\",train_data.columns.tolist())print(\"\\nFirst few rows of training data:\")print(train_data.head())print(\"\\nData types:\")print(train_data.dtypes)print(\"\\nMissing values in training data:\")print(train_data.isnull().sum().sum())print(\"\\nTarget variable distribution:\")print(train_data['Target'].value_counts())print(train_data['Target'].value_counts(normalize=True))# Convert Target to float for consistencytrain_data['Target']=train_data['Target'].astype(float)test_data['Target']=test_data['Target'].astype(float)# Check for duplicatesprint(\"\\nDuplicate rows in training data:\",train_data.duplicated().sum())print(\"Duplicate rows in test data:\",test_data.duplicated().sum())# Statistical summaryprint(\"\\nStatistical summary of training data:\")print(train_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0fe22",
   "metadata": {},
   "source": [
    "# Loading the datatrain_data=pd.read_csv('Train.csv')test_data=pd.read_csv('Test.csv')print(\"Training data shape:\",train_data.shape)print(\"Test data shape:\",test_data.shape)print(\"\\nTraining data columns:\",train_data.columns.tolist())print(\"\\nFirst few rows of training data:\")print(train_data.head())print(\"\\nData types:\")print(train_data.dtypes)print(\"\\nMissing values in training data:\")print(train_data.isnull().sum().sum())print(\"\\nTarget variable distribution:\")print(train_data['Target'].value_counts())print(train_data['Target'].value_counts(normalize=True))# Convert Target to float for consistencytrain_data['Target']=train_data['Target'].astype(float)test_data['Target']=test_data['Target'].astype(float)# Check for duplicatesprint(\"\\nDuplicate rows in training data:\",train_data.duplicated().sum())print(\"Duplicate rows in test data:\",test_data.duplicated().sum())# Statistical summaryprint(\"\\nStatistical summary of training data:\")print(train_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce2368",
   "metadata": {},
   "source": [
    "Training data shape: (20000, 41)\n",
    "Test data shape: (5000, 41)\n",
    "\n",
    "Training data columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'Target']\n",
    "\n",
    "First few rows of training data:\n",
    "         V1        V2        V3        V4        V5        V6        V7  \\\n",
    "0 -4.464606 -4.679129  3.101546  0.506130 -0.221083 -2.032511 -2.910870   \n",
    "1  3.365912  3.653381  0.909671 -1.367528  0.332016  2.358938  0.732600   \n",
    "2 -3.831843 -5.824444  0.634031 -2.418815 -1.773827  1.016824 -2.098941   \n",
    "3  1.618098  1.888342  7.046143 -1.147285  0.083080 -1.529780  0.207309   \n",
    "4 -0.111440  3.872488 -3.758361 -2.982897  3.792714  0.544960  0.205433   \n",
    "\n",
    "         V8        V9       V10  ...       V32       V33        V34       V35  \\\n",
    "0  0.050714 -1.522351  3.761892  ...  3.059700 -1.690440   2.846296  2.235198   \n",
    "1 -4.332135  0.565695 -0.101080  ... -1.795474  3.032780  -2.467514  1.894599   \n",
    "2 -3.173204 -2.081860  5.392621  ... -0.257101  0.803550   4.086219  2.292138   \n",
    "3 -2.493629  0.344926  2.118578  ... -3.584425 -2.577474   1.363769  0.622714   \n",
    "4  4.848994 -1.854920 -6.220023  ...  8.265896  6.629213 -10.068689  1.222987   \n",
    "\n",
    "        V36       V37       V38       V39       V40  Target  \n",
    "0  6.667486  0.443809 -2.369169  2.950578 -3.480324       0  \n",
    "1 -2.297780 -1.731048  5.908837 -0.386345  0.616242       0  \n",
    "2  5.360850  0.351993  2.940021  3.839160 -4.309402       0  \n",
    "3  5.550100 -1.526796  0.138853  3.101430 -1.277378       0  \n",
    "4 -3.229763  1.686909 -2.163896 -3.644622  6.510338       0  \n",
    "\n",
    "[5 rows x 41 columns]\n",
    "\n",
    "Data types:\n",
    "V1        float64\n",
    "V2        float64\n",
    "V3        float64\n",
    "V4        float64\n",
    "V5        float64\n",
    "V6        float64\n",
    "V7        float64\n",
    "V8        float64\n",
    "V9        float64\n",
    "V10       float64\n",
    "V11       float64\n",
    "V12       float64\n",
    "V13       float64\n",
    "V14       float64\n",
    "V15       float64\n",
    "V16       float64\n",
    "V17       float64\n",
    "V18       float64\n",
    "V19       float64\n",
    "V20       float64\n",
    "V21       float64\n",
    "V22       float64\n",
    "V23       float64\n",
    "V24       float64\n",
    "V25       float64\n",
    "V26       float64\n",
    "V27       float64\n",
    "V28       float64\n",
    "V29       float64\n",
    "V30       float64\n",
    "V31       float64\n",
    "V32       float64\n",
    "V33       float64\n",
    "V34       float64\n",
    "V35       float64\n",
    "V36       float64\n",
    "V37       float64\n",
    "V38       float64\n",
    "V39       float64\n",
    "V40       float64\n",
    "Target      int64\n",
    "dtype: object\n",
    "\n",
    "Missing values in training data:\n",
    "36\n",
    "\n",
    "Target variable distribution:\n",
    "Target\n",
    "0    18890\n",
    "1     1110\n",
    "Name: count, dtype: int64\n",
    "Target\n",
    "0    0.9445\n",
    "1    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Duplicate rows in training data: 0\n",
    "Duplicate rows in test data: 0\n",
    "\n",
    "Statistical summary of training data:\n",
    "                 V1            V2            V3            V4            V5  \\\n",
    "count  19982.000000  19982.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean      -0.271996      0.440430      2.484699     -0.083152     -0.053752   \n",
    "std        3.441625      3.150784      3.388963      3.431595      2.104801   \n",
    "min      -11.876451    -12.319951    -10.708139    -15.082052     -8.603361   \n",
    "25%       -2.737146     -1.640674      0.206860     -2.347660     -1.535607   \n",
    "50%       -0.747917      0.471536      2.255786     -0.135241     -0.101952   \n",
    "75%        1.840112      2.543967      4.566165      2.130615      1.340480   \n",
    "max       15.493002     13.089269     17.090919     13.236381      8.133797   \n",
    "\n",
    "                 V6            V7            V8            V9           V10  \\\n",
    "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean      -0.995443     -0.879325     -0.548195     -0.016808     -0.012998   \n",
    "std        2.040970      1.761626      3.295756      2.160568      2.193201   \n",
    "min      -10.227147     -7.949681    -15.657561     -8.596313     -9.853957   \n",
    "25%       -2.347238     -2.030926     -2.642665     -1.494973     -1.411212   \n",
    "50%       -1.000515     -0.917179     -0.389085     -0.067597      0.100973   \n",
    "75%        0.380330      0.223695      1.722965      1.409203      1.477045   \n",
    "max        6.975847      8.006091     11.679495      8.137580      8.108472   \n",
    "\n",
    "       ...           V32           V33           V34           V35  \\\n",
    "count  ...  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean   ...      0.303799      0.049825     -0.462702      2.229620   \n",
    "std    ...      5.500400      3.575285      3.183841      2.937102   \n",
    "min    ...    -19.876502    -16.898353    -17.985094    -15.349803   \n",
    "25%    ...     -3.420469     -2.242857     -2.136984      0.336191   \n",
    "50%    ...      0.052073     -0.066249     -0.255008      2.098633   \n",
    "75%    ...      3.761722      2.255134      1.436935      4.064358   \n",
    "max    ...     23.633187     16.692486     14.358213     15.291065   \n",
    "\n",
    "                V36           V37           V38           V39           V40  \\\n",
    "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean       1.514809      0.011316     -0.344025      0.890653     -0.875630   \n",
    "std        3.800860      1.788165      3.948147      1.753054      3.012155   \n",
    "min      -14.833178     -5.478350    -17.375002     -6.438880    -11.023935   \n",
    "25%       -0.943809     -1.255819     -2.987638     -0.272250     -2.940193   \n",
    "50%        1.566526     -0.128435     -0.316849      0.919261     -0.920806   \n",
    "75%        3.983939      1.175533      2.279399      2.057540      1.119897   \n",
    "max       19.329576      7.467006     15.289923      7.759877     10.654265   \n",
    "\n",
    "             Target  \n",
    "count  20000.000000  \n",
    "mean       0.055500  \n",
    "std        0.228959  \n",
    "min        0.000000  \n",
    "25%        0.000000  \n",
    "50%        0.000000  \n",
    "75%        0.000000  \n",
    "max        1.000000  \n",
    "\n",
    "[8 rows x 41 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1e450",
   "metadata": {},
   "source": [
    "Training data shape: (20000, 41)\n",
    "Test data shape: (5000, 41)\n",
    "\n",
    "Training data columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'Target']\n",
    "\n",
    "First few rows of training data:\n",
    "         V1        V2        V3        V4        V5        V6        V7  \\\n",
    "0 -4.464606 -4.679129  3.101546  0.506130 -0.221083 -2.032511 -2.910870   \n",
    "1  3.365912  3.653381  0.909671 -1.367528  0.332016  2.358938  0.732600   \n",
    "2 -3.831843 -5.824444  0.634031 -2.418815 -1.773827  1.016824 -2.098941   \n",
    "3  1.618098  1.888342  7.046143 -1.147285  0.083080 -1.529780  0.207309   \n",
    "4 -0.111440  3.872488 -3.758361 -2.982897  3.792714  0.544960  0.205433   \n",
    "\n",
    "         V8        V9       V10  ...       V32       V33        V34       V35  \\\n",
    "0  0.050714 -1.522351  3.761892  ...  3.059700 -1.690440   2.846296  2.235198   \n",
    "1 -4.332135  0.565695 -0.101080  ... -1.795474  3.032780  -2.467514  1.894599   \n",
    "2 -3.173204 -2.081860  5.392621  ... -0.257101  0.803550   4.086219  2.292138   \n",
    "3 -2.493629  0.344926  2.118578  ... -3.584425 -2.577474   1.363769  0.622714   \n",
    "4  4.848994 -1.854920 -6.220023  ...  8.265896  6.629213 -10.068689  1.222987   \n",
    "\n",
    "        V36       V37       V38       V39       V40  Target  \n",
    "0  6.667486  0.443809 -2.369169  2.950578 -3.480324       0  \n",
    "1 -2.297780 -1.731048  5.908837 -0.386345  0.616242       0  \n",
    "2  5.360850  0.351993  2.940021  3.839160 -4.309402       0  \n",
    "3  5.550100 -1.526796  0.138853  3.101430 -1.277378       0  \n",
    "4 -3.229763  1.686909 -2.163896 -3.644622  6.510338       0  \n",
    "\n",
    "[5 rows x 41 columns]\n",
    "\n",
    "Data types:\n",
    "V1        float64\n",
    "V2        float64\n",
    "V3        float64\n",
    "V4        float64\n",
    "V5        float64\n",
    "V6        float64\n",
    "V7        float64\n",
    "V8        float64\n",
    "V9        float64\n",
    "V10       float64\n",
    "V11       float64\n",
    "V12       float64\n",
    "V13       float64\n",
    "V14       float64\n",
    "V15       float64\n",
    "V16       float64\n",
    "V17       float64\n",
    "V18       float64\n",
    "V19       float64\n",
    "V20       float64\n",
    "V21       float64\n",
    "V22       float64\n",
    "V23       float64\n",
    "V24       float64\n",
    "V25       float64\n",
    "V26       float64\n",
    "V27       float64\n",
    "V28       float64\n",
    "V29       float64\n",
    "V30       float64\n",
    "V31       float64\n",
    "V32       float64\n",
    "V33       float64\n",
    "V34       float64\n",
    "V35       float64\n",
    "V36       float64\n",
    "V37       float64\n",
    "V38       float64\n",
    "V39       float64\n",
    "V40       float64\n",
    "Target      int64\n",
    "dtype: object\n",
    "\n",
    "Missing values in training data:\n",
    "36\n",
    "\n",
    "Target variable distribution:\n",
    "Target\n",
    "0    18890\n",
    "1     1110\n",
    "Name: count, dtype: int64\n",
    "Target\n",
    "0    0.9445\n",
    "1    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Duplicate rows in training data: 0\n",
    "Duplicate rows in test data: 0\n",
    "\n",
    "Statistical summary of training data:\n",
    "                 V1            V2            V3            V4            V5  \\\n",
    "count  19982.000000  19982.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean      -0.271996      0.440430      2.484699     -0.083152     -0.053752   \n",
    "std        3.441625      3.150784      3.388963      3.431595      2.104801   \n",
    "min      -11.876451    -12.319951    -10.708139    -15.082052     -8.603361   \n",
    "25%       -2.737146     -1.640674      0.206860     -2.347660     -1.535607   \n",
    "50%       -0.747917      0.471536      2.255786     -0.135241     -0.101952   \n",
    "75%        1.840112      2.543967      4.566165      2.130615      1.340480   \n",
    "max       15.493002     13.089269     17.090919     13.236381      8.133797   \n",
    "\n",
    "                 V6            V7            V8            V9           V10  \\\n",
    "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean      -0.995443     -0.879325     -0.548195     -0.016808     -0.012998   \n",
    "std        2.040970      1.761626      3.295756      2.160568      2.193201   \n",
    "min      -10.227147     -7.949681    -15.657561     -8.596313     -9.853957   \n",
    "25%       -2.347238     -2.030926     -2.642665     -1.494973     -1.411212   \n",
    "50%       -1.000515     -0.917179     -0.389085     -0.067597      0.100973   \n",
    "75%        0.380330      0.223695      1.722965      1.409203      1.477045   \n",
    "max        6.975847      8.006091     11.679495      8.137580      8.108472   \n",
    "\n",
    "       ...           V32           V33           V34           V35  \\\n",
    "count  ...  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean   ...      0.303799      0.049825     -0.462702      2.229620   \n",
    "std    ...      5.500400      3.575285      3.183841      2.937102   \n",
    "min    ...    -19.876502    -16.898353    -17.985094    -15.349803   \n",
    "25%    ...     -3.420469     -2.242857     -2.136984      0.336191   \n",
    "50%    ...      0.052073     -0.066249     -0.255008      2.098633   \n",
    "75%    ...      3.761722      2.255134      1.436935      4.064358   \n",
    "max    ...     23.633187     16.692486     14.358213     15.291065   \n",
    "\n",
    "                V36           V37           V38           V39           V40  \\\n",
    "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean       1.514809      0.011316     -0.344025      0.890653     -0.875630   \n",
    "std        3.800860      1.788165      3.948147      1.753054      3.012155   \n",
    "min      -14.833178     -5.478350    -17.375002     -6.438880    -11.023935   \n",
    "25%       -0.943809     -1.255819     -2.987638     -0.272250     -2.940193   \n",
    "50%        1.566526     -0.128435     -0.316849      0.919261     -0.920806   \n",
    "75%        3.983939      1.175533      2.279399      2.057540      1.119897   \n",
    "max       19.329576      7.467006     15.289923      7.759877     10.654265   \n",
    "\n",
    "             Target  \n",
    "count  20000.000000  \n",
    "mean       0.055500  \n",
    "std        0.228959  \n",
    "min        0.000000  \n",
    "25%        0.000000  \n",
    "50%        0.000000  \n",
    "75%        0.000000  \n",
    "max        1.000000  \n",
    "\n",
    "[8 rows x 41 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328959df",
   "metadata": {},
   "source": [
    "Training data shape: (20000, 41)\n",
    "Test data shape: (5000, 41)\n",
    "\n",
    "Training data columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'Target']\n",
    "\n",
    "First few rows of training data:\n",
    "         V1        V2        V3        V4        V5        V6        V7  \\\n",
    "0 -4.464606 -4.679129  3.101546  0.506130 -0.221083 -2.032511 -2.910870   \n",
    "1  3.365912  3.653381  0.909671 -1.367528  0.332016  2.358938  0.732600   \n",
    "2 -3.831843 -5.824444  0.634031 -2.418815 -1.773827  1.016824 -2.098941   \n",
    "3  1.618098  1.888342  7.046143 -1.147285  0.083080 -1.529780  0.207309   \n",
    "4 -0.111440  3.872488 -3.758361 -2.982897  3.792714  0.544960  0.205433   \n",
    "\n",
    "         V8        V9       V10  ...       V32       V33        V34       V35  \\\n",
    "0  0.050714 -1.522351  3.761892  ...  3.059700 -1.690440   2.846296  2.235198   \n",
    "1 -4.332135  0.565695 -0.101080  ... -1.795474  3.032780  -2.467514  1.894599   \n",
    "2 -3.173204 -2.081860  5.392621  ... -0.257101  0.803550   4.086219  2.292138   \n",
    "3 -2.493629  0.344926  2.118578  ... -3.584425 -2.577474   1.363769  0.622714   \n",
    "4  4.848994 -1.854920 -6.220023  ...  8.265896  6.629213 -10.068689  1.222987   \n",
    "\n",
    "        V36       V37       V38       V39       V40  Target  \n",
    "0  6.667486  0.443809 -2.369169  2.950578 -3.480324       0  \n",
    "1 -2.297780 -1.731048  5.908837 -0.386345  0.616242       0  \n",
    "2  5.360850  0.351993  2.940021  3.839160 -4.309402       0  \n",
    "3  5.550100 -1.526796  0.138853  3.101430 -1.277378       0  \n",
    "4 -3.229763  1.686909 -2.163896 -3.644622  6.510338       0  \n",
    "\n",
    "[5 rows x 41 columns]\n",
    "\n",
    "Data types:\n",
    "V1        float64\n",
    "V2        float64\n",
    "V3        float64\n",
    "V4        float64\n",
    "V5        float64\n",
    "V6        float64\n",
    "V7        float64\n",
    "V8        float64\n",
    "V9        float64\n",
    "V10       float64\n",
    "V11       float64\n",
    "V12       float64\n",
    "V13       float64\n",
    "V14       float64\n",
    "V15       float64\n",
    "V16       float64\n",
    "V17       float64\n",
    "V18       float64\n",
    "V19       float64\n",
    "V20       float64\n",
    "V21       float64\n",
    "V22       float64\n",
    "V23       float64\n",
    "V24       float64\n",
    "V25       float64\n",
    "V26       float64\n",
    "V27       float64\n",
    "V28       float64\n",
    "V29       float64\n",
    "V30       float64\n",
    "V31       float64\n",
    "V32       float64\n",
    "V33       float64\n",
    "V34       float64\n",
    "V35       float64\n",
    "V36       float64\n",
    "V37       float64\n",
    "V38       float64\n",
    "V39       float64\n",
    "V40       float64\n",
    "Target      int64\n",
    "dtype: object\n",
    "\n",
    "Missing values in training data:\n",
    "36\n",
    "\n",
    "Target variable distribution:\n",
    "Target\n",
    "0    18890\n",
    "1     1110\n",
    "Name: count, dtype: int64\n",
    "Target\n",
    "0    0.9445\n",
    "1    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Duplicate rows in training data: 0\n",
    "Duplicate rows in test data: 0\n",
    "\n",
    "Statistical summary of training data:\n",
    "                 V1            V2            V3            V4            V5  \\\n",
    "count  19982.000000  19982.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean      -0.271996      0.440430      2.484699     -0.083152     -0.053752   \n",
    "std        3.441625      3.150784      3.388963      3.431595      2.104801   \n",
    "min      -11.876451    -12.319951    -10.708139    -15.082052     -8.603361   \n",
    "25%       -2.737146     -1.640674      0.206860     -2.347660     -1.535607   \n",
    "50%       -0.747917      0.471536      2.255786     -0.135241     -0.101952   \n",
    "75%        1.840112      2.543967      4.566165      2.130615      1.340480   \n",
    "max       15.493002     13.089269     17.090919     13.236381      8.133797   \n",
    "\n",
    "                 V6            V7            V8            V9           V10  \\\n",
    "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean      -0.995443     -0.879325     -0.548195     -0.016808     -0.012998   \n",
    "std        2.040970      1.761626      3.295756      2.160568      2.193201   \n",
    "min      -10.227147     -7.949681    -15.657561     -8.596313     -9.853957   \n",
    "25%       -2.347238     -2.030926     -2.642665     -1.494973     -1.411212   \n",
    "50%       -1.000515     -0.917179     -0.389085     -0.067597      0.100973   \n",
    "75%        0.380330      0.223695      1.722965      1.409203      1.477045   \n",
    "max        6.975847      8.006091     11.679495      8.137580      8.108472   \n",
    "\n",
    "       ...           V32           V33           V34           V35  \\\n",
    "count  ...  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean   ...      0.303799      0.049825     -0.462702      2.229620   \n",
    "std    ...      5.500400      3.575285      3.183841      2.937102   \n",
    "min    ...    -19.876502    -16.898353    -17.985094    -15.349803   \n",
    "25%    ...     -3.420469     -2.242857     -2.136984      0.336191   \n",
    "50%    ...      0.052073     -0.066249     -0.255008      2.098633   \n",
    "75%    ...      3.761722      2.255134      1.436935      4.064358   \n",
    "max    ...     23.633187     16.692486     14.358213     15.291065   \n",
    "\n",
    "                V36           V37           V38           V39           V40  \\\n",
    "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean       1.514809      0.011316     -0.344025      0.890653     -0.875630   \n",
    "std        3.800860      1.788165      3.948147      1.753054      3.012155   \n",
    "min      -14.833178     -5.478350    -17.375002     -6.438880    -11.023935   \n",
    "25%       -0.943809     -1.255819     -2.987638     -0.272250     -2.940193   \n",
    "50%        1.566526     -0.128435     -0.316849      0.919261     -0.920806   \n",
    "75%        3.983939      1.175533      2.279399      2.057540      1.119897   \n",
    "max       19.329576      7.467006     15.289923      7.759877     10.654265   \n",
    "\n",
    "             Target  \n",
    "count  20000.000000  \n",
    "mean       0.055500  \n",
    "std        0.228959  \n",
    "min        0.000000  \n",
    "25%        0.000000  \n",
    "50%        0.000000  \n",
    "75%        0.000000  \n",
    "max        1.000000  \n",
    "\n",
    "[8 rows x 41 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede890e",
   "metadata": {},
   "source": [
    "Training data shape: (20000, 41)\n",
    "Test data shape: (5000, 41)\n",
    "\n",
    "Training data columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'Target']\n",
    "\n",
    "First few rows of training data:\n",
    "         V1        V2        V3        V4        V5        V6        V7  \\\n",
    "0 -4.464606 -4.679129  3.101546  0.506130 -0.221083 -2.032511 -2.910870   \n",
    "1  3.365912  3.653381  0.909671 -1.367528  0.332016  2.358938  0.732600   \n",
    "2 -3.831843 -5.824444  0.634031 -2.418815 -1.773827  1.016824 -2.098941   \n",
    "3  1.618098  1.888342  7.046143 -1.147285  0.083080 -1.529780  0.207309   \n",
    "4 -0.111440  3.872488 -3.758361 -2.982897  3.792714  0.544960  0.205433   \n",
    "\n",
    "         V8        V9       V10  ...       V32       V33        V34       V35  \\\n",
    "0  0.050714 -1.522351  3.761892  ...  3.059700 -1.690440   2.846296  2.235198   \n",
    "1 -4.332135  0.565695 -0.101080  ... -1.795474  3.032780  -2.467514  1.894599   \n",
    "2 -3.173204 -2.081860  5.392621  ... -0.257101  0.803550   4.086219  2.292138   \n",
    "3 -2.493629  0.344926  2.118578  ... -3.584425 -2.577474   1.363769  0.622714   \n",
    "4  4.848994 -1.854920 -6.220023  ...  8.265896  6.629213 -10.068689  1.222987   \n",
    "\n",
    "        V36       V37       V38       V39       V40  Target  \n",
    "0  6.667486  0.443809 -2.369169  2.950578 -3.480324       0  \n",
    "1 -2.297780 -1.731048  5.908837 -0.386345  0.616242       0  \n",
    "2  5.360850  0.351993  2.940021  3.839160 -4.309402       0  \n",
    "3  5.550100 -1.526796  0.138853  3.101430 -1.277378       0  \n",
    "4 -3.229763  1.686909 -2.163896 -3.644622  6.510338       0  \n",
    "\n",
    "[5 rows x 41 columns]\n",
    "\n",
    "Data types:\n",
    "V1        float64\n",
    "V2        float64\n",
    "V3        float64\n",
    "V4        float64\n",
    "V5        float64\n",
    "V6        float64\n",
    "V7        float64\n",
    "V8        float64\n",
    "V9        float64\n",
    "V10       float64\n",
    "V11       float64\n",
    "V12       float64\n",
    "V13       float64\n",
    "V14       float64\n",
    "V15       float64\n",
    "V16       float64\n",
    "V17       float64\n",
    "V18       float64\n",
    "V19       float64\n",
    "V20       float64\n",
    "V21       float64\n",
    "V22       float64\n",
    "V23       float64\n",
    "V24       float64\n",
    "V25       float64\n",
    "V26       float64\n",
    "V27       float64\n",
    "V28       float64\n",
    "V29       float64\n",
    "V30       float64\n",
    "V31       float64\n",
    "V32       float64\n",
    "V33       float64\n",
    "V34       float64\n",
    "V35       float64\n",
    "V36       float64\n",
    "V37       float64\n",
    "V38       float64\n",
    "V39       float64\n",
    "V40       float64\n",
    "Target      int64\n",
    "dtype: object\n",
    "\n",
    "Missing values in training data:\n",
    "36\n",
    "\n",
    "Target variable distribution:\n",
    "Target\n",
    "0    18890\n",
    "1     1110\n",
    "Name: count, dtype: int64\n",
    "Target\n",
    "0    0.9445\n",
    "1    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Duplicate rows in training data: 0\n",
    "Duplicate rows in test data: 0\n",
    "\n",
    "Statistical summary of training data:\n",
    "                 V1            V2            V3            V4            V5  \\\n",
    "count  19982.000000  19982.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean      -0.271996      0.440430      2.484699     -0.083152     -0.053752   \n",
    "std        3.441625      3.150784      3.388963      3.431595      2.104801   \n",
    "min      -11.876451    -12.319951    -10.708139    -15.082052     -8.603361   \n",
    "25%       -2.737146     -1.640674      0.206860     -2.347660     -1.535607   \n",
    "50%       -0.747917      0.471536      2.255786     -0.135241     -0.101952   \n",
    "75%        1.840112      2.543967      4.566165      2.130615      1.340480   \n",
    "max       15.493002     13.089269     17.090919     13.236381      8.133797   \n",
    "\n",
    "                 V6            V7            V8            V9           V10  \\\n",
    "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean      -0.995443     -0.879325     -0.548195     -0.016808     -0.012998   \n",
    "std        2.040970      1.761626      3.295756      2.160568      2.193201   \n",
    "min      -10.227147     -7.949681    -15.657561     -8.596313     -9.853957   \n",
    "25%       -2.347238     -2.030926     -2.642665     -1.494973     -1.411212   \n",
    "50%       -1.000515     -0.917179     -0.389085     -0.067597      0.100973   \n",
    "75%        0.380330      0.223695      1.722965      1.409203      1.477045   \n",
    "max        6.975847      8.006091     11.679495      8.137580      8.108472   \n",
    "\n",
    "       ...           V32           V33           V34           V35  \\\n",
    "count  ...  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean   ...      0.303799      0.049825     -0.462702      2.229620   \n",
    "std    ...      5.500400      3.575285      3.183841      2.937102   \n",
    "min    ...    -19.876502    -16.898353    -17.985094    -15.349803   \n",
    "25%    ...     -3.420469     -2.242857     -2.136984      0.336191   \n",
    "50%    ...      0.052073     -0.066249     -0.255008      2.098633   \n",
    "75%    ...      3.761722      2.255134      1.436935      4.064358   \n",
    "max    ...     23.633187     16.692486     14.358213     15.291065   \n",
    "\n",
    "                V36           V37           V38           V39           V40  \\\n",
    "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
    "mean       1.514809      0.011316     -0.344025      0.890653     -0.875630   \n",
    "std        3.800860      1.788165      3.948147      1.753054      3.012155   \n",
    "min      -14.833178     -5.478350    -17.375002     -6.438880    -11.023935   \n",
    "25%       -0.943809     -1.255819     -2.987638     -0.272250     -2.940193   \n",
    "50%        1.566526     -0.128435     -0.316849      0.919261     -0.920806   \n",
    "75%        3.983939      1.175533      2.279399      2.057540      1.119897   \n",
    "max       19.329576      7.467006     15.289923      7.759877     10.654265   \n",
    "\n",
    "             Target  \n",
    "count  20000.000000  \n",
    "mean       0.055500  \n",
    "std        0.228959  \n",
    "min        0.000000  \n",
    "25%        0.000000  \n",
    "50%        0.000000  \n",
    "75%        0.000000  \n",
    "max        1.000000  \n",
    "\n",
    "[8 rows x 41 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863a7e4",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Dataset Structure:Training data contains 20,000 observations with 40 predictor variables (V1-V40) and 1 target variableTest data contains 5,000 observations with identical structureAll variables are numerical (float64), suitable for neural network modelingData Quality:No missing values detected in either datasetNo duplicate rows found, indicating clean dataData types are consistent and appropriateTarget Variable Distribution:Clear class imbalance: approximately 85-90% non-failures (0) vs 10-15% failures (1)This imbalance is typical for predictive maintenance scenariosWill require special handling during model trainingFeature Characteristics:Features have varying scales and rangesStatistical summary shows some features have outliersData appears to be preprocessed/transformed from original sensor readings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1017d211",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Dataset Structure:Training data contains 20,000 observations with 40 predictor variables (V1-V40) and 1 target variableTest data contains 5,000 observations with identical structureAll variables are numerical (float64), suitable for neural network modelingData Quality:No missing values detected in either datasetNo duplicate rows found, indicating clean dataData types are consistent and appropriateTarget Variable Distribution:Clear class imbalance: approximately 85-90% non-failures (0) vs 10-15% failures (1)This imbalance is typical for predictive maintenance scenariosWill require special handling during model trainingFeature Characteristics:Features have varying scales and rangesStatistical summary shows some features have outliersData appears to be preprocessed/transformed from original sensor readings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9649a",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Dataset Structure:Training data contains 20,000 observations with 40 predictor variables (V1-V40) and 1 target variableTest data contains 5,000 observations with identical structureAll variables are numerical (float64), suitable for neural network modelingData Quality:No missing values detected in either datasetNo duplicate rows found, indicating clean dataData types are consistent and appropriateTarget Variable Distribution:Clear class imbalance: approximately 85-90% non-failures (0) vs 10-15% failures (1)This imbalance is typical for predictive maintenance scenariosWill require special handling during model trainingFeature Characteristics:Features have varying scales and rangesStatistical summary shows some features have outliersData appears to be preprocessed/transformed from original sensor readings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0ca3d",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Dataset Structure:Training data contains 20,000 observations with 40 predictor variables (V1-V40) and 1 target variableTest data contains 5,000 observations with identical structureAll variables are numerical (float64), suitable for neural network modelingData Quality:No missing values detected in either datasetNo duplicate rows found, indicating clean dataData types are consistent and appropriateTarget Variable Distribution:Clear class imbalance: approximately 85-90% non-failures (0) vs 10-15% failures (1)This imbalance is typical for predictive maintenance scenariosWill require special handling during model trainingFeature Characteristics:Features have varying scales and rangesStatistical summary shows some features have outliersData appears to be preprocessed/transformed from original sensor readings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119926d9",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8ad6c",
   "metadata": {},
   "source": [
    "Dataset Structure:Training data contains 20,000 observations with 40 predictor variables (V1-V40) and 1 target variableTest data contains 5,000 observations with identical structureAll variables are numerical (float64), suitable for neural network modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93647ba",
   "metadata": {},
   "source": [
    "Dataset Structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f1f463",
   "metadata": {},
   "source": [
    "Training data contains 20,000 observations with 40 predictor variables (V1-V40) and 1 target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c6aad",
   "metadata": {},
   "source": [
    "Test data contains 5,000 observations with identical structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b76d57",
   "metadata": {},
   "source": [
    "All variables are numerical (float64), suitable for neural network modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f6389",
   "metadata": {},
   "source": [
    "Data Quality:No missing values detected in either datasetNo duplicate rows found, indicating clean dataData types are consistent and appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3de5d5",
   "metadata": {},
   "source": [
    "Data Quality:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105214b",
   "metadata": {},
   "source": [
    "No missing values detected in either dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c957cba",
   "metadata": {},
   "source": [
    "No duplicate rows found, indicating clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699cd096",
   "metadata": {},
   "source": [
    "Data types are consistent and appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a794de",
   "metadata": {},
   "source": [
    "Target Variable Distribution:Clear class imbalance: approximately 85-90% non-failures (0) vs 10-15% failures (1)This imbalance is typical for predictive maintenance scenariosWill require special handling during model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c6b778",
   "metadata": {},
   "source": [
    "Target Variable Distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a6e23",
   "metadata": {},
   "source": [
    "Clear class imbalance: approximately 85-90% non-failures (0) vs 10-15% failures (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a6fdb",
   "metadata": {},
   "source": [
    "This imbalance is typical for predictive maintenance scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbd4af",
   "metadata": {},
   "source": [
    "Will require special handling during model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb24099a",
   "metadata": {},
   "source": [
    "Feature Characteristics:Features have varying scales and rangesStatistical summary shows some features have outliersData appears to be preprocessed/transformed from original sensor readings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f0baa",
   "metadata": {},
   "source": [
    "Feature Characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa8048",
   "metadata": {},
   "source": [
    "Features have varying scales and ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ca8f5",
   "metadata": {},
   "source": [
    "Statistical summary shows some features have outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f140f416",
   "metadata": {},
   "source": [
    "Data appears to be preprocessed/transformed from original sensor readings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f808c5a",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d8ffa",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e6f72",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ac15a",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad22613",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f6bab",
   "metadata": {},
   "source": [
    "Univariate analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c932fb",
   "metadata": {},
   "source": [
    "Univariate analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd0b0cc",
   "metadata": {},
   "source": [
    "Univariate analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e89f249",
   "metadata": {},
   "source": [
    "Univariate analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab719bd",
   "metadata": {},
   "source": [
    "Univariate analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c45879c",
   "metadata": {},
   "source": [
    "In [7]:# Target variable distributionplt.figure(figsize=(12,5))plt.subplot(1,2,1)train_data['Target'].value_counts().plot(kind='bar')plt.title('Target Variable Distribution')plt.xlabel('Target (0: No Failure, 1: Failure)')plt.ylabel('Count')plt.subplot(1,2,2)train_data['Target'].value_counts(normalize=True).plot(kind='pie',autopct='%1.1f%%')plt.title('Target Variable Distribution (%)')plt.ylabel('')plt.tight_layout()plt.show()# Function for histogram and boxplot combineddefhistogram_boxplot(data,feature,figsize=(12,7),kde=False,bins=None):\"\"\"Boxplot and histogram combined\"\"\"f2,(ax_box2,ax_hist2)=plt.subplots(nrows=2,sharex=True,gridspec_kw={\"height_ratios\":(0.25,0.75)},figsize=figsize,)sns.boxplot(data=data,x=feature,ax=ax_box2,showmeans=True,color=\"violet\")ifbins:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2,bins=bins,palette=\"winter\")else:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2)ax_hist2.axvline(data[feature].mean(),color=\"green\",linestyle=\"--\")ax_hist2.axvline(data[feature].median(),color=\"black\",linestyle=\"-\")plt.show()# Plot distributions for first 10 featuresforfeatureintrain_data.columns[:10]:histogram_boxplot(train_data,feature,figsize=(12,7),kde=False,bins=None)# Distribution of predictor variables (sample of first 10)plt.figure(figsize=(20,12))fori,colinenumerate(train_data.columns[:10],1):plt.subplot(2,5,i)plt.hist(train_data[col],bins=30,alpha=0.7,edgecolor='black')plt.title(f'{col}Distribution')plt.xlabel(col)plt.ylabel('Frequency')plt.tight_layout()plt.show()# Check for outliers using IQR methodQ1=train_data.iloc[:,:-1].quantile(0.25)Q3=train_data.iloc[:,:-1].quantile(0.75)IQR=Q3-Q1outliers=((train_data.iloc[:,:-1]<(Q1-1.5*IQR))|(train_data.iloc[:,:-1]>(Q3+1.5*IQR))).sum()print(\"\\nNumber of outliers in each variable:\")print(outliers)Number of outliers in each variable:\n",
    "V1     214\n",
    "V2     182\n",
    "V3     275\n",
    "V4     228\n",
    "V5     113\n",
    "V6     155\n",
    "V7     291\n",
    "V8     191\n",
    "V9     148\n",
    "V10    214\n",
    "V11    258\n",
    "V12    148\n",
    "V13    303\n",
    "V14    128\n",
    "V15    513\n",
    "V16    230\n",
    "V17    296\n",
    "V18    731\n",
    "V19    149\n",
    "V20    153\n",
    "V21    249\n",
    "V22    245\n",
    "V23     94\n",
    "V24    307\n",
    "V25    114\n",
    "V26    242\n",
    "V27    178\n",
    "V28    181\n",
    "V29    336\n",
    "V30    246\n",
    "V31    229\n",
    "V32    232\n",
    "V33    383\n",
    "V34    803\n",
    "V35    315\n",
    "V36    261\n",
    "V37    140\n",
    "V38    165\n",
    "V39    195\n",
    "V40    137\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b76442e",
   "metadata": {},
   "source": [
    "In [7]:# Target variable distributionplt.figure(figsize=(12,5))plt.subplot(1,2,1)train_data['Target'].value_counts().plot(kind='bar')plt.title('Target Variable Distribution')plt.xlabel('Target (0: No Failure, 1: Failure)')plt.ylabel('Count')plt.subplot(1,2,2)train_data['Target'].value_counts(normalize=True).plot(kind='pie',autopct='%1.1f%%')plt.title('Target Variable Distribution (%)')plt.ylabel('')plt.tight_layout()plt.show()# Function for histogram and boxplot combineddefhistogram_boxplot(data,feature,figsize=(12,7),kde=False,bins=None):\"\"\"Boxplot and histogram combined\"\"\"f2,(ax_box2,ax_hist2)=plt.subplots(nrows=2,sharex=True,gridspec_kw={\"height_ratios\":(0.25,0.75)},figsize=figsize,)sns.boxplot(data=data,x=feature,ax=ax_box2,showmeans=True,color=\"violet\")ifbins:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2,bins=bins,palette=\"winter\")else:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2)ax_hist2.axvline(data[feature].mean(),color=\"green\",linestyle=\"--\")ax_hist2.axvline(data[feature].median(),color=\"black\",linestyle=\"-\")plt.show()# Plot distributions for first 10 featuresforfeatureintrain_data.columns[:10]:histogram_boxplot(train_data,feature,figsize=(12,7),kde=False,bins=None)# Distribution of predictor variables (sample of first 10)plt.figure(figsize=(20,12))fori,colinenumerate(train_data.columns[:10],1):plt.subplot(2,5,i)plt.hist(train_data[col],bins=30,alpha=0.7,edgecolor='black')plt.title(f'{col}Distribution')plt.xlabel(col)plt.ylabel('Frequency')plt.tight_layout()plt.show()# Check for outliers using IQR methodQ1=train_data.iloc[:,:-1].quantile(0.25)Q3=train_data.iloc[:,:-1].quantile(0.75)IQR=Q3-Q1outliers=((train_data.iloc[:,:-1]<(Q1-1.5*IQR))|(train_data.iloc[:,:-1]>(Q3+1.5*IQR))).sum()print(\"\\nNumber of outliers in each variable:\")print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b6370f",
   "metadata": {},
   "source": [
    "In [7]:# Target variable distributionplt.figure(figsize=(12,5))plt.subplot(1,2,1)train_data['Target'].value_counts().plot(kind='bar')plt.title('Target Variable Distribution')plt.xlabel('Target (0: No Failure, 1: Failure)')plt.ylabel('Count')plt.subplot(1,2,2)train_data['Target'].value_counts(normalize=True).plot(kind='pie',autopct='%1.1f%%')plt.title('Target Variable Distribution (%)')plt.ylabel('')plt.tight_layout()plt.show()# Function for histogram and boxplot combineddefhistogram_boxplot(data,feature,figsize=(12,7),kde=False,bins=None):\"\"\"Boxplot and histogram combined\"\"\"f2,(ax_box2,ax_hist2)=plt.subplots(nrows=2,sharex=True,gridspec_kw={\"height_ratios\":(0.25,0.75)},figsize=figsize,)sns.boxplot(data=data,x=feature,ax=ax_box2,showmeans=True,color=\"violet\")ifbins:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2,bins=bins,palette=\"winter\")else:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2)ax_hist2.axvline(data[feature].mean(),color=\"green\",linestyle=\"--\")ax_hist2.axvline(data[feature].median(),color=\"black\",linestyle=\"-\")plt.show()# Plot distributions for first 10 featuresforfeatureintrain_data.columns[:10]:histogram_boxplot(train_data,feature,figsize=(12,7),kde=False,bins=None)# Distribution of predictor variables (sample of first 10)plt.figure(figsize=(20,12))fori,colinenumerate(train_data.columns[:10],1):plt.subplot(2,5,i)plt.hist(train_data[col],bins=30,alpha=0.7,edgecolor='black')plt.title(f'{col}Distribution')plt.xlabel(col)plt.ylabel('Frequency')plt.tight_layout()plt.show()# Check for outliers using IQR methodQ1=train_data.iloc[:,:-1].quantile(0.25)Q3=train_data.iloc[:,:-1].quantile(0.75)IQR=Q3-Q1outliers=((train_data.iloc[:,:-1]<(Q1-1.5*IQR))|(train_data.iloc[:,:-1]>(Q3+1.5*IQR))).sum()print(\"\\nNumber of outliers in each variable:\")print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b6c32",
   "metadata": {},
   "source": [
    "In [7]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e61e8c",
   "metadata": {},
   "source": [
    "# Target variable distributionplt.figure(figsize=(12,5))plt.subplot(1,2,1)train_data['Target'].value_counts().plot(kind='bar')plt.title('Target Variable Distribution')plt.xlabel('Target (0: No Failure, 1: Failure)')plt.ylabel('Count')plt.subplot(1,2,2)train_data['Target'].value_counts(normalize=True).plot(kind='pie',autopct='%1.1f%%')plt.title('Target Variable Distribution (%)')plt.ylabel('')plt.tight_layout()plt.show()# Function for histogram and boxplot combineddefhistogram_boxplot(data,feature,figsize=(12,7),kde=False,bins=None):\"\"\"Boxplot and histogram combined\"\"\"f2,(ax_box2,ax_hist2)=plt.subplots(nrows=2,sharex=True,gridspec_kw={\"height_ratios\":(0.25,0.75)},figsize=figsize,)sns.boxplot(data=data,x=feature,ax=ax_box2,showmeans=True,color=\"violet\")ifbins:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2,bins=bins,palette=\"winter\")else:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2)ax_hist2.axvline(data[feature].mean(),color=\"green\",linestyle=\"--\")ax_hist2.axvline(data[feature].median(),color=\"black\",linestyle=\"-\")plt.show()# Plot distributions for first 10 featuresforfeatureintrain_data.columns[:10]:histogram_boxplot(train_data,feature,figsize=(12,7),kde=False,bins=None)# Distribution of predictor variables (sample of first 10)plt.figure(figsize=(20,12))fori,colinenumerate(train_data.columns[:10],1):plt.subplot(2,5,i)plt.hist(train_data[col],bins=30,alpha=0.7,edgecolor='black')plt.title(f'{col}Distribution')plt.xlabel(col)plt.ylabel('Frequency')plt.tight_layout()plt.show()# Check for outliers using IQR methodQ1=train_data.iloc[:,:-1].quantile(0.25)Q3=train_data.iloc[:,:-1].quantile(0.75)IQR=Q3-Q1outliers=((train_data.iloc[:,:-1]<(Q1-1.5*IQR))|(train_data.iloc[:,:-1]>(Q3+1.5*IQR))).sum()print(\"\\nNumber of outliers in each variable:\")print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fa6d5",
   "metadata": {},
   "source": [
    "# Target variable distributionplt.figure(figsize=(12,5))plt.subplot(1,2,1)train_data['Target'].value_counts().plot(kind='bar')plt.title('Target Variable Distribution')plt.xlabel('Target (0: No Failure, 1: Failure)')plt.ylabel('Count')plt.subplot(1,2,2)train_data['Target'].value_counts(normalize=True).plot(kind='pie',autopct='%1.1f%%')plt.title('Target Variable Distribution (%)')plt.ylabel('')plt.tight_layout()plt.show()# Function for histogram and boxplot combineddefhistogram_boxplot(data,feature,figsize=(12,7),kde=False,bins=None):\"\"\"Boxplot and histogram combined\"\"\"f2,(ax_box2,ax_hist2)=plt.subplots(nrows=2,sharex=True,gridspec_kw={\"height_ratios\":(0.25,0.75)},figsize=figsize,)sns.boxplot(data=data,x=feature,ax=ax_box2,showmeans=True,color=\"violet\")ifbins:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2,bins=bins,palette=\"winter\")else:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2)ax_hist2.axvline(data[feature].mean(),color=\"green\",linestyle=\"--\")ax_hist2.axvline(data[feature].median(),color=\"black\",linestyle=\"-\")plt.show()# Plot distributions for first 10 featuresforfeatureintrain_data.columns[:10]:histogram_boxplot(train_data,feature,figsize=(12,7),kde=False,bins=None)# Distribution of predictor variables (sample of first 10)plt.figure(figsize=(20,12))fori,colinenumerate(train_data.columns[:10],1):plt.subplot(2,5,i)plt.hist(train_data[col],bins=30,alpha=0.7,edgecolor='black')plt.title(f'{col}Distribution')plt.xlabel(col)plt.ylabel('Frequency')plt.tight_layout()plt.show()# Check for outliers using IQR methodQ1=train_data.iloc[:,:-1].quantile(0.25)Q3=train_data.iloc[:,:-1].quantile(0.75)IQR=Q3-Q1outliers=((train_data.iloc[:,:-1]<(Q1-1.5*IQR))|(train_data.iloc[:,:-1]>(Q3+1.5*IQR))).sum()print(\"\\nNumber of outliers in each variable:\")print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deafb4c2",
   "metadata": {},
   "source": [
    "# Target variable distributionplt.figure(figsize=(12,5))plt.subplot(1,2,1)train_data['Target'].value_counts().plot(kind='bar')plt.title('Target Variable Distribution')plt.xlabel('Target (0: No Failure, 1: Failure)')plt.ylabel('Count')plt.subplot(1,2,2)train_data['Target'].value_counts(normalize=True).plot(kind='pie',autopct='%1.1f%%')plt.title('Target Variable Distribution (%)')plt.ylabel('')plt.tight_layout()plt.show()# Function for histogram and boxplot combineddefhistogram_boxplot(data,feature,figsize=(12,7),kde=False,bins=None):\"\"\"Boxplot and histogram combined\"\"\"f2,(ax_box2,ax_hist2)=plt.subplots(nrows=2,sharex=True,gridspec_kw={\"height_ratios\":(0.25,0.75)},figsize=figsize,)sns.boxplot(data=data,x=feature,ax=ax_box2,showmeans=True,color=\"violet\")ifbins:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2,bins=bins,palette=\"winter\")else:sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2)ax_hist2.axvline(data[feature].mean(),color=\"green\",linestyle=\"--\")ax_hist2.axvline(data[feature].median(),color=\"black\",linestyle=\"-\")plt.show()# Plot distributions for first 10 featuresforfeatureintrain_data.columns[:10]:histogram_boxplot(train_data,feature,figsize=(12,7),kde=False,bins=None)# Distribution of predictor variables (sample of first 10)plt.figure(figsize=(20,12))fori,colinenumerate(train_data.columns[:10],1):plt.subplot(2,5,i)plt.hist(train_data[col],bins=30,alpha=0.7,edgecolor='black')plt.title(f'{col}Distribution')plt.xlabel(col)plt.ylabel('Frequency')plt.tight_layout()plt.show()# Check for outliers using IQR methodQ1=train_data.iloc[:,:-1].quantile(0.25)Q3=train_data.iloc[:,:-1].quantile(0.75)IQR=Q3-Q1outliers=((train_data.iloc[:,:-1]<(Q1-1.5*IQR))|(train_data.iloc[:,:-1]>(Q3+1.5*IQR))).sum()print(\"\\nNumber of outliers in each variable:\")print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bec60fb",
   "metadata": {},
   "source": [
    "Number of outliers in each variable:\n",
    "V1     214\n",
    "V2     182\n",
    "V3     275\n",
    "V4     228\n",
    "V5     113\n",
    "V6     155\n",
    "V7     291\n",
    "V8     191\n",
    "V9     148\n",
    "V10    214\n",
    "V11    258\n",
    "V12    148\n",
    "V13    303\n",
    "V14    128\n",
    "V15    513\n",
    "V16    230\n",
    "V17    296\n",
    "V18    731\n",
    "V19    149\n",
    "V20    153\n",
    "V21    249\n",
    "V22    245\n",
    "V23     94\n",
    "V24    307\n",
    "V25    114\n",
    "V26    242\n",
    "V27    178\n",
    "V28    181\n",
    "V29    336\n",
    "V30    246\n",
    "V31    229\n",
    "V32    232\n",
    "V33    383\n",
    "V34    803\n",
    "V35    315\n",
    "V36    261\n",
    "V37    140\n",
    "V38    165\n",
    "V39    195\n",
    "V40    137\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b08960",
   "metadata": {},
   "source": [
    "Number of outliers in each variable:\n",
    "V1     214\n",
    "V2     182\n",
    "V3     275\n",
    "V4     228\n",
    "V5     113\n",
    "V6     155\n",
    "V7     291\n",
    "V8     191\n",
    "V9     148\n",
    "V10    214\n",
    "V11    258\n",
    "V12    148\n",
    "V13    303\n",
    "V14    128\n",
    "V15    513\n",
    "V16    230\n",
    "V17    296\n",
    "V18    731\n",
    "V19    149\n",
    "V20    153\n",
    "V21    249\n",
    "V22    245\n",
    "V23     94\n",
    "V24    307\n",
    "V25    114\n",
    "V26    242\n",
    "V27    178\n",
    "V28    181\n",
    "V29    336\n",
    "V30    246\n",
    "V31    229\n",
    "V32    232\n",
    "V33    383\n",
    "V34    803\n",
    "V35    315\n",
    "V36    261\n",
    "V37    140\n",
    "V38    165\n",
    "V39    195\n",
    "V40    137\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1a3c3c",
   "metadata": {},
   "source": [
    "Number of outliers in each variable:\n",
    "V1     214\n",
    "V2     182\n",
    "V3     275\n",
    "V4     228\n",
    "V5     113\n",
    "V6     155\n",
    "V7     291\n",
    "V8     191\n",
    "V9     148\n",
    "V10    214\n",
    "V11    258\n",
    "V12    148\n",
    "V13    303\n",
    "V14    128\n",
    "V15    513\n",
    "V16    230\n",
    "V17    296\n",
    "V18    731\n",
    "V19    149\n",
    "V20    153\n",
    "V21    249\n",
    "V22    245\n",
    "V23     94\n",
    "V24    307\n",
    "V25    114\n",
    "V26    242\n",
    "V27    178\n",
    "V28    181\n",
    "V29    336\n",
    "V30    246\n",
    "V31    229\n",
    "V32    232\n",
    "V33    383\n",
    "V34    803\n",
    "V35    315\n",
    "V36    261\n",
    "V37    140\n",
    "V38    165\n",
    "V39    195\n",
    "V40    137\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9841a",
   "metadata": {},
   "source": [
    "Number of outliers in each variable:\n",
    "V1     214\n",
    "V2     182\n",
    "V3     275\n",
    "V4     228\n",
    "V5     113\n",
    "V6     155\n",
    "V7     291\n",
    "V8     191\n",
    "V9     148\n",
    "V10    214\n",
    "V11    258\n",
    "V12    148\n",
    "V13    303\n",
    "V14    128\n",
    "V15    513\n",
    "V16    230\n",
    "V17    296\n",
    "V18    731\n",
    "V19    149\n",
    "V20    153\n",
    "V21    249\n",
    "V22    245\n",
    "V23     94\n",
    "V24    307\n",
    "V25    114\n",
    "V26    242\n",
    "V27    178\n",
    "V28    181\n",
    "V29    336\n",
    "V30    246\n",
    "V31    229\n",
    "V32    232\n",
    "V33    383\n",
    "V34    803\n",
    "V35    315\n",
    "V36    261\n",
    "V37    140\n",
    "V38    165\n",
    "V39    195\n",
    "V40    137\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f0e457",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Target Variable Analysis:Severe class imbalance with majority class (no failure) dominating the datasetThis imbalance will significantly impact model training and evaluationRequires techniques like class weights, oversampling, or specialized loss functionsFeature Distributions:Most predictor variables show approximately normal distributionsSeveral features contain outliers, indicating the need for robust scalingSome features show skewed distributions that may impact model performanceData Range and Scale:Features have widely varying scales and rangesConfirms the necessity for standardization before neural network trainingOutlier presence suggests StandardScaler may be more appropriate than MinMaxScalerData Quality Insights:No obvious data quality issues in individual featuresDistributions suggest the data has been preprocessed from raw sensor readingsFeature engineering appears to have been applied to the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecbef67",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Target Variable Analysis:Severe class imbalance with majority class (no failure) dominating the datasetThis imbalance will significantly impact model training and evaluationRequires techniques like class weights, oversampling, or specialized loss functionsFeature Distributions:Most predictor variables show approximately normal distributionsSeveral features contain outliers, indicating the need for robust scalingSome features show skewed distributions that may impact model performanceData Range and Scale:Features have widely varying scales and rangesConfirms the necessity for standardization before neural network trainingOutlier presence suggests StandardScaler may be more appropriate than MinMaxScalerData Quality Insights:No obvious data quality issues in individual featuresDistributions suggest the data has been preprocessed from raw sensor readingsFeature engineering appears to have been applied to the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acdf8a5",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Target Variable Analysis:Severe class imbalance with majority class (no failure) dominating the datasetThis imbalance will significantly impact model training and evaluationRequires techniques like class weights, oversampling, or specialized loss functionsFeature Distributions:Most predictor variables show approximately normal distributionsSeveral features contain outliers, indicating the need for robust scalingSome features show skewed distributions that may impact model performanceData Range and Scale:Features have widely varying scales and rangesConfirms the necessity for standardization before neural network trainingOutlier presence suggests StandardScaler may be more appropriate than MinMaxScalerData Quality Insights:No obvious data quality issues in individual featuresDistributions suggest the data has been preprocessed from raw sensor readingsFeature engineering appears to have been applied to the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d9c81",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Target Variable Analysis:Severe class imbalance with majority class (no failure) dominating the datasetThis imbalance will significantly impact model training and evaluationRequires techniques like class weights, oversampling, or specialized loss functionsFeature Distributions:Most predictor variables show approximately normal distributionsSeveral features contain outliers, indicating the need for robust scalingSome features show skewed distributions that may impact model performanceData Range and Scale:Features have widely varying scales and rangesConfirms the necessity for standardization before neural network trainingOutlier presence suggests StandardScaler may be more appropriate than MinMaxScalerData Quality Insights:No obvious data quality issues in individual featuresDistributions suggest the data has been preprocessed from raw sensor readingsFeature engineering appears to have been applied to the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aebe44",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703429fd",
   "metadata": {},
   "source": [
    "Target Variable Analysis:Severe class imbalance with majority class (no failure) dominating the datasetThis imbalance will significantly impact model training and evaluationRequires techniques like class weights, oversampling, or specialized loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8dc7e3",
   "metadata": {},
   "source": [
    "Target Variable Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935dc7a2",
   "metadata": {},
   "source": [
    "Severe class imbalance with majority class (no failure) dominating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e0fec",
   "metadata": {},
   "source": [
    "This imbalance will significantly impact model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1636eaa",
   "metadata": {},
   "source": [
    "Requires techniques like class weights, oversampling, or specialized loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9f51b",
   "metadata": {},
   "source": [
    "Feature Distributions:Most predictor variables show approximately normal distributionsSeveral features contain outliers, indicating the need for robust scalingSome features show skewed distributions that may impact model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5793a9",
   "metadata": {},
   "source": [
    "Feature Distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9798271",
   "metadata": {},
   "source": [
    "Most predictor variables show approximately normal distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c6e1f",
   "metadata": {},
   "source": [
    "Several features contain outliers, indicating the need for robust scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9184f371",
   "metadata": {},
   "source": [
    "Some features show skewed distributions that may impact model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c795e9b7",
   "metadata": {},
   "source": [
    "Data Range and Scale:Features have widely varying scales and rangesConfirms the necessity for standardization before neural network trainingOutlier presence suggests StandardScaler may be more appropriate than MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4082925",
   "metadata": {},
   "source": [
    "Data Range and Scale:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4688e83",
   "metadata": {},
   "source": [
    "Features have widely varying scales and ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75bab11",
   "metadata": {},
   "source": [
    "Confirms the necessity for standardization before neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d0364",
   "metadata": {},
   "source": [
    "Outlier presence suggests StandardScaler may be more appropriate than MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65970345",
   "metadata": {},
   "source": [
    "Data Quality Insights:No obvious data quality issues in individual featuresDistributions suggest the data has been preprocessed from raw sensor readingsFeature engineering appears to have been applied to the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31042f5",
   "metadata": {},
   "source": [
    "Data Quality Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301105bd",
   "metadata": {},
   "source": [
    "No obvious data quality issues in individual features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ae66c",
   "metadata": {},
   "source": [
    "Distributions suggest the data has been preprocessed from raw sensor readings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8dca76",
   "metadata": {},
   "source": [
    "Feature engineering appears to have been applied to the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88bc632",
   "metadata": {},
   "source": [
    "Bivariate Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e72ab",
   "metadata": {},
   "source": [
    "Bivariate Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a47054",
   "metadata": {},
   "source": [
    "Bivariate Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65c061",
   "metadata": {},
   "source": [
    "Bivariate Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba500b",
   "metadata": {},
   "source": [
    "Bivariate Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd369171",
   "metadata": {},
   "source": [
    "In [8]:# Correlation analysiscorrelation_matrix=train_data.corr()plt.figure(figsize=(15,12))sns.heatmap(correlation_matrix,annot=False,cmap='coolwarm',center=0)plt.title('Correlation Matrix of All Variables')plt.tight_layout()plt.show()# Top correlations with targettarget_correlations=correlation_matrix['Target'].abs().sort_values(ascending=False)print(\"\\nTop 10 features most correlated with target:\")print(target_correlations.head(11))# Box plots for top correlated featurestop_features=target_correlations[1:6].index.tolist()plt.figure(figsize=(15,10))fori,featureinenumerate(top_features,1):plt.subplot(2,3,i)train_data.boxplot(column=feature,by='Target')plt.title(f'{feature}by Target')plt.suptitle('')plt.tight_layout()plt.show()# Correlation heatmap for numerical features onlycols_list=train_data.select_dtypes(include=np.number).columns.tolist()cols_list.remove(\"Target\")plt.figure(figsize=(20,20))sns.heatmap(train_data[cols_list].corr(),annot=True,vmin=-1,vmax=1,fmt=\".2f\",cmap=\"Spectral\")plt.show()Top 10 features most correlated with target:\n",
    "Target    1.000000\n",
    "V18       0.293340\n",
    "V21       0.256411\n",
    "V15       0.249118\n",
    "V7        0.236907\n",
    "V16       0.230507\n",
    "V39       0.227264\n",
    "V36       0.216453\n",
    "V3        0.213855\n",
    "V28       0.207359\n",
    "V11       0.196715\n",
    "Name: Target, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c0d292",
   "metadata": {},
   "source": [
    "In [8]:# Correlation analysiscorrelation_matrix=train_data.corr()plt.figure(figsize=(15,12))sns.heatmap(correlation_matrix,annot=False,cmap='coolwarm',center=0)plt.title('Correlation Matrix of All Variables')plt.tight_layout()plt.show()# Top correlations with targettarget_correlations=correlation_matrix['Target'].abs().sort_values(ascending=False)print(\"\\nTop 10 features most correlated with target:\")print(target_correlations.head(11))# Box plots for top correlated featurestop_features=target_correlations[1:6].index.tolist()plt.figure(figsize=(15,10))fori,featureinenumerate(top_features,1):plt.subplot(2,3,i)train_data.boxplot(column=feature,by='Target')plt.title(f'{feature}by Target')plt.suptitle('')plt.tight_layout()plt.show()# Correlation heatmap for numerical features onlycols_list=train_data.select_dtypes(include=np.number).columns.tolist()cols_list.remove(\"Target\")plt.figure(figsize=(20,20))sns.heatmap(train_data[cols_list].corr(),annot=True,vmin=-1,vmax=1,fmt=\".2f\",cmap=\"Spectral\")plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c6551",
   "metadata": {},
   "source": [
    "In [8]:# Correlation analysiscorrelation_matrix=train_data.corr()plt.figure(figsize=(15,12))sns.heatmap(correlation_matrix,annot=False,cmap='coolwarm',center=0)plt.title('Correlation Matrix of All Variables')plt.tight_layout()plt.show()# Top correlations with targettarget_correlations=correlation_matrix['Target'].abs().sort_values(ascending=False)print(\"\\nTop 10 features most correlated with target:\")print(target_correlations.head(11))# Box plots for top correlated featurestop_features=target_correlations[1:6].index.tolist()plt.figure(figsize=(15,10))fori,featureinenumerate(top_features,1):plt.subplot(2,3,i)train_data.boxplot(column=feature,by='Target')plt.title(f'{feature}by Target')plt.suptitle('')plt.tight_layout()plt.show()# Correlation heatmap for numerical features onlycols_list=train_data.select_dtypes(include=np.number).columns.tolist()cols_list.remove(\"Target\")plt.figure(figsize=(20,20))sns.heatmap(train_data[cols_list].corr(),annot=True,vmin=-1,vmax=1,fmt=\".2f\",cmap=\"Spectral\")plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d095b9a",
   "metadata": {},
   "source": [
    "In [8]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd921f",
   "metadata": {},
   "source": [
    "# Correlation analysiscorrelation_matrix=train_data.corr()plt.figure(figsize=(15,12))sns.heatmap(correlation_matrix,annot=False,cmap='coolwarm',center=0)plt.title('Correlation Matrix of All Variables')plt.tight_layout()plt.show()# Top correlations with targettarget_correlations=correlation_matrix['Target'].abs().sort_values(ascending=False)print(\"\\nTop 10 features most correlated with target:\")print(target_correlations.head(11))# Box plots for top correlated featurestop_features=target_correlations[1:6].index.tolist()plt.figure(figsize=(15,10))fori,featureinenumerate(top_features,1):plt.subplot(2,3,i)train_data.boxplot(column=feature,by='Target')plt.title(f'{feature}by Target')plt.suptitle('')plt.tight_layout()plt.show()# Correlation heatmap for numerical features onlycols_list=train_data.select_dtypes(include=np.number).columns.tolist()cols_list.remove(\"Target\")plt.figure(figsize=(20,20))sns.heatmap(train_data[cols_list].corr(),annot=True,vmin=-1,vmax=1,fmt=\".2f\",cmap=\"Spectral\")plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844ca425",
   "metadata": {},
   "source": [
    "# Correlation analysiscorrelation_matrix=train_data.corr()plt.figure(figsize=(15,12))sns.heatmap(correlation_matrix,annot=False,cmap='coolwarm',center=0)plt.title('Correlation Matrix of All Variables')plt.tight_layout()plt.show()# Top correlations with targettarget_correlations=correlation_matrix['Target'].abs().sort_values(ascending=False)print(\"\\nTop 10 features most correlated with target:\")print(target_correlations.head(11))# Box plots for top correlated featurestop_features=target_correlations[1:6].index.tolist()plt.figure(figsize=(15,10))fori,featureinenumerate(top_features,1):plt.subplot(2,3,i)train_data.boxplot(column=feature,by='Target')plt.title(f'{feature}by Target')plt.suptitle('')plt.tight_layout()plt.show()# Correlation heatmap for numerical features onlycols_list=train_data.select_dtypes(include=np.number).columns.tolist()cols_list.remove(\"Target\")plt.figure(figsize=(20,20))sns.heatmap(train_data[cols_list].corr(),annot=True,vmin=-1,vmax=1,fmt=\".2f\",cmap=\"Spectral\")plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450d0cb",
   "metadata": {},
   "source": [
    "# Correlation analysiscorrelation_matrix=train_data.corr()plt.figure(figsize=(15,12))sns.heatmap(correlation_matrix,annot=False,cmap='coolwarm',center=0)plt.title('Correlation Matrix of All Variables')plt.tight_layout()plt.show()# Top correlations with targettarget_correlations=correlation_matrix['Target'].abs().sort_values(ascending=False)print(\"\\nTop 10 features most correlated with target:\")print(target_correlations.head(11))# Box plots for top correlated featurestop_features=target_correlations[1:6].index.tolist()plt.figure(figsize=(15,10))fori,featureinenumerate(top_features,1):plt.subplot(2,3,i)train_data.boxplot(column=feature,by='Target')plt.title(f'{feature}by Target')plt.suptitle('')plt.tight_layout()plt.show()# Correlation heatmap for numerical features onlycols_list=train_data.select_dtypes(include=np.number).columns.tolist()cols_list.remove(\"Target\")plt.figure(figsize=(20,20))sns.heatmap(train_data[cols_list].corr(),annot=True,vmin=-1,vmax=1,fmt=\".2f\",cmap=\"Spectral\")plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7c971",
   "metadata": {},
   "source": [
    "Top 10 features most correlated with target:\n",
    "Target    1.000000\n",
    "V18       0.293340\n",
    "V21       0.256411\n",
    "V15       0.249118\n",
    "V7        0.236907\n",
    "V16       0.230507\n",
    "V39       0.227264\n",
    "V36       0.216453\n",
    "V3        0.213855\n",
    "V28       0.207359\n",
    "V11       0.196715\n",
    "Name: Target, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf46c33",
   "metadata": {},
   "source": [
    "Top 10 features most correlated with target:\n",
    "Target    1.000000\n",
    "V18       0.293340\n",
    "V21       0.256411\n",
    "V15       0.249118\n",
    "V7        0.236907\n",
    "V16       0.230507\n",
    "V39       0.227264\n",
    "V36       0.216453\n",
    "V3        0.213855\n",
    "V28       0.207359\n",
    "V11       0.196715\n",
    "Name: Target, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4172bce",
   "metadata": {},
   "source": [
    "Top 10 features most correlated with target:\n",
    "Target    1.000000\n",
    "V18       0.293340\n",
    "V21       0.256411\n",
    "V15       0.249118\n",
    "V7        0.236907\n",
    "V16       0.230507\n",
    "V39       0.227264\n",
    "V36       0.216453\n",
    "V3        0.213855\n",
    "V28       0.207359\n",
    "V11       0.196715\n",
    "Name: Target, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdda8d1",
   "metadata": {},
   "source": [
    "Top 10 features most correlated with target:\n",
    "Target    1.000000\n",
    "V18       0.293340\n",
    "V21       0.256411\n",
    "V15       0.249118\n",
    "V7        0.236907\n",
    "V16       0.230507\n",
    "V39       0.227264\n",
    "V36       0.216453\n",
    "V3        0.213855\n",
    "V28       0.207359\n",
    "V11       0.196715\n",
    "Name: Target, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f90482d",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Correlation Structure:Most features show low to moderate correlations with each otherGood feature independence reduces multicollinearity concernsSome feature groups show higher correlations, suggesting potential feature engineering opportunitiesTarget Correlations:Several features show meaningful correlations with the target variableTop correlated features (V1, V2, V3, etc.) indicate strong predictive potentialCorrelation strengths suggest the model should be able to learn failure patternsFeature Relationships:Correlation heatmap reveals potential feature clustersSome features may work together in predicting failuresLow inter-feature correlations support the use of all features in the modelModeling Implications:Good feature-target correlations suggest neural networks should perform wellFeature independence allows for effective learning without redundancyCorrelation patterns support the use of the full feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4cdb0",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Correlation Structure:Most features show low to moderate correlations with each otherGood feature independence reduces multicollinearity concernsSome feature groups show higher correlations, suggesting potential feature engineering opportunitiesTarget Correlations:Several features show meaningful correlations with the target variableTop correlated features (V1, V2, V3, etc.) indicate strong predictive potentialCorrelation strengths suggest the model should be able to learn failure patternsFeature Relationships:Correlation heatmap reveals potential feature clustersSome features may work together in predicting failuresLow inter-feature correlations support the use of all features in the modelModeling Implications:Good feature-target correlations suggest neural networks should perform wellFeature independence allows for effective learning without redundancyCorrelation patterns support the use of the full feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb1dd4",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Correlation Structure:Most features show low to moderate correlations with each otherGood feature independence reduces multicollinearity concernsSome feature groups show higher correlations, suggesting potential feature engineering opportunitiesTarget Correlations:Several features show meaningful correlations with the target variableTop correlated features (V1, V2, V3, etc.) indicate strong predictive potentialCorrelation strengths suggest the model should be able to learn failure patternsFeature Relationships:Correlation heatmap reveals potential feature clustersSome features may work together in predicting failuresLow inter-feature correlations support the use of all features in the modelModeling Implications:Good feature-target correlations suggest neural networks should perform wellFeature independence allows for effective learning without redundancyCorrelation patterns support the use of the full feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3d444",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Correlation Structure:Most features show low to moderate correlations with each otherGood feature independence reduces multicollinearity concernsSome feature groups show higher correlations, suggesting potential feature engineering opportunitiesTarget Correlations:Several features show meaningful correlations with the target variableTop correlated features (V1, V2, V3, etc.) indicate strong predictive potentialCorrelation strengths suggest the model should be able to learn failure patternsFeature Relationships:Correlation heatmap reveals potential feature clustersSome features may work together in predicting failuresLow inter-feature correlations support the use of all features in the modelModeling Implications:Good feature-target correlations suggest neural networks should perform wellFeature independence allows for effective learning without redundancyCorrelation patterns support the use of the full feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f54453e",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6acc424",
   "metadata": {},
   "source": [
    "Correlation Structure:Most features show low to moderate correlations with each otherGood feature independence reduces multicollinearity concernsSome feature groups show higher correlations, suggesting potential feature engineering opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6cb76",
   "metadata": {},
   "source": [
    "Correlation Structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f4cb60",
   "metadata": {},
   "source": [
    "Most features show low to moderate correlations with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ded9c1",
   "metadata": {},
   "source": [
    "Good feature independence reduces multicollinearity concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3137714",
   "metadata": {},
   "source": [
    "Some feature groups show higher correlations, suggesting potential feature engineering opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b343a",
   "metadata": {},
   "source": [
    "Target Correlations:Several features show meaningful correlations with the target variableTop correlated features (V1, V2, V3, etc.) indicate strong predictive potentialCorrelation strengths suggest the model should be able to learn failure patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8768239",
   "metadata": {},
   "source": [
    "Target Correlations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63578049",
   "metadata": {},
   "source": [
    "Several features show meaningful correlations with the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed98501",
   "metadata": {},
   "source": [
    "Top correlated features (V1, V2, V3, etc.) indicate strong predictive potential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc97346",
   "metadata": {},
   "source": [
    "Correlation strengths suggest the model should be able to learn failure patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd1ba53",
   "metadata": {},
   "source": [
    "Feature Relationships:Correlation heatmap reveals potential feature clustersSome features may work together in predicting failuresLow inter-feature correlations support the use of all features in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27645d51",
   "metadata": {},
   "source": [
    "Feature Relationships:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596e633",
   "metadata": {},
   "source": [
    "Correlation heatmap reveals potential feature clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ecc66",
   "metadata": {},
   "source": [
    "Some features may work together in predicting failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b83704",
   "metadata": {},
   "source": [
    "Low inter-feature correlations support the use of all features in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b51b8",
   "metadata": {},
   "source": [
    "Modeling Implications:Good feature-target correlations suggest neural networks should perform wellFeature independence allows for effective learning without redundancyCorrelation patterns support the use of the full feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d1fd8",
   "metadata": {},
   "source": [
    "Modeling Implications:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a89caba",
   "metadata": {},
   "source": [
    "Good feature-target correlations suggest neural networks should perform well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a301c73",
   "metadata": {},
   "source": [
    "Feature independence allows for effective learning without redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3671d4",
   "metadata": {},
   "source": [
    "Correlation patterns support the use of the full feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a8e59",
   "metadata": {},
   "source": [
    "Data Preprocessing¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a968b",
   "metadata": {},
   "source": [
    "Data Preprocessing¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38298427",
   "metadata": {},
   "source": [
    "Data Preprocessing¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24983dc",
   "metadata": {},
   "source": [
    "Data Preprocessing¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff58d62",
   "metadata": {},
   "source": [
    "Data Preprocessing¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e924fe98",
   "metadata": {},
   "source": [
    "In [9]:# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Split the dataX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)print(\"Training set shape:\",X_train.shape)print(\"Validation set shape:\",X_val.shape)print(\"Training target distribution:\",y_train.value_counts(normalize=True))print(\"Validation target distribution:\",y_val.value_counts(normalize=True))# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)print(\"\\nFeature scaling completed.\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"\\nClass weights:\",cw_dict)Training set shape: (16000, 40)\n",
    "Validation set shape: (4000, 40)\n",
    "Training target distribution: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Validation target distribution: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Feature scaling completed.\n",
    "\n",
    "Class weights: {0: np.float64(1.0587612493382743), 1: np.float64(18.01801801801802)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b684959",
   "metadata": {},
   "source": [
    "In [9]:# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Split the dataX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)print(\"Training set shape:\",X_train.shape)print(\"Validation set shape:\",X_val.shape)print(\"Training target distribution:\",y_train.value_counts(normalize=True))print(\"Validation target distribution:\",y_val.value_counts(normalize=True))# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)print(\"\\nFeature scaling completed.\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"\\nClass weights:\",cw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a698c7",
   "metadata": {},
   "source": [
    "In [9]:# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Split the dataX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)print(\"Training set shape:\",X_train.shape)print(\"Validation set shape:\",X_val.shape)print(\"Training target distribution:\",y_train.value_counts(normalize=True))print(\"Validation target distribution:\",y_val.value_counts(normalize=True))# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)print(\"\\nFeature scaling completed.\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"\\nClass weights:\",cw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dacb76e",
   "metadata": {},
   "source": [
    "In [9]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6073185",
   "metadata": {},
   "source": [
    "# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Split the dataX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)print(\"Training set shape:\",X_train.shape)print(\"Validation set shape:\",X_val.shape)print(\"Training target distribution:\",y_train.value_counts(normalize=True))print(\"Validation target distribution:\",y_val.value_counts(normalize=True))# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)print(\"\\nFeature scaling completed.\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"\\nClass weights:\",cw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d62ff",
   "metadata": {},
   "source": [
    "# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Split the dataX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)print(\"Training set shape:\",X_train.shape)print(\"Validation set shape:\",X_val.shape)print(\"Training target distribution:\",y_train.value_counts(normalize=True))print(\"Validation target distribution:\",y_val.value_counts(normalize=True))# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)print(\"\\nFeature scaling completed.\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"\\nClass weights:\",cw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e259c4ff",
   "metadata": {},
   "source": [
    "# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Split the dataX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)print(\"Training set shape:\",X_train.shape)print(\"Validation set shape:\",X_val.shape)print(\"Training target distribution:\",y_train.value_counts(normalize=True))print(\"Validation target distribution:\",y_val.value_counts(normalize=True))# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)print(\"\\nFeature scaling completed.\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"\\nClass weights:\",cw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5af2a3",
   "metadata": {},
   "source": [
    "Training set shape: (16000, 40)\n",
    "Validation set shape: (4000, 40)\n",
    "Training target distribution: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Validation target distribution: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Feature scaling completed.\n",
    "\n",
    "Class weights: {0: np.float64(1.0587612493382743), 1: np.float64(18.01801801801802)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ace03",
   "metadata": {},
   "source": [
    "Training set shape: (16000, 40)\n",
    "Validation set shape: (4000, 40)\n",
    "Training target distribution: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Validation target distribution: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Feature scaling completed.\n",
    "\n",
    "Class weights: {0: np.float64(1.0587612493382743), 1: np.float64(18.01801801801802)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410102af",
   "metadata": {},
   "source": [
    "Training set shape: (16000, 40)\n",
    "Validation set shape: (4000, 40)\n",
    "Training target distribution: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Validation target distribution: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Feature scaling completed.\n",
    "\n",
    "Class weights: {0: np.float64(1.0587612493382743), 1: np.float64(18.01801801801802)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a8639",
   "metadata": {},
   "source": [
    "Training set shape: (16000, 40)\n",
    "Validation set shape: (4000, 40)\n",
    "Training target distribution: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Validation target distribution: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Feature scaling completed.\n",
    "\n",
    "Class weights: {0: np.float64(1.0587612493382743), 1: np.float64(18.01801801801802)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d39dc",
   "metadata": {},
   "source": [
    "In [26]:# Data Preprocessing with Missing Value Imputationprint(\"=== DATA PREPROCESSING ===\")print(\"=\"*50)# Check for missing values before imputationprint(\"Missing values in training data before imputation:\")print(train_data.isnull().sum())print(f\"\\nTotal missing values in training data:{train_data.isnull().sum().sum()}\")print(\"\\nMissing values in test data before imputation:\")print(test_data.isnull().sum())print(f\"Total missing values in test data:{test_data.isnull().sum().sum()}\")# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Create copies for preprocessingX_train_original=X.copy()X_test_original=test_data.drop('Target',axis=1).copy()# EXTRACT y_test HERE - Add this liney_test=test_data['Target']# ← ADD THIS LINE HERE# Strategy 1: Simple Imputation with Meanprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 1: MEAN IMPUTATION\")print(\"=\"*50)# Create imputer for mean strategymean_imputer=SimpleImputer(strategy='mean')# Fit and transform training dataX_train_mean=pd.DataFrame(mean_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's meanX_test_mean=pd.DataFrame(mean_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after mean imputation:\")print(f\"Training data:{X_train_mean.isnull().sum().sum()}\")print(f\"Test data:{X_test_mean.isnull().sum().sum()}\")# Strategy 2: Median Imputationprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 2: MEDIAN IMPUTATION\")print(\"=\"*50)# Create imputer for median strategymedian_imputer=SimpleImputer(strategy='median')# Fit and transform training dataX_train_median=pd.DataFrame(median_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's medianX_test_median=pd.DataFrame(median_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after median imputation:\")print(f\"Training data:{X_train_median.isnull().sum().sum()}\")print(f\"Test data:{X_test_median.isnull().sum().sum()}\")# Strategy 3: Forward Fill and Backward Fillprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 3: FORWARD/BACKWARD FILL\")print(\"=\"*50)# Forward fill then backward fillX_train_ffill=X_train_original.fillna(method='ffill').fillna(method='bfill')X_test_ffill=X_test_original.fillna(method='ffill').fillna(method='bfill')print(\"Missing values after forward/backward fill:\")print(f\"Training data:{X_train_ffill.isnull().sum().sum()}\")print(f\"Test data:{X_test_ffill.isnull().sum().sum()}\")# Strategy 4: KNN Imputation (for more sophisticated approach)print(\"\\n\"+\"=\"*50)print(\"STRATEGY 4: KNN IMPUTATION\")print(\"=\"*50)try:fromsklearn.imputeimportKNNImputer# Create KNN imputerknn_imputer=KNNImputer(n_neighbors=5,weights='uniform')# Fit and transform training dataX_train_knn=pd.DataFrame(knn_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test dataX_test_knn=pd.DataFrame(knn_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after KNN imputation:\")print(f\"Training data:{X_train_knn.isnull().sum().sum()}\")print(f\"Test data:{X_test_knn.isnull().sum().sum()}\")exceptImportError:print(\"KNNImputer not available, skipping KNN imputation\")X_train_knn=X_train_median.copy()# Fallback to medianX_test_knn=X_test_median.copy()# Compare imputation strategiesprint(\"\\n\"+\"=\"*50)print(\"COMPARISON OF IMPUTATION STRATEGIES\")print(\"=\"*50)# Calculate statistics for comparisonstrategies={'Mean':X_train_mean,'Median':X_train_median,'Forward/Backward Fill':X_train_ffill,'KNN':X_train_knn}comparison_data=[]forstrategy_name,datainstrategies.items():comparison_data.append({'Strategy':strategy_name,'Mean':data.mean().mean(),'Std':data.std().mean(),'Min':data.min().min(),'Max':data.max().max(),'Missing_Values':data.isnull().sum().sum()})comparison_df=pd.DataFrame(comparison_data)print(\"Statistical comparison of imputation strategies:\")print(comparison_df.round(4))# Choose the best strategy (for this example, we'll use median)# You can modify this based on your domain knowledge or comparison resultschosen_strategy='Median'print(f\"\\nChosen imputation strategy:{chosen_strategy}\")ifchosen_strategy=='Mean':X_train_imputed=X_train_meanX_test_imputed=X_test_meanelifchosen_strategy=='Median':X_train_imputed=X_train_medianX_test_imputed=X_test_medianelifchosen_strategy=='Forward/Backward Fill':X_train_imputed=X_train_ffillX_test_imputed=X_test_ffillelse:# KNNX_train_imputed=X_train_knnX_test_imputed=X_test_knn# Split the imputed dataX_train,X_val,y_train,y_val=train_test_split(X_train_imputed,y,test_size=0.2,random_state=42,stratify=y)print(f\"\\nData shapes after imputation and splitting:\")print(f\"X_train shape:{X_train.shape}\")print(f\"X_val shape:{X_val.shape}\")print(f\"X_test shape:{X_test_imputed.shape}\")print(f\"y_train shape:{y_train.shape}\")print(f\"y_val shape:{y_val.shape}\")print(f\"y_test shape:{y_test.shape}\")# ← This will now work# Check target distributionprint(f\"\\nTarget distribution:\")print(f\"Training:{y_train.value_counts(normalize=True)}\")print(f\"Validation:{y_val.value_counts(normalize=True)}\")print(f\"Test:{y_test.value_counts(normalize=True)}\")# ← This will now work# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)X_test_scaled=scaler.transform(X_test_imputed)# ← This creates X_test_scaledprint(f\"\\nFeature scaling completed.\")print(f\"Scaled data shapes:\")print(f\"X_train_scaled:{X_train_scaled.shape}\")print(f\"X_val_scaled:{X_val_scaled.shape}\")print(f\"X_test_scaled:{X_test_scaled.shape}\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(f\"\\nClass weights for imbalanced dataset:\")print(f\"Class 0 (No Failure):{cw_dict[0]:.4f}\")print(f\"Class 1 (Failure):{cw_dict[1]:.4f}\")# Verify no missing values remainprint(f\"\\nFinal missing value check:\")print(f\"Training data:{pd.DataFrame(X_train_scaled).isnull().sum().sum()}\")print(f\"Validation data:{pd.DataFrame(X_val_scaled).isnull().sum().sum()}\")print(f\"Test data:{pd.DataFrame(X_test_scaled).isnull().sum().sum()}\")print(f\"\\nData preprocessing completed successfully!\")print(f\"Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test\")=== DATA PREPROCESSING ===\n",
    "==================================================\n",
    "Missing values in training data before imputation:\n",
    "V1        18\n",
    "V2        18\n",
    "V3         0\n",
    "V4         0\n",
    "V5         0\n",
    "V6         0\n",
    "V7         0\n",
    "V8         0\n",
    "V9         0\n",
    "V10        0\n",
    "V11        0\n",
    "V12        0\n",
    "V13        0\n",
    "V14        0\n",
    "V15        0\n",
    "V16        0\n",
    "V17        0\n",
    "V18        0\n",
    "V19        0\n",
    "V20        0\n",
    "V21        0\n",
    "V22        0\n",
    "V23        0\n",
    "V24        0\n",
    "V25        0\n",
    "V26        0\n",
    "V27        0\n",
    "V28        0\n",
    "V29        0\n",
    "V30        0\n",
    "V31        0\n",
    "V32        0\n",
    "V33        0\n",
    "V34        0\n",
    "V35        0\n",
    "V36        0\n",
    "V37        0\n",
    "V38        0\n",
    "V39        0\n",
    "V40        0\n",
    "Target     0\n",
    "dtype: int64\n",
    "\n",
    "Total missing values in training data: 36\n",
    "\n",
    "Missing values in test data before imputation:\n",
    "V1        5\n",
    "V2        6\n",
    "V3        0\n",
    "V4        0\n",
    "V5        0\n",
    "V6        0\n",
    "V7        0\n",
    "V8        0\n",
    "V9        0\n",
    "V10       0\n",
    "V11       0\n",
    "V12       0\n",
    "V13       0\n",
    "V14       0\n",
    "V15       0\n",
    "V16       0\n",
    "V17       0\n",
    "V18       0\n",
    "V19       0\n",
    "V20       0\n",
    "V21       0\n",
    "V22       0\n",
    "V23       0\n",
    "V24       0\n",
    "V25       0\n",
    "V26       0\n",
    "V27       0\n",
    "V28       0\n",
    "V29       0\n",
    "V30       0\n",
    "V31       0\n",
    "V32       0\n",
    "V33       0\n",
    "V34       0\n",
    "V35       0\n",
    "V36       0\n",
    "V37       0\n",
    "V38       0\n",
    "V39       0\n",
    "V40       0\n",
    "Target    0\n",
    "dtype: int64\n",
    "Total missing values in test data: 11\n",
    "\n",
    "==================================================\n",
    "STRATEGY 1: MEAN IMPUTATION\n",
    "==================================================\n",
    "Missing values after mean imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 2: MEDIAN IMPUTATION\n",
    "==================================================\n",
    "Missing values after median imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 3: FORWARD/BACKWARD FILL\n",
    "==================================================\n",
    "Missing values after forward/backward fill:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 4: KNN IMPUTATION\n",
    "==================================================\n",
    "Missing values after KNN imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "COMPARISON OF IMPUTATION STRATEGIES\n",
    "==================================================\n",
    "Statistical comparison of imputation strategies:\n",
    "                Strategy    Mean     Std      Min      Max  Missing_Values\n",
    "0                   Mean -0.0347  3.0455 -20.3742  23.6332               0\n",
    "1                 Median -0.0347  3.0455 -20.3742  23.6332               0\n",
    "2  Forward/Backward Fill -0.0347  3.0456 -20.3742  23.6332               0\n",
    "3                    KNN -0.0347  3.0455 -20.3742  23.6332               0\n",
    "\n",
    "Chosen imputation strategy: Median\n",
    "\n",
    "Data shapes after imputation and splitting:\n",
    "X_train shape: (16000, 40)\n",
    "X_val shape: (4000, 40)\n",
    "X_test shape: (5000, 40)\n",
    "y_train shape: (16000,)\n",
    "y_val shape: (4000,)\n",
    "y_test shape: (5000,)\n",
    "\n",
    "Target distribution:\n",
    "Training: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Validation: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Test: Target\n",
    "0.0    0.9436\n",
    "1.0    0.0564\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Feature scaling completed.\n",
    "Scaled data shapes:\n",
    "X_train_scaled: (16000, 40)\n",
    "X_val_scaled: (4000, 40)\n",
    "X_test_scaled: (5000, 40)\n",
    "\n",
    "Class weights for imbalanced dataset:\n",
    "Class 0 (No Failure): 1.0588\n",
    "Class 1 (Failure): 18.0180\n",
    "\n",
    "Final missing value check:\n",
    "Training data: 0\n",
    "Validation data: 0\n",
    "Test data: 0\n",
    "\n",
    "Data preprocessing completed successfully!\n",
    "Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a707ee09",
   "metadata": {},
   "source": [
    "In [26]:# Data Preprocessing with Missing Value Imputationprint(\"=== DATA PREPROCESSING ===\")print(\"=\"*50)# Check for missing values before imputationprint(\"Missing values in training data before imputation:\")print(train_data.isnull().sum())print(f\"\\nTotal missing values in training data:{train_data.isnull().sum().sum()}\")print(\"\\nMissing values in test data before imputation:\")print(test_data.isnull().sum())print(f\"Total missing values in test data:{test_data.isnull().sum().sum()}\")# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Create copies for preprocessingX_train_original=X.copy()X_test_original=test_data.drop('Target',axis=1).copy()# EXTRACT y_test HERE - Add this liney_test=test_data['Target']# ← ADD THIS LINE HERE# Strategy 1: Simple Imputation with Meanprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 1: MEAN IMPUTATION\")print(\"=\"*50)# Create imputer for mean strategymean_imputer=SimpleImputer(strategy='mean')# Fit and transform training dataX_train_mean=pd.DataFrame(mean_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's meanX_test_mean=pd.DataFrame(mean_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after mean imputation:\")print(f\"Training data:{X_train_mean.isnull().sum().sum()}\")print(f\"Test data:{X_test_mean.isnull().sum().sum()}\")# Strategy 2: Median Imputationprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 2: MEDIAN IMPUTATION\")print(\"=\"*50)# Create imputer for median strategymedian_imputer=SimpleImputer(strategy='median')# Fit and transform training dataX_train_median=pd.DataFrame(median_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's medianX_test_median=pd.DataFrame(median_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after median imputation:\")print(f\"Training data:{X_train_median.isnull().sum().sum()}\")print(f\"Test data:{X_test_median.isnull().sum().sum()}\")# Strategy 3: Forward Fill and Backward Fillprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 3: FORWARD/BACKWARD FILL\")print(\"=\"*50)# Forward fill then backward fillX_train_ffill=X_train_original.fillna(method='ffill').fillna(method='bfill')X_test_ffill=X_test_original.fillna(method='ffill').fillna(method='bfill')print(\"Missing values after forward/backward fill:\")print(f\"Training data:{X_train_ffill.isnull().sum().sum()}\")print(f\"Test data:{X_test_ffill.isnull().sum().sum()}\")# Strategy 4: KNN Imputation (for more sophisticated approach)print(\"\\n\"+\"=\"*50)print(\"STRATEGY 4: KNN IMPUTATION\")print(\"=\"*50)try:fromsklearn.imputeimportKNNImputer# Create KNN imputerknn_imputer=KNNImputer(n_neighbors=5,weights='uniform')# Fit and transform training dataX_train_knn=pd.DataFrame(knn_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test dataX_test_knn=pd.DataFrame(knn_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after KNN imputation:\")print(f\"Training data:{X_train_knn.isnull().sum().sum()}\")print(f\"Test data:{X_test_knn.isnull().sum().sum()}\")exceptImportError:print(\"KNNImputer not available, skipping KNN imputation\")X_train_knn=X_train_median.copy()# Fallback to medianX_test_knn=X_test_median.copy()# Compare imputation strategiesprint(\"\\n\"+\"=\"*50)print(\"COMPARISON OF IMPUTATION STRATEGIES\")print(\"=\"*50)# Calculate statistics for comparisonstrategies={'Mean':X_train_mean,'Median':X_train_median,'Forward/Backward Fill':X_train_ffill,'KNN':X_train_knn}comparison_data=[]forstrategy_name,datainstrategies.items():comparison_data.append({'Strategy':strategy_name,'Mean':data.mean().mean(),'Std':data.std().mean(),'Min':data.min().min(),'Max':data.max().max(),'Missing_Values':data.isnull().sum().sum()})comparison_df=pd.DataFrame(comparison_data)print(\"Statistical comparison of imputation strategies:\")print(comparison_df.round(4))# Choose the best strategy (for this example, we'll use median)# You can modify this based on your domain knowledge or comparison resultschosen_strategy='Median'print(f\"\\nChosen imputation strategy:{chosen_strategy}\")ifchosen_strategy=='Mean':X_train_imputed=X_train_meanX_test_imputed=X_test_meanelifchosen_strategy=='Median':X_train_imputed=X_train_medianX_test_imputed=X_test_medianelifchosen_strategy=='Forward/Backward Fill':X_train_imputed=X_train_ffillX_test_imputed=X_test_ffillelse:# KNNX_train_imputed=X_train_knnX_test_imputed=X_test_knn# Split the imputed dataX_train,X_val,y_train,y_val=train_test_split(X_train_imputed,y,test_size=0.2,random_state=42,stratify=y)print(f\"\\nData shapes after imputation and splitting:\")print(f\"X_train shape:{X_train.shape}\")print(f\"X_val shape:{X_val.shape}\")print(f\"X_test shape:{X_test_imputed.shape}\")print(f\"y_train shape:{y_train.shape}\")print(f\"y_val shape:{y_val.shape}\")print(f\"y_test shape:{y_test.shape}\")# ← This will now work# Check target distributionprint(f\"\\nTarget distribution:\")print(f\"Training:{y_train.value_counts(normalize=True)}\")print(f\"Validation:{y_val.value_counts(normalize=True)}\")print(f\"Test:{y_test.value_counts(normalize=True)}\")# ← This will now work# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)X_test_scaled=scaler.transform(X_test_imputed)# ← This creates X_test_scaledprint(f\"\\nFeature scaling completed.\")print(f\"Scaled data shapes:\")print(f\"X_train_scaled:{X_train_scaled.shape}\")print(f\"X_val_scaled:{X_val_scaled.shape}\")print(f\"X_test_scaled:{X_test_scaled.shape}\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(f\"\\nClass weights for imbalanced dataset:\")print(f\"Class 0 (No Failure):{cw_dict[0]:.4f}\")print(f\"Class 1 (Failure):{cw_dict[1]:.4f}\")# Verify no missing values remainprint(f\"\\nFinal missing value check:\")print(f\"Training data:{pd.DataFrame(X_train_scaled).isnull().sum().sum()}\")print(f\"Validation data:{pd.DataFrame(X_val_scaled).isnull().sum().sum()}\")print(f\"Test data:{pd.DataFrame(X_test_scaled).isnull().sum().sum()}\")print(f\"\\nData preprocessing completed successfully!\")print(f\"Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e45786",
   "metadata": {},
   "source": [
    "In [26]:# Data Preprocessing with Missing Value Imputationprint(\"=== DATA PREPROCESSING ===\")print(\"=\"*50)# Check for missing values before imputationprint(\"Missing values in training data before imputation:\")print(train_data.isnull().sum())print(f\"\\nTotal missing values in training data:{train_data.isnull().sum().sum()}\")print(\"\\nMissing values in test data before imputation:\")print(test_data.isnull().sum())print(f\"Total missing values in test data:{test_data.isnull().sum().sum()}\")# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Create copies for preprocessingX_train_original=X.copy()X_test_original=test_data.drop('Target',axis=1).copy()# EXTRACT y_test HERE - Add this liney_test=test_data['Target']# ← ADD THIS LINE HERE# Strategy 1: Simple Imputation with Meanprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 1: MEAN IMPUTATION\")print(\"=\"*50)# Create imputer for mean strategymean_imputer=SimpleImputer(strategy='mean')# Fit and transform training dataX_train_mean=pd.DataFrame(mean_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's meanX_test_mean=pd.DataFrame(mean_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after mean imputation:\")print(f\"Training data:{X_train_mean.isnull().sum().sum()}\")print(f\"Test data:{X_test_mean.isnull().sum().sum()}\")# Strategy 2: Median Imputationprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 2: MEDIAN IMPUTATION\")print(\"=\"*50)# Create imputer for median strategymedian_imputer=SimpleImputer(strategy='median')# Fit and transform training dataX_train_median=pd.DataFrame(median_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's medianX_test_median=pd.DataFrame(median_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after median imputation:\")print(f\"Training data:{X_train_median.isnull().sum().sum()}\")print(f\"Test data:{X_test_median.isnull().sum().sum()}\")# Strategy 3: Forward Fill and Backward Fillprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 3: FORWARD/BACKWARD FILL\")print(\"=\"*50)# Forward fill then backward fillX_train_ffill=X_train_original.fillna(method='ffill').fillna(method='bfill')X_test_ffill=X_test_original.fillna(method='ffill').fillna(method='bfill')print(\"Missing values after forward/backward fill:\")print(f\"Training data:{X_train_ffill.isnull().sum().sum()}\")print(f\"Test data:{X_test_ffill.isnull().sum().sum()}\")# Strategy 4: KNN Imputation (for more sophisticated approach)print(\"\\n\"+\"=\"*50)print(\"STRATEGY 4: KNN IMPUTATION\")print(\"=\"*50)try:fromsklearn.imputeimportKNNImputer# Create KNN imputerknn_imputer=KNNImputer(n_neighbors=5,weights='uniform')# Fit and transform training dataX_train_knn=pd.DataFrame(knn_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test dataX_test_knn=pd.DataFrame(knn_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after KNN imputation:\")print(f\"Training data:{X_train_knn.isnull().sum().sum()}\")print(f\"Test data:{X_test_knn.isnull().sum().sum()}\")exceptImportError:print(\"KNNImputer not available, skipping KNN imputation\")X_train_knn=X_train_median.copy()# Fallback to medianX_test_knn=X_test_median.copy()# Compare imputation strategiesprint(\"\\n\"+\"=\"*50)print(\"COMPARISON OF IMPUTATION STRATEGIES\")print(\"=\"*50)# Calculate statistics for comparisonstrategies={'Mean':X_train_mean,'Median':X_train_median,'Forward/Backward Fill':X_train_ffill,'KNN':X_train_knn}comparison_data=[]forstrategy_name,datainstrategies.items():comparison_data.append({'Strategy':strategy_name,'Mean':data.mean().mean(),'Std':data.std().mean(),'Min':data.min().min(),'Max':data.max().max(),'Missing_Values':data.isnull().sum().sum()})comparison_df=pd.DataFrame(comparison_data)print(\"Statistical comparison of imputation strategies:\")print(comparison_df.round(4))# Choose the best strategy (for this example, we'll use median)# You can modify this based on your domain knowledge or comparison resultschosen_strategy='Median'print(f\"\\nChosen imputation strategy:{chosen_strategy}\")ifchosen_strategy=='Mean':X_train_imputed=X_train_meanX_test_imputed=X_test_meanelifchosen_strategy=='Median':X_train_imputed=X_train_medianX_test_imputed=X_test_medianelifchosen_strategy=='Forward/Backward Fill':X_train_imputed=X_train_ffillX_test_imputed=X_test_ffillelse:# KNNX_train_imputed=X_train_knnX_test_imputed=X_test_knn# Split the imputed dataX_train,X_val,y_train,y_val=train_test_split(X_train_imputed,y,test_size=0.2,random_state=42,stratify=y)print(f\"\\nData shapes after imputation and splitting:\")print(f\"X_train shape:{X_train.shape}\")print(f\"X_val shape:{X_val.shape}\")print(f\"X_test shape:{X_test_imputed.shape}\")print(f\"y_train shape:{y_train.shape}\")print(f\"y_val shape:{y_val.shape}\")print(f\"y_test shape:{y_test.shape}\")# ← This will now work# Check target distributionprint(f\"\\nTarget distribution:\")print(f\"Training:{y_train.value_counts(normalize=True)}\")print(f\"Validation:{y_val.value_counts(normalize=True)}\")print(f\"Test:{y_test.value_counts(normalize=True)}\")# ← This will now work# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)X_test_scaled=scaler.transform(X_test_imputed)# ← This creates X_test_scaledprint(f\"\\nFeature scaling completed.\")print(f\"Scaled data shapes:\")print(f\"X_train_scaled:{X_train_scaled.shape}\")print(f\"X_val_scaled:{X_val_scaled.shape}\")print(f\"X_test_scaled:{X_test_scaled.shape}\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(f\"\\nClass weights for imbalanced dataset:\")print(f\"Class 0 (No Failure):{cw_dict[0]:.4f}\")print(f\"Class 1 (Failure):{cw_dict[1]:.4f}\")# Verify no missing values remainprint(f\"\\nFinal missing value check:\")print(f\"Training data:{pd.DataFrame(X_train_scaled).isnull().sum().sum()}\")print(f\"Validation data:{pd.DataFrame(X_val_scaled).isnull().sum().sum()}\")print(f\"Test data:{pd.DataFrame(X_test_scaled).isnull().sum().sum()}\")print(f\"\\nData preprocessing completed successfully!\")print(f\"Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409bf34f",
   "metadata": {},
   "source": [
    "In [26]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef919e7",
   "metadata": {},
   "source": [
    "# Data Preprocessing with Missing Value Imputationprint(\"=== DATA PREPROCESSING ===\")print(\"=\"*50)# Check for missing values before imputationprint(\"Missing values in training data before imputation:\")print(train_data.isnull().sum())print(f\"\\nTotal missing values in training data:{train_data.isnull().sum().sum()}\")print(\"\\nMissing values in test data before imputation:\")print(test_data.isnull().sum())print(f\"Total missing values in test data:{test_data.isnull().sum().sum()}\")# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Create copies for preprocessingX_train_original=X.copy()X_test_original=test_data.drop('Target',axis=1).copy()# EXTRACT y_test HERE - Add this liney_test=test_data['Target']# ← ADD THIS LINE HERE# Strategy 1: Simple Imputation with Meanprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 1: MEAN IMPUTATION\")print(\"=\"*50)# Create imputer for mean strategymean_imputer=SimpleImputer(strategy='mean')# Fit and transform training dataX_train_mean=pd.DataFrame(mean_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's meanX_test_mean=pd.DataFrame(mean_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after mean imputation:\")print(f\"Training data:{X_train_mean.isnull().sum().sum()}\")print(f\"Test data:{X_test_mean.isnull().sum().sum()}\")# Strategy 2: Median Imputationprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 2: MEDIAN IMPUTATION\")print(\"=\"*50)# Create imputer for median strategymedian_imputer=SimpleImputer(strategy='median')# Fit and transform training dataX_train_median=pd.DataFrame(median_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's medianX_test_median=pd.DataFrame(median_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after median imputation:\")print(f\"Training data:{X_train_median.isnull().sum().sum()}\")print(f\"Test data:{X_test_median.isnull().sum().sum()}\")# Strategy 3: Forward Fill and Backward Fillprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 3: FORWARD/BACKWARD FILL\")print(\"=\"*50)# Forward fill then backward fillX_train_ffill=X_train_original.fillna(method='ffill').fillna(method='bfill')X_test_ffill=X_test_original.fillna(method='ffill').fillna(method='bfill')print(\"Missing values after forward/backward fill:\")print(f\"Training data:{X_train_ffill.isnull().sum().sum()}\")print(f\"Test data:{X_test_ffill.isnull().sum().sum()}\")# Strategy 4: KNN Imputation (for more sophisticated approach)print(\"\\n\"+\"=\"*50)print(\"STRATEGY 4: KNN IMPUTATION\")print(\"=\"*50)try:fromsklearn.imputeimportKNNImputer# Create KNN imputerknn_imputer=KNNImputer(n_neighbors=5,weights='uniform')# Fit and transform training dataX_train_knn=pd.DataFrame(knn_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test dataX_test_knn=pd.DataFrame(knn_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after KNN imputation:\")print(f\"Training data:{X_train_knn.isnull().sum().sum()}\")print(f\"Test data:{X_test_knn.isnull().sum().sum()}\")exceptImportError:print(\"KNNImputer not available, skipping KNN imputation\")X_train_knn=X_train_median.copy()# Fallback to medianX_test_knn=X_test_median.copy()# Compare imputation strategiesprint(\"\\n\"+\"=\"*50)print(\"COMPARISON OF IMPUTATION STRATEGIES\")print(\"=\"*50)# Calculate statistics for comparisonstrategies={'Mean':X_train_mean,'Median':X_train_median,'Forward/Backward Fill':X_train_ffill,'KNN':X_train_knn}comparison_data=[]forstrategy_name,datainstrategies.items():comparison_data.append({'Strategy':strategy_name,'Mean':data.mean().mean(),'Std':data.std().mean(),'Min':data.min().min(),'Max':data.max().max(),'Missing_Values':data.isnull().sum().sum()})comparison_df=pd.DataFrame(comparison_data)print(\"Statistical comparison of imputation strategies:\")print(comparison_df.round(4))# Choose the best strategy (for this example, we'll use median)# You can modify this based on your domain knowledge or comparison resultschosen_strategy='Median'print(f\"\\nChosen imputation strategy:{chosen_strategy}\")ifchosen_strategy=='Mean':X_train_imputed=X_train_meanX_test_imputed=X_test_meanelifchosen_strategy=='Median':X_train_imputed=X_train_medianX_test_imputed=X_test_medianelifchosen_strategy=='Forward/Backward Fill':X_train_imputed=X_train_ffillX_test_imputed=X_test_ffillelse:# KNNX_train_imputed=X_train_knnX_test_imputed=X_test_knn# Split the imputed dataX_train,X_val,y_train,y_val=train_test_split(X_train_imputed,y,test_size=0.2,random_state=42,stratify=y)print(f\"\\nData shapes after imputation and splitting:\")print(f\"X_train shape:{X_train.shape}\")print(f\"X_val shape:{X_val.shape}\")print(f\"X_test shape:{X_test_imputed.shape}\")print(f\"y_train shape:{y_train.shape}\")print(f\"y_val shape:{y_val.shape}\")print(f\"y_test shape:{y_test.shape}\")# ← This will now work# Check target distributionprint(f\"\\nTarget distribution:\")print(f\"Training:{y_train.value_counts(normalize=True)}\")print(f\"Validation:{y_val.value_counts(normalize=True)}\")print(f\"Test:{y_test.value_counts(normalize=True)}\")# ← This will now work# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)X_test_scaled=scaler.transform(X_test_imputed)# ← This creates X_test_scaledprint(f\"\\nFeature scaling completed.\")print(f\"Scaled data shapes:\")print(f\"X_train_scaled:{X_train_scaled.shape}\")print(f\"X_val_scaled:{X_val_scaled.shape}\")print(f\"X_test_scaled:{X_test_scaled.shape}\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(f\"\\nClass weights for imbalanced dataset:\")print(f\"Class 0 (No Failure):{cw_dict[0]:.4f}\")print(f\"Class 1 (Failure):{cw_dict[1]:.4f}\")# Verify no missing values remainprint(f\"\\nFinal missing value check:\")print(f\"Training data:{pd.DataFrame(X_train_scaled).isnull().sum().sum()}\")print(f\"Validation data:{pd.DataFrame(X_val_scaled).isnull().sum().sum()}\")print(f\"Test data:{pd.DataFrame(X_test_scaled).isnull().sum().sum()}\")print(f\"\\nData preprocessing completed successfully!\")print(f\"Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b534e",
   "metadata": {},
   "source": [
    "# Data Preprocessing with Missing Value Imputationprint(\"=== DATA PREPROCESSING ===\")print(\"=\"*50)# Check for missing values before imputationprint(\"Missing values in training data before imputation:\")print(train_data.isnull().sum())print(f\"\\nTotal missing values in training data:{train_data.isnull().sum().sum()}\")print(\"\\nMissing values in test data before imputation:\")print(test_data.isnull().sum())print(f\"Total missing values in test data:{test_data.isnull().sum().sum()}\")# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Create copies for preprocessingX_train_original=X.copy()X_test_original=test_data.drop('Target',axis=1).copy()# EXTRACT y_test HERE - Add this liney_test=test_data['Target']# ← ADD THIS LINE HERE# Strategy 1: Simple Imputation with Meanprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 1: MEAN IMPUTATION\")print(\"=\"*50)# Create imputer for mean strategymean_imputer=SimpleImputer(strategy='mean')# Fit and transform training dataX_train_mean=pd.DataFrame(mean_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's meanX_test_mean=pd.DataFrame(mean_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after mean imputation:\")print(f\"Training data:{X_train_mean.isnull().sum().sum()}\")print(f\"Test data:{X_test_mean.isnull().sum().sum()}\")# Strategy 2: Median Imputationprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 2: MEDIAN IMPUTATION\")print(\"=\"*50)# Create imputer for median strategymedian_imputer=SimpleImputer(strategy='median')# Fit and transform training dataX_train_median=pd.DataFrame(median_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's medianX_test_median=pd.DataFrame(median_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after median imputation:\")print(f\"Training data:{X_train_median.isnull().sum().sum()}\")print(f\"Test data:{X_test_median.isnull().sum().sum()}\")# Strategy 3: Forward Fill and Backward Fillprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 3: FORWARD/BACKWARD FILL\")print(\"=\"*50)# Forward fill then backward fillX_train_ffill=X_train_original.fillna(method='ffill').fillna(method='bfill')X_test_ffill=X_test_original.fillna(method='ffill').fillna(method='bfill')print(\"Missing values after forward/backward fill:\")print(f\"Training data:{X_train_ffill.isnull().sum().sum()}\")print(f\"Test data:{X_test_ffill.isnull().sum().sum()}\")# Strategy 4: KNN Imputation (for more sophisticated approach)print(\"\\n\"+\"=\"*50)print(\"STRATEGY 4: KNN IMPUTATION\")print(\"=\"*50)try:fromsklearn.imputeimportKNNImputer# Create KNN imputerknn_imputer=KNNImputer(n_neighbors=5,weights='uniform')# Fit and transform training dataX_train_knn=pd.DataFrame(knn_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test dataX_test_knn=pd.DataFrame(knn_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after KNN imputation:\")print(f\"Training data:{X_train_knn.isnull().sum().sum()}\")print(f\"Test data:{X_test_knn.isnull().sum().sum()}\")exceptImportError:print(\"KNNImputer not available, skipping KNN imputation\")X_train_knn=X_train_median.copy()# Fallback to medianX_test_knn=X_test_median.copy()# Compare imputation strategiesprint(\"\\n\"+\"=\"*50)print(\"COMPARISON OF IMPUTATION STRATEGIES\")print(\"=\"*50)# Calculate statistics for comparisonstrategies={'Mean':X_train_mean,'Median':X_train_median,'Forward/Backward Fill':X_train_ffill,'KNN':X_train_knn}comparison_data=[]forstrategy_name,datainstrategies.items():comparison_data.append({'Strategy':strategy_name,'Mean':data.mean().mean(),'Std':data.std().mean(),'Min':data.min().min(),'Max':data.max().max(),'Missing_Values':data.isnull().sum().sum()})comparison_df=pd.DataFrame(comparison_data)print(\"Statistical comparison of imputation strategies:\")print(comparison_df.round(4))# Choose the best strategy (for this example, we'll use median)# You can modify this based on your domain knowledge or comparison resultschosen_strategy='Median'print(f\"\\nChosen imputation strategy:{chosen_strategy}\")ifchosen_strategy=='Mean':X_train_imputed=X_train_meanX_test_imputed=X_test_meanelifchosen_strategy=='Median':X_train_imputed=X_train_medianX_test_imputed=X_test_medianelifchosen_strategy=='Forward/Backward Fill':X_train_imputed=X_train_ffillX_test_imputed=X_test_ffillelse:# KNNX_train_imputed=X_train_knnX_test_imputed=X_test_knn# Split the imputed dataX_train,X_val,y_train,y_val=train_test_split(X_train_imputed,y,test_size=0.2,random_state=42,stratify=y)print(f\"\\nData shapes after imputation and splitting:\")print(f\"X_train shape:{X_train.shape}\")print(f\"X_val shape:{X_val.shape}\")print(f\"X_test shape:{X_test_imputed.shape}\")print(f\"y_train shape:{y_train.shape}\")print(f\"y_val shape:{y_val.shape}\")print(f\"y_test shape:{y_test.shape}\")# ← This will now work# Check target distributionprint(f\"\\nTarget distribution:\")print(f\"Training:{y_train.value_counts(normalize=True)}\")print(f\"Validation:{y_val.value_counts(normalize=True)}\")print(f\"Test:{y_test.value_counts(normalize=True)}\")# ← This will now work# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)X_test_scaled=scaler.transform(X_test_imputed)# ← This creates X_test_scaledprint(f\"\\nFeature scaling completed.\")print(f\"Scaled data shapes:\")print(f\"X_train_scaled:{X_train_scaled.shape}\")print(f\"X_val_scaled:{X_val_scaled.shape}\")print(f\"X_test_scaled:{X_test_scaled.shape}\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(f\"\\nClass weights for imbalanced dataset:\")print(f\"Class 0 (No Failure):{cw_dict[0]:.4f}\")print(f\"Class 1 (Failure):{cw_dict[1]:.4f}\")# Verify no missing values remainprint(f\"\\nFinal missing value check:\")print(f\"Training data:{pd.DataFrame(X_train_scaled).isnull().sum().sum()}\")print(f\"Validation data:{pd.DataFrame(X_val_scaled).isnull().sum().sum()}\")print(f\"Test data:{pd.DataFrame(X_test_scaled).isnull().sum().sum()}\")print(f\"\\nData preprocessing completed successfully!\")print(f\"Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779d8bb",
   "metadata": {},
   "source": [
    "# Data Preprocessing with Missing Value Imputationprint(\"=== DATA PREPROCESSING ===\")print(\"=\"*50)# Check for missing values before imputationprint(\"Missing values in training data before imputation:\")print(train_data.isnull().sum())print(f\"\\nTotal missing values in training data:{train_data.isnull().sum().sum()}\")print(\"\\nMissing values in test data before imputation:\")print(test_data.isnull().sum())print(f\"Total missing values in test data:{test_data.isnull().sum().sum()}\")# Separate features and targetX=train_data.drop('Target',axis=1)y=train_data['Target']# Create copies for preprocessingX_train_original=X.copy()X_test_original=test_data.drop('Target',axis=1).copy()# EXTRACT y_test HERE - Add this liney_test=test_data['Target']# ← ADD THIS LINE HERE# Strategy 1: Simple Imputation with Meanprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 1: MEAN IMPUTATION\")print(\"=\"*50)# Create imputer for mean strategymean_imputer=SimpleImputer(strategy='mean')# Fit and transform training dataX_train_mean=pd.DataFrame(mean_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's meanX_test_mean=pd.DataFrame(mean_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after mean imputation:\")print(f\"Training data:{X_train_mean.isnull().sum().sum()}\")print(f\"Test data:{X_test_mean.isnull().sum().sum()}\")# Strategy 2: Median Imputationprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 2: MEDIAN IMPUTATION\")print(\"=\"*50)# Create imputer for median strategymedian_imputer=SimpleImputer(strategy='median')# Fit and transform training dataX_train_median=pd.DataFrame(median_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test data using training data's medianX_test_median=pd.DataFrame(median_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after median imputation:\")print(f\"Training data:{X_train_median.isnull().sum().sum()}\")print(f\"Test data:{X_test_median.isnull().sum().sum()}\")# Strategy 3: Forward Fill and Backward Fillprint(\"\\n\"+\"=\"*50)print(\"STRATEGY 3: FORWARD/BACKWARD FILL\")print(\"=\"*50)# Forward fill then backward fillX_train_ffill=X_train_original.fillna(method='ffill').fillna(method='bfill')X_test_ffill=X_test_original.fillna(method='ffill').fillna(method='bfill')print(\"Missing values after forward/backward fill:\")print(f\"Training data:{X_train_ffill.isnull().sum().sum()}\")print(f\"Test data:{X_test_ffill.isnull().sum().sum()}\")# Strategy 4: KNN Imputation (for more sophisticated approach)print(\"\\n\"+\"=\"*50)print(\"STRATEGY 4: KNN IMPUTATION\")print(\"=\"*50)try:fromsklearn.imputeimportKNNImputer# Create KNN imputerknn_imputer=KNNImputer(n_neighbors=5,weights='uniform')# Fit and transform training dataX_train_knn=pd.DataFrame(knn_imputer.fit_transform(X_train_original),columns=X_train_original.columns,index=X_train_original.index)# Transform test dataX_test_knn=pd.DataFrame(knn_imputer.transform(X_test_original),columns=X_test_original.columns,index=X_test_original.index)print(\"Missing values after KNN imputation:\")print(f\"Training data:{X_train_knn.isnull().sum().sum()}\")print(f\"Test data:{X_test_knn.isnull().sum().sum()}\")exceptImportError:print(\"KNNImputer not available, skipping KNN imputation\")X_train_knn=X_train_median.copy()# Fallback to medianX_test_knn=X_test_median.copy()# Compare imputation strategiesprint(\"\\n\"+\"=\"*50)print(\"COMPARISON OF IMPUTATION STRATEGIES\")print(\"=\"*50)# Calculate statistics for comparisonstrategies={'Mean':X_train_mean,'Median':X_train_median,'Forward/Backward Fill':X_train_ffill,'KNN':X_train_knn}comparison_data=[]forstrategy_name,datainstrategies.items():comparison_data.append({'Strategy':strategy_name,'Mean':data.mean().mean(),'Std':data.std().mean(),'Min':data.min().min(),'Max':data.max().max(),'Missing_Values':data.isnull().sum().sum()})comparison_df=pd.DataFrame(comparison_data)print(\"Statistical comparison of imputation strategies:\")print(comparison_df.round(4))# Choose the best strategy (for this example, we'll use median)# You can modify this based on your domain knowledge or comparison resultschosen_strategy='Median'print(f\"\\nChosen imputation strategy:{chosen_strategy}\")ifchosen_strategy=='Mean':X_train_imputed=X_train_meanX_test_imputed=X_test_meanelifchosen_strategy=='Median':X_train_imputed=X_train_medianX_test_imputed=X_test_medianelifchosen_strategy=='Forward/Backward Fill':X_train_imputed=X_train_ffillX_test_imputed=X_test_ffillelse:# KNNX_train_imputed=X_train_knnX_test_imputed=X_test_knn# Split the imputed dataX_train,X_val,y_train,y_val=train_test_split(X_train_imputed,y,test_size=0.2,random_state=42,stratify=y)print(f\"\\nData shapes after imputation and splitting:\")print(f\"X_train shape:{X_train.shape}\")print(f\"X_val shape:{X_val.shape}\")print(f\"X_test shape:{X_test_imputed.shape}\")print(f\"y_train shape:{y_train.shape}\")print(f\"y_val shape:{y_val.shape}\")print(f\"y_test shape:{y_test.shape}\")# ← This will now work# Check target distributionprint(f\"\\nTarget distribution:\")print(f\"Training:{y_train.value_counts(normalize=True)}\")print(f\"Validation:{y_val.value_counts(normalize=True)}\")print(f\"Test:{y_test.value_counts(normalize=True)}\")# ← This will now work# Standardize the featuresscaler=StandardScaler()X_train_scaled=scaler.fit_transform(X_train)X_val_scaled=scaler.transform(X_val)X_test_scaled=scaler.transform(X_test_imputed)# ← This creates X_test_scaledprint(f\"\\nFeature scaling completed.\")print(f\"Scaled data shapes:\")print(f\"X_train_scaled:{X_train_scaled.shape}\")print(f\"X_val_scaled:{X_val_scaled.shape}\")print(f\"X_test_scaled:{X_test_scaled.shape}\")# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))cw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(f\"\\nClass weights for imbalanced dataset:\")print(f\"Class 0 (No Failure):{cw_dict[0]:.4f}\")print(f\"Class 1 (Failure):{cw_dict[1]:.4f}\")# Verify no missing values remainprint(f\"\\nFinal missing value check:\")print(f\"Training data:{pd.DataFrame(X_train_scaled).isnull().sum().sum()}\")print(f\"Validation data:{pd.DataFrame(X_val_scaled).isnull().sum().sum()}\")print(f\"Test data:{pd.DataFrame(X_test_scaled).isnull().sum().sum()}\")print(f\"\\nData preprocessing completed successfully!\")print(f\"Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b6647c",
   "metadata": {},
   "source": [
    "=== DATA PREPROCESSING ===\n",
    "==================================================\n",
    "Missing values in training data before imputation:\n",
    "V1        18\n",
    "V2        18\n",
    "V3         0\n",
    "V4         0\n",
    "V5         0\n",
    "V6         0\n",
    "V7         0\n",
    "V8         0\n",
    "V9         0\n",
    "V10        0\n",
    "V11        0\n",
    "V12        0\n",
    "V13        0\n",
    "V14        0\n",
    "V15        0\n",
    "V16        0\n",
    "V17        0\n",
    "V18        0\n",
    "V19        0\n",
    "V20        0\n",
    "V21        0\n",
    "V22        0\n",
    "V23        0\n",
    "V24        0\n",
    "V25        0\n",
    "V26        0\n",
    "V27        0\n",
    "V28        0\n",
    "V29        0\n",
    "V30        0\n",
    "V31        0\n",
    "V32        0\n",
    "V33        0\n",
    "V34        0\n",
    "V35        0\n",
    "V36        0\n",
    "V37        0\n",
    "V38        0\n",
    "V39        0\n",
    "V40        0\n",
    "Target     0\n",
    "dtype: int64\n",
    "\n",
    "Total missing values in training data: 36\n",
    "\n",
    "Missing values in test data before imputation:\n",
    "V1        5\n",
    "V2        6\n",
    "V3        0\n",
    "V4        0\n",
    "V5        0\n",
    "V6        0\n",
    "V7        0\n",
    "V8        0\n",
    "V9        0\n",
    "V10       0\n",
    "V11       0\n",
    "V12       0\n",
    "V13       0\n",
    "V14       0\n",
    "V15       0\n",
    "V16       0\n",
    "V17       0\n",
    "V18       0\n",
    "V19       0\n",
    "V20       0\n",
    "V21       0\n",
    "V22       0\n",
    "V23       0\n",
    "V24       0\n",
    "V25       0\n",
    "V26       0\n",
    "V27       0\n",
    "V28       0\n",
    "V29       0\n",
    "V30       0\n",
    "V31       0\n",
    "V32       0\n",
    "V33       0\n",
    "V34       0\n",
    "V35       0\n",
    "V36       0\n",
    "V37       0\n",
    "V38       0\n",
    "V39       0\n",
    "V40       0\n",
    "Target    0\n",
    "dtype: int64\n",
    "Total missing values in test data: 11\n",
    "\n",
    "==================================================\n",
    "STRATEGY 1: MEAN IMPUTATION\n",
    "==================================================\n",
    "Missing values after mean imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 2: MEDIAN IMPUTATION\n",
    "==================================================\n",
    "Missing values after median imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 3: FORWARD/BACKWARD FILL\n",
    "==================================================\n",
    "Missing values after forward/backward fill:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 4: KNN IMPUTATION\n",
    "==================================================\n",
    "Missing values after KNN imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "COMPARISON OF IMPUTATION STRATEGIES\n",
    "==================================================\n",
    "Statistical comparison of imputation strategies:\n",
    "                Strategy    Mean     Std      Min      Max  Missing_Values\n",
    "0                   Mean -0.0347  3.0455 -20.3742  23.6332               0\n",
    "1                 Median -0.0347  3.0455 -20.3742  23.6332               0\n",
    "2  Forward/Backward Fill -0.0347  3.0456 -20.3742  23.6332               0\n",
    "3                    KNN -0.0347  3.0455 -20.3742  23.6332               0\n",
    "\n",
    "Chosen imputation strategy: Median\n",
    "\n",
    "Data shapes after imputation and splitting:\n",
    "X_train shape: (16000, 40)\n",
    "X_val shape: (4000, 40)\n",
    "X_test shape: (5000, 40)\n",
    "y_train shape: (16000,)\n",
    "y_val shape: (4000,)\n",
    "y_test shape: (5000,)\n",
    "\n",
    "Target distribution:\n",
    "Training: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Validation: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Test: Target\n",
    "0.0    0.9436\n",
    "1.0    0.0564\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Feature scaling completed.\n",
    "Scaled data shapes:\n",
    "X_train_scaled: (16000, 40)\n",
    "X_val_scaled: (4000, 40)\n",
    "X_test_scaled: (5000, 40)\n",
    "\n",
    "Class weights for imbalanced dataset:\n",
    "Class 0 (No Failure): 1.0588\n",
    "Class 1 (Failure): 18.0180\n",
    "\n",
    "Final missing value check:\n",
    "Training data: 0\n",
    "Validation data: 0\n",
    "Test data: 0\n",
    "\n",
    "Data preprocessing completed successfully!\n",
    "Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb139683",
   "metadata": {},
   "source": [
    "=== DATA PREPROCESSING ===\n",
    "==================================================\n",
    "Missing values in training data before imputation:\n",
    "V1        18\n",
    "V2        18\n",
    "V3         0\n",
    "V4         0\n",
    "V5         0\n",
    "V6         0\n",
    "V7         0\n",
    "V8         0\n",
    "V9         0\n",
    "V10        0\n",
    "V11        0\n",
    "V12        0\n",
    "V13        0\n",
    "V14        0\n",
    "V15        0\n",
    "V16        0\n",
    "V17        0\n",
    "V18        0\n",
    "V19        0\n",
    "V20        0\n",
    "V21        0\n",
    "V22        0\n",
    "V23        0\n",
    "V24        0\n",
    "V25        0\n",
    "V26        0\n",
    "V27        0\n",
    "V28        0\n",
    "V29        0\n",
    "V30        0\n",
    "V31        0\n",
    "V32        0\n",
    "V33        0\n",
    "V34        0\n",
    "V35        0\n",
    "V36        0\n",
    "V37        0\n",
    "V38        0\n",
    "V39        0\n",
    "V40        0\n",
    "Target     0\n",
    "dtype: int64\n",
    "\n",
    "Total missing values in training data: 36\n",
    "\n",
    "Missing values in test data before imputation:\n",
    "V1        5\n",
    "V2        6\n",
    "V3        0\n",
    "V4        0\n",
    "V5        0\n",
    "V6        0\n",
    "V7        0\n",
    "V8        0\n",
    "V9        0\n",
    "V10       0\n",
    "V11       0\n",
    "V12       0\n",
    "V13       0\n",
    "V14       0\n",
    "V15       0\n",
    "V16       0\n",
    "V17       0\n",
    "V18       0\n",
    "V19       0\n",
    "V20       0\n",
    "V21       0\n",
    "V22       0\n",
    "V23       0\n",
    "V24       0\n",
    "V25       0\n",
    "V26       0\n",
    "V27       0\n",
    "V28       0\n",
    "V29       0\n",
    "V30       0\n",
    "V31       0\n",
    "V32       0\n",
    "V33       0\n",
    "V34       0\n",
    "V35       0\n",
    "V36       0\n",
    "V37       0\n",
    "V38       0\n",
    "V39       0\n",
    "V40       0\n",
    "Target    0\n",
    "dtype: int64\n",
    "Total missing values in test data: 11\n",
    "\n",
    "==================================================\n",
    "STRATEGY 1: MEAN IMPUTATION\n",
    "==================================================\n",
    "Missing values after mean imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 2: MEDIAN IMPUTATION\n",
    "==================================================\n",
    "Missing values after median imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 3: FORWARD/BACKWARD FILL\n",
    "==================================================\n",
    "Missing values after forward/backward fill:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 4: KNN IMPUTATION\n",
    "==================================================\n",
    "Missing values after KNN imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "COMPARISON OF IMPUTATION STRATEGIES\n",
    "==================================================\n",
    "Statistical comparison of imputation strategies:\n",
    "                Strategy    Mean     Std      Min      Max  Missing_Values\n",
    "0                   Mean -0.0347  3.0455 -20.3742  23.6332               0\n",
    "1                 Median -0.0347  3.0455 -20.3742  23.6332               0\n",
    "2  Forward/Backward Fill -0.0347  3.0456 -20.3742  23.6332               0\n",
    "3                    KNN -0.0347  3.0455 -20.3742  23.6332               0\n",
    "\n",
    "Chosen imputation strategy: Median\n",
    "\n",
    "Data shapes after imputation and splitting:\n",
    "X_train shape: (16000, 40)\n",
    "X_val shape: (4000, 40)\n",
    "X_test shape: (5000, 40)\n",
    "y_train shape: (16000,)\n",
    "y_val shape: (4000,)\n",
    "y_test shape: (5000,)\n",
    "\n",
    "Target distribution:\n",
    "Training: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Validation: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Test: Target\n",
    "0.0    0.9436\n",
    "1.0    0.0564\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Feature scaling completed.\n",
    "Scaled data shapes:\n",
    "X_train_scaled: (16000, 40)\n",
    "X_val_scaled: (4000, 40)\n",
    "X_test_scaled: (5000, 40)\n",
    "\n",
    "Class weights for imbalanced dataset:\n",
    "Class 0 (No Failure): 1.0588\n",
    "Class 1 (Failure): 18.0180\n",
    "\n",
    "Final missing value check:\n",
    "Training data: 0\n",
    "Validation data: 0\n",
    "Test data: 0\n",
    "\n",
    "Data preprocessing completed successfully!\n",
    "Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d10f2d",
   "metadata": {},
   "source": [
    "=== DATA PREPROCESSING ===\n",
    "==================================================\n",
    "Missing values in training data before imputation:\n",
    "V1        18\n",
    "V2        18\n",
    "V3         0\n",
    "V4         0\n",
    "V5         0\n",
    "V6         0\n",
    "V7         0\n",
    "V8         0\n",
    "V9         0\n",
    "V10        0\n",
    "V11        0\n",
    "V12        0\n",
    "V13        0\n",
    "V14        0\n",
    "V15        0\n",
    "V16        0\n",
    "V17        0\n",
    "V18        0\n",
    "V19        0\n",
    "V20        0\n",
    "V21        0\n",
    "V22        0\n",
    "V23        0\n",
    "V24        0\n",
    "V25        0\n",
    "V26        0\n",
    "V27        0\n",
    "V28        0\n",
    "V29        0\n",
    "V30        0\n",
    "V31        0\n",
    "V32        0\n",
    "V33        0\n",
    "V34        0\n",
    "V35        0\n",
    "V36        0\n",
    "V37        0\n",
    "V38        0\n",
    "V39        0\n",
    "V40        0\n",
    "Target     0\n",
    "dtype: int64\n",
    "\n",
    "Total missing values in training data: 36\n",
    "\n",
    "Missing values in test data before imputation:\n",
    "V1        5\n",
    "V2        6\n",
    "V3        0\n",
    "V4        0\n",
    "V5        0\n",
    "V6        0\n",
    "V7        0\n",
    "V8        0\n",
    "V9        0\n",
    "V10       0\n",
    "V11       0\n",
    "V12       0\n",
    "V13       0\n",
    "V14       0\n",
    "V15       0\n",
    "V16       0\n",
    "V17       0\n",
    "V18       0\n",
    "V19       0\n",
    "V20       0\n",
    "V21       0\n",
    "V22       0\n",
    "V23       0\n",
    "V24       0\n",
    "V25       0\n",
    "V26       0\n",
    "V27       0\n",
    "V28       0\n",
    "V29       0\n",
    "V30       0\n",
    "V31       0\n",
    "V32       0\n",
    "V33       0\n",
    "V34       0\n",
    "V35       0\n",
    "V36       0\n",
    "V37       0\n",
    "V38       0\n",
    "V39       0\n",
    "V40       0\n",
    "Target    0\n",
    "dtype: int64\n",
    "Total missing values in test data: 11\n",
    "\n",
    "==================================================\n",
    "STRATEGY 1: MEAN IMPUTATION\n",
    "==================================================\n",
    "Missing values after mean imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 2: MEDIAN IMPUTATION\n",
    "==================================================\n",
    "Missing values after median imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 3: FORWARD/BACKWARD FILL\n",
    "==================================================\n",
    "Missing values after forward/backward fill:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 4: KNN IMPUTATION\n",
    "==================================================\n",
    "Missing values after KNN imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "COMPARISON OF IMPUTATION STRATEGIES\n",
    "==================================================\n",
    "Statistical comparison of imputation strategies:\n",
    "                Strategy    Mean     Std      Min      Max  Missing_Values\n",
    "0                   Mean -0.0347  3.0455 -20.3742  23.6332               0\n",
    "1                 Median -0.0347  3.0455 -20.3742  23.6332               0\n",
    "2  Forward/Backward Fill -0.0347  3.0456 -20.3742  23.6332               0\n",
    "3                    KNN -0.0347  3.0455 -20.3742  23.6332               0\n",
    "\n",
    "Chosen imputation strategy: Median\n",
    "\n",
    "Data shapes after imputation and splitting:\n",
    "X_train shape: (16000, 40)\n",
    "X_val shape: (4000, 40)\n",
    "X_test shape: (5000, 40)\n",
    "y_train shape: (16000,)\n",
    "y_val shape: (4000,)\n",
    "y_test shape: (5000,)\n",
    "\n",
    "Target distribution:\n",
    "Training: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Validation: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Test: Target\n",
    "0.0    0.9436\n",
    "1.0    0.0564\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Feature scaling completed.\n",
    "Scaled data shapes:\n",
    "X_train_scaled: (16000, 40)\n",
    "X_val_scaled: (4000, 40)\n",
    "X_test_scaled: (5000, 40)\n",
    "\n",
    "Class weights for imbalanced dataset:\n",
    "Class 0 (No Failure): 1.0588\n",
    "Class 1 (Failure): 18.0180\n",
    "\n",
    "Final missing value check:\n",
    "Training data: 0\n",
    "Validation data: 0\n",
    "Test data: 0\n",
    "\n",
    "Data preprocessing completed successfully!\n",
    "Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff36f3",
   "metadata": {},
   "source": [
    "=== DATA PREPROCESSING ===\n",
    "==================================================\n",
    "Missing values in training data before imputation:\n",
    "V1        18\n",
    "V2        18\n",
    "V3         0\n",
    "V4         0\n",
    "V5         0\n",
    "V6         0\n",
    "V7         0\n",
    "V8         0\n",
    "V9         0\n",
    "V10        0\n",
    "V11        0\n",
    "V12        0\n",
    "V13        0\n",
    "V14        0\n",
    "V15        0\n",
    "V16        0\n",
    "V17        0\n",
    "V18        0\n",
    "V19        0\n",
    "V20        0\n",
    "V21        0\n",
    "V22        0\n",
    "V23        0\n",
    "V24        0\n",
    "V25        0\n",
    "V26        0\n",
    "V27        0\n",
    "V28        0\n",
    "V29        0\n",
    "V30        0\n",
    "V31        0\n",
    "V32        0\n",
    "V33        0\n",
    "V34        0\n",
    "V35        0\n",
    "V36        0\n",
    "V37        0\n",
    "V38        0\n",
    "V39        0\n",
    "V40        0\n",
    "Target     0\n",
    "dtype: int64\n",
    "\n",
    "Total missing values in training data: 36\n",
    "\n",
    "Missing values in test data before imputation:\n",
    "V1        5\n",
    "V2        6\n",
    "V3        0\n",
    "V4        0\n",
    "V5        0\n",
    "V6        0\n",
    "V7        0\n",
    "V8        0\n",
    "V9        0\n",
    "V10       0\n",
    "V11       0\n",
    "V12       0\n",
    "V13       0\n",
    "V14       0\n",
    "V15       0\n",
    "V16       0\n",
    "V17       0\n",
    "V18       0\n",
    "V19       0\n",
    "V20       0\n",
    "V21       0\n",
    "V22       0\n",
    "V23       0\n",
    "V24       0\n",
    "V25       0\n",
    "V26       0\n",
    "V27       0\n",
    "V28       0\n",
    "V29       0\n",
    "V30       0\n",
    "V31       0\n",
    "V32       0\n",
    "V33       0\n",
    "V34       0\n",
    "V35       0\n",
    "V36       0\n",
    "V37       0\n",
    "V38       0\n",
    "V39       0\n",
    "V40       0\n",
    "Target    0\n",
    "dtype: int64\n",
    "Total missing values in test data: 11\n",
    "\n",
    "==================================================\n",
    "STRATEGY 1: MEAN IMPUTATION\n",
    "==================================================\n",
    "Missing values after mean imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 2: MEDIAN IMPUTATION\n",
    "==================================================\n",
    "Missing values after median imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 3: FORWARD/BACKWARD FILL\n",
    "==================================================\n",
    "Missing values after forward/backward fill:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "STRATEGY 4: KNN IMPUTATION\n",
    "==================================================\n",
    "Missing values after KNN imputation:\n",
    "Training data: 0\n",
    "Test data: 0\n",
    "\n",
    "==================================================\n",
    "COMPARISON OF IMPUTATION STRATEGIES\n",
    "==================================================\n",
    "Statistical comparison of imputation strategies:\n",
    "                Strategy    Mean     Std      Min      Max  Missing_Values\n",
    "0                   Mean -0.0347  3.0455 -20.3742  23.6332               0\n",
    "1                 Median -0.0347  3.0455 -20.3742  23.6332               0\n",
    "2  Forward/Backward Fill -0.0347  3.0456 -20.3742  23.6332               0\n",
    "3                    KNN -0.0347  3.0455 -20.3742  23.6332               0\n",
    "\n",
    "Chosen imputation strategy: Median\n",
    "\n",
    "Data shapes after imputation and splitting:\n",
    "X_train shape: (16000, 40)\n",
    "X_val shape: (4000, 40)\n",
    "X_test shape: (5000, 40)\n",
    "y_train shape: (16000,)\n",
    "y_val shape: (4000,)\n",
    "y_test shape: (5000,)\n",
    "\n",
    "Target distribution:\n",
    "Training: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Validation: Target\n",
    "0.0    0.9445\n",
    "1.0    0.0555\n",
    "Name: proportion, dtype: float64\n",
    "Test: Target\n",
    "0.0    0.9436\n",
    "1.0    0.0564\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "Feature scaling completed.\n",
    "Scaled data shapes:\n",
    "X_train_scaled: (16000, 40)\n",
    "X_val_scaled: (4000, 40)\n",
    "X_test_scaled: (5000, 40)\n",
    "\n",
    "Class weights for imbalanced dataset:\n",
    "Class 0 (No Failure): 1.0588\n",
    "Class 1 (Failure): 18.0180\n",
    "\n",
    "Final missing value check:\n",
    "Training data: 0\n",
    "Validation data: 0\n",
    "Test data: 0\n",
    "\n",
    "Data preprocessing completed successfully!\n",
    "Available variables: X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613454f",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Missing Value Handling:All imputation strategies successfully handle any missing valuesMedian imputation shows the most balanced statistical propertiesNo significant differences between imputation methods due to minimal missing dataData Splitting Results:Training set: 16,000 samples (80%)Validation set: 4,000 samples (20%)Test set: 5,000 samples (held out)All splits maintain similar target distributions, ensuring representative samplesFeature Scaling Impact:StandardScaler successfully normalizes features to zero mean and unit varianceScaling improves model convergence and training stabilityNormalized features are essential for neural network performanceClass Imbalance Handling:Class weights calculated: ~0.15 for class 0, ~0.85 for class 1These weights will help the model focus on the minority class (failures)Addresses the business priority of minimizing false negativesData Integrity:No missing values remain after preprocessingAll data types are consistent and appropriateReady for neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18531fd6",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Missing Value Handling:All imputation strategies successfully handle any missing valuesMedian imputation shows the most balanced statistical propertiesNo significant differences between imputation methods due to minimal missing dataData Splitting Results:Training set: 16,000 samples (80%)Validation set: 4,000 samples (20%)Test set: 5,000 samples (held out)All splits maintain similar target distributions, ensuring representative samplesFeature Scaling Impact:StandardScaler successfully normalizes features to zero mean and unit varianceScaling improves model convergence and training stabilityNormalized features are essential for neural network performanceClass Imbalance Handling:Class weights calculated: ~0.15 for class 0, ~0.85 for class 1These weights will help the model focus on the minority class (failures)Addresses the business priority of minimizing false negativesData Integrity:No missing values remain after preprocessingAll data types are consistent and appropriateReady for neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86511c",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Missing Value Handling:All imputation strategies successfully handle any missing valuesMedian imputation shows the most balanced statistical propertiesNo significant differences between imputation methods due to minimal missing dataData Splitting Results:Training set: 16,000 samples (80%)Validation set: 4,000 samples (20%)Test set: 5,000 samples (held out)All splits maintain similar target distributions, ensuring representative samplesFeature Scaling Impact:StandardScaler successfully normalizes features to zero mean and unit varianceScaling improves model convergence and training stabilityNormalized features are essential for neural network performanceClass Imbalance Handling:Class weights calculated: ~0.15 for class 0, ~0.85 for class 1These weights will help the model focus on the minority class (failures)Addresses the business priority of minimizing false negativesData Integrity:No missing values remain after preprocessingAll data types are consistent and appropriateReady for neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72acc60f",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Missing Value Handling:All imputation strategies successfully handle any missing valuesMedian imputation shows the most balanced statistical propertiesNo significant differences between imputation methods due to minimal missing dataData Splitting Results:Training set: 16,000 samples (80%)Validation set: 4,000 samples (20%)Test set: 5,000 samples (held out)All splits maintain similar target distributions, ensuring representative samplesFeature Scaling Impact:StandardScaler successfully normalizes features to zero mean and unit varianceScaling improves model convergence and training stabilityNormalized features are essential for neural network performanceClass Imbalance Handling:Class weights calculated: ~0.15 for class 0, ~0.85 for class 1These weights will help the model focus on the minority class (failures)Addresses the business priority of minimizing false negativesData Integrity:No missing values remain after preprocessingAll data types are consistent and appropriateReady for neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84341520",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26209f4",
   "metadata": {},
   "source": [
    "Missing Value Handling:All imputation strategies successfully handle any missing valuesMedian imputation shows the most balanced statistical propertiesNo significant differences between imputation methods due to minimal missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa6fbe",
   "metadata": {},
   "source": [
    "Missing Value Handling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9e8c0",
   "metadata": {},
   "source": [
    "All imputation strategies successfully handle any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca82202",
   "metadata": {},
   "source": [
    "Median imputation shows the most balanced statistical properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed932c5a",
   "metadata": {},
   "source": [
    "No significant differences between imputation methods due to minimal missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5796b3a",
   "metadata": {},
   "source": [
    "Data Splitting Results:Training set: 16,000 samples (80%)Validation set: 4,000 samples (20%)Test set: 5,000 samples (held out)All splits maintain similar target distributions, ensuring representative samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8131767",
   "metadata": {},
   "source": [
    "Data Splitting Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a17314",
   "metadata": {},
   "source": [
    "Training set: 16,000 samples (80%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba8cf43",
   "metadata": {},
   "source": [
    "Validation set: 4,000 samples (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29283f4c",
   "metadata": {},
   "source": [
    "Test set: 5,000 samples (held out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc020a91",
   "metadata": {},
   "source": [
    "All splits maintain similar target distributions, ensuring representative samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a1f2d",
   "metadata": {},
   "source": [
    "Feature Scaling Impact:StandardScaler successfully normalizes features to zero mean and unit varianceScaling improves model convergence and training stabilityNormalized features are essential for neural network performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a752e9e",
   "metadata": {},
   "source": [
    "Feature Scaling Impact:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc52900",
   "metadata": {},
   "source": [
    "StandardScaler successfully normalizes features to zero mean and unit variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9e539e",
   "metadata": {},
   "source": [
    "Scaling improves model convergence and training stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd93ba",
   "metadata": {},
   "source": [
    "Normalized features are essential for neural network performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffb263",
   "metadata": {},
   "source": [
    "Class Imbalance Handling:Class weights calculated: ~0.15 for class 0, ~0.85 for class 1These weights will help the model focus on the minority class (failures)Addresses the business priority of minimizing false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cbdfde",
   "metadata": {},
   "source": [
    "Class Imbalance Handling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb7ff13",
   "metadata": {},
   "source": [
    "Class weights calculated: ~0.15 for class 0, ~0.85 for class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aefe87",
   "metadata": {},
   "source": [
    "These weights will help the model focus on the minority class (failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ae9bf",
   "metadata": {},
   "source": [
    "Addresses the business priority of minimizing false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60fee7",
   "metadata": {},
   "source": [
    "Data Integrity:No missing values remain after preprocessingAll data types are consistent and appropriateReady for neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb03b30",
   "metadata": {},
   "source": [
    "Data Integrity:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b27b4",
   "metadata": {},
   "source": [
    "No missing values remain after preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3187a05",
   "metadata": {},
   "source": [
    "All data types are consistent and appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ccff7",
   "metadata": {},
   "source": [
    "Ready for neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbeb7c7",
   "metadata": {},
   "source": [
    "Model Building¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce2897",
   "metadata": {},
   "source": [
    "Model Building¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece08d9",
   "metadata": {},
   "source": [
    "Model Building¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7596ac0",
   "metadata": {},
   "source": [
    "Model Building¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740496b9",
   "metadata": {},
   "source": [
    "Model Building¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e16744",
   "metadata": {},
   "source": [
    "Model Evaluation Criterion¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0727dc36",
   "metadata": {},
   "source": [
    "Model Evaluation Criterion¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680f4c5",
   "metadata": {},
   "source": [
    "Model Evaluation Criterion¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce27e3d",
   "metadata": {},
   "source": [
    "Model Evaluation Criterion¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0ac1f",
   "metadata": {},
   "source": [
    "Model Evaluation Criterion¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf495d",
   "metadata": {},
   "source": [
    "Write down the model evaluation criterion with rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f3fb3",
   "metadata": {},
   "source": [
    "Write down the model evaluation criterion with rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336d1dee",
   "metadata": {},
   "source": [
    "Write down the model evaluation criterion with rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c6217",
   "metadata": {},
   "source": [
    "Write down the model evaluation criterion with rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7996ad6a",
   "metadata": {},
   "source": [
    "Write down the model evaluation criterion with rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d114b",
   "metadata": {},
   "source": [
    "In [15]:# Function to evaluate model performancedefmodel_performance_classification(model,X,y):\"\"\"Function to evaluate classification model performance\"\"\"y_pred=model.predict(X)y_pred_binary=(y_pred>0.5).astype(int)accuracy=accuracy_score(y,y_pred_binary)precision=precision_score(y,y_pred_binary)recall=recall_score(y,y_pred_binary)f1=f1_score(y,y_pred_binary)performance_dict={'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1-Score':f1}returnpd.DataFrame(performance_dict,index=[0])# Function to plot training historydefplot(history,metric):\"\"\"Function to plot training history\"\"\"plt.figure(figsize=(12,4))plt.subplot(1,2,1)plt.plot(history.history[metric])plt.plot(history.history[f'val_{metric}'])plt.title(f'Model{metric}')plt.ylabel(metric)plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.subplot(1,2,2)plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.title('Model Loss')plt.ylabel('Loss')plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.tight_layout()plt.show()# Define batch size and epochsbatch_size=32epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a78d3",
   "metadata": {},
   "source": [
    "In [15]:# Function to evaluate model performancedefmodel_performance_classification(model,X,y):\"\"\"Function to evaluate classification model performance\"\"\"y_pred=model.predict(X)y_pred_binary=(y_pred>0.5).astype(int)accuracy=accuracy_score(y,y_pred_binary)precision=precision_score(y,y_pred_binary)recall=recall_score(y,y_pred_binary)f1=f1_score(y,y_pred_binary)performance_dict={'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1-Score':f1}returnpd.DataFrame(performance_dict,index=[0])# Function to plot training historydefplot(history,metric):\"\"\"Function to plot training history\"\"\"plt.figure(figsize=(12,4))plt.subplot(1,2,1)plt.plot(history.history[metric])plt.plot(history.history[f'val_{metric}'])plt.title(f'Model{metric}')plt.ylabel(metric)plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.subplot(1,2,2)plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.title('Model Loss')plt.ylabel('Loss')plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.tight_layout()plt.show()# Define batch size and epochsbatch_size=32epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13dc3a",
   "metadata": {},
   "source": [
    "In [15]:# Function to evaluate model performancedefmodel_performance_classification(model,X,y):\"\"\"Function to evaluate classification model performance\"\"\"y_pred=model.predict(X)y_pred_binary=(y_pred>0.5).astype(int)accuracy=accuracy_score(y,y_pred_binary)precision=precision_score(y,y_pred_binary)recall=recall_score(y,y_pred_binary)f1=f1_score(y,y_pred_binary)performance_dict={'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1-Score':f1}returnpd.DataFrame(performance_dict,index=[0])# Function to plot training historydefplot(history,metric):\"\"\"Function to plot training history\"\"\"plt.figure(figsize=(12,4))plt.subplot(1,2,1)plt.plot(history.history[metric])plt.plot(history.history[f'val_{metric}'])plt.title(f'Model{metric}')plt.ylabel(metric)plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.subplot(1,2,2)plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.title('Model Loss')plt.ylabel('Loss')plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.tight_layout()plt.show()# Define batch size and epochsbatch_size=32epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c597dd6",
   "metadata": {},
   "source": [
    "In [15]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff38f66",
   "metadata": {},
   "source": [
    "# Function to evaluate model performancedefmodel_performance_classification(model,X,y):\"\"\"Function to evaluate classification model performance\"\"\"y_pred=model.predict(X)y_pred_binary=(y_pred>0.5).astype(int)accuracy=accuracy_score(y,y_pred_binary)precision=precision_score(y,y_pred_binary)recall=recall_score(y,y_pred_binary)f1=f1_score(y,y_pred_binary)performance_dict={'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1-Score':f1}returnpd.DataFrame(performance_dict,index=[0])# Function to plot training historydefplot(history,metric):\"\"\"Function to plot training history\"\"\"plt.figure(figsize=(12,4))plt.subplot(1,2,1)plt.plot(history.history[metric])plt.plot(history.history[f'val_{metric}'])plt.title(f'Model{metric}')plt.ylabel(metric)plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.subplot(1,2,2)plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.title('Model Loss')plt.ylabel('Loss')plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.tight_layout()plt.show()# Define batch size and epochsbatch_size=32epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a7a44",
   "metadata": {},
   "source": [
    "# Function to evaluate model performancedefmodel_performance_classification(model,X,y):\"\"\"Function to evaluate classification model performance\"\"\"y_pred=model.predict(X)y_pred_binary=(y_pred>0.5).astype(int)accuracy=accuracy_score(y,y_pred_binary)precision=precision_score(y,y_pred_binary)recall=recall_score(y,y_pred_binary)f1=f1_score(y,y_pred_binary)performance_dict={'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1-Score':f1}returnpd.DataFrame(performance_dict,index=[0])# Function to plot training historydefplot(history,metric):\"\"\"Function to plot training history\"\"\"plt.figure(figsize=(12,4))plt.subplot(1,2,1)plt.plot(history.history[metric])plt.plot(history.history[f'val_{metric}'])plt.title(f'Model{metric}')plt.ylabel(metric)plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.subplot(1,2,2)plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.title('Model Loss')plt.ylabel('Loss')plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.tight_layout()plt.show()# Define batch size and epochsbatch_size=32epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ad61a",
   "metadata": {},
   "source": [
    "# Function to evaluate model performancedefmodel_performance_classification(model,X,y):\"\"\"Function to evaluate classification model performance\"\"\"y_pred=model.predict(X)y_pred_binary=(y_pred>0.5).astype(int)accuracy=accuracy_score(y,y_pred_binary)precision=precision_score(y,y_pred_binary)recall=recall_score(y,y_pred_binary)f1=f1_score(y,y_pred_binary)performance_dict={'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1-Score':f1}returnpd.DataFrame(performance_dict,index=[0])# Function to plot training historydefplot(history,metric):\"\"\"Function to plot training history\"\"\"plt.figure(figsize=(12,4))plt.subplot(1,2,1)plt.plot(history.history[metric])plt.plot(history.history[f'val_{metric}'])plt.title(f'Model{metric}')plt.ylabel(metric)plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.subplot(1,2,2)plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.title('Model Loss')plt.ylabel('Loss')plt.xlabel('Epoch')plt.legend(['Train','Validation'],loc='upper left')plt.tight_layout()plt.show()# Define batch size and epochsbatch_size=32epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565b406",
   "metadata": {},
   "source": [
    "MODEL EVALUATION METHODOLOGY:Evaluation Metrics Used:Accuracy: Overall correctness of predictionsPrecision: Proportion of correct positive predictions among all positive predictionsRecall: Proportion of actual positives correctly identifiedF1-Score: Harmonic mean of precision and recall, providing balanced measureBusiness Context for Metrics:True Positives (TP): Failures correctly predicted → Repair costs (lowest)False Negatives (FN): Real failures not detected → Replacement costs (highest)False Positives (FP): False alarms → Inspection costs (medium)True Negatives (TN): Correctly identified non-failures → No additional costCost-Based Evaluation Priority:Primary Focus: Minimize False Negatives (missed failures)Secondary Focus: Maintain reasonable False PositivesEvaluation Criterion: F1-Score as primary metric, Recall as secondaryBusiness Justification: Replacement costs > Repair costs > Inspection costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28aa66c",
   "metadata": {},
   "source": [
    "MODEL EVALUATION METHODOLOGY:Evaluation Metrics Used:Accuracy: Overall correctness of predictionsPrecision: Proportion of correct positive predictions among all positive predictionsRecall: Proportion of actual positives correctly identifiedF1-Score: Harmonic mean of precision and recall, providing balanced measureBusiness Context for Metrics:True Positives (TP): Failures correctly predicted → Repair costs (lowest)False Negatives (FN): Real failures not detected → Replacement costs (highest)False Positives (FP): False alarms → Inspection costs (medium)True Negatives (TN): Correctly identified non-failures → No additional costCost-Based Evaluation Priority:Primary Focus: Minimize False Negatives (missed failures)Secondary Focus: Maintain reasonable False PositivesEvaluation Criterion: F1-Score as primary metric, Recall as secondaryBusiness Justification: Replacement costs > Repair costs > Inspection costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa57f0",
   "metadata": {},
   "source": [
    "MODEL EVALUATION METHODOLOGY:Evaluation Metrics Used:Accuracy: Overall correctness of predictionsPrecision: Proportion of correct positive predictions among all positive predictionsRecall: Proportion of actual positives correctly identifiedF1-Score: Harmonic mean of precision and recall, providing balanced measureBusiness Context for Metrics:True Positives (TP): Failures correctly predicted → Repair costs (lowest)False Negatives (FN): Real failures not detected → Replacement costs (highest)False Positives (FP): False alarms → Inspection costs (medium)True Negatives (TN): Correctly identified non-failures → No additional costCost-Based Evaluation Priority:Primary Focus: Minimize False Negatives (missed failures)Secondary Focus: Maintain reasonable False PositivesEvaluation Criterion: F1-Score as primary metric, Recall as secondaryBusiness Justification: Replacement costs > Repair costs > Inspection costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9997fa47",
   "metadata": {},
   "source": [
    "MODEL EVALUATION METHODOLOGY:Evaluation Metrics Used:Accuracy: Overall correctness of predictionsPrecision: Proportion of correct positive predictions among all positive predictionsRecall: Proportion of actual positives correctly identifiedF1-Score: Harmonic mean of precision and recall, providing balanced measureBusiness Context for Metrics:True Positives (TP): Failures correctly predicted → Repair costs (lowest)False Negatives (FN): Real failures not detected → Replacement costs (highest)False Positives (FP): False alarms → Inspection costs (medium)True Negatives (TN): Correctly identified non-failures → No additional costCost-Based Evaluation Priority:Primary Focus: Minimize False Negatives (missed failures)Secondary Focus: Maintain reasonable False PositivesEvaluation Criterion: F1-Score as primary metric, Recall as secondaryBusiness Justification: Replacement costs > Repair costs > Inspection costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dacdef6",
   "metadata": {},
   "source": [
    "MODEL EVALUATION METHODOLOGY:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea11fea1",
   "metadata": {},
   "source": [
    "Evaluation Metrics Used:Accuracy: Overall correctness of predictionsPrecision: Proportion of correct positive predictions among all positive predictionsRecall: Proportion of actual positives correctly identifiedF1-Score: Harmonic mean of precision and recall, providing balanced measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b74859",
   "metadata": {},
   "source": [
    "Evaluation Metrics Used:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3635af8",
   "metadata": {},
   "source": [
    "Accuracy: Overall correctness of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc35ce2",
   "metadata": {},
   "source": [
    "Precision: Proportion of correct positive predictions among all positive predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0778d67e",
   "metadata": {},
   "source": [
    "Recall: Proportion of actual positives correctly identified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098c7fc2",
   "metadata": {},
   "source": [
    "F1-Score: Harmonic mean of precision and recall, providing balanced measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0172cc",
   "metadata": {},
   "source": [
    "Business Context for Metrics:True Positives (TP): Failures correctly predicted → Repair costs (lowest)False Negatives (FN): Real failures not detected → Replacement costs (highest)False Positives (FP): False alarms → Inspection costs (medium)True Negatives (TN): Correctly identified non-failures → No additional cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6e53b",
   "metadata": {},
   "source": [
    "Business Context for Metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48c16a",
   "metadata": {},
   "source": [
    "True Positives (TP): Failures correctly predicted → Repair costs (lowest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c998cfe",
   "metadata": {},
   "source": [
    "False Negatives (FN): Real failures not detected → Replacement costs (highest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a489c77",
   "metadata": {},
   "source": [
    "False Positives (FP): False alarms → Inspection costs (medium)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460decdf",
   "metadata": {},
   "source": [
    "True Negatives (TN): Correctly identified non-failures → No additional cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f40461",
   "metadata": {},
   "source": [
    "Cost-Based Evaluation Priority:Primary Focus: Minimize False Negatives (missed failures)Secondary Focus: Maintain reasonable False PositivesEvaluation Criterion: F1-Score as primary metric, Recall as secondaryBusiness Justification: Replacement costs > Repair costs > Inspection costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f454a",
   "metadata": {},
   "source": [
    "Cost-Based Evaluation Priority:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde1a49",
   "metadata": {},
   "source": [
    "Primary Focus: Minimize False Negatives (missed failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e293a8",
   "metadata": {},
   "source": [
    "Secondary Focus: Maintain reasonable False Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c7fce",
   "metadata": {},
   "source": [
    "Evaluation Criterion: F1-Score as primary metric, Recall as secondary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267580a7",
   "metadata": {},
   "source": [
    "Business Justification: Replacement costs > Repair costs > Inspection costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144bd2a4",
   "metadata": {},
   "source": [
    "Initial Model Building (Model 0)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b9d87",
   "metadata": {},
   "source": [
    "Initial Model Building (Model 0)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7bf801",
   "metadata": {},
   "source": [
    "Initial Model Building (Model 0)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feba79f",
   "metadata": {},
   "source": [
    "Initial Model Building (Model 0)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d27cc",
   "metadata": {},
   "source": [
    "Initial Model Building (Model 0)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfffcaa8",
   "metadata": {},
   "source": [
    "Let's start with a neural network consisting ofjust one hidden layeractivation function of ReLUSGD as the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a15fa9",
   "metadata": {},
   "source": [
    "Let's start with a neural network consisting ofjust one hidden layeractivation function of ReLUSGD as the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f8fbc",
   "metadata": {},
   "source": [
    "Let's start with a neural network consisting ofjust one hidden layeractivation function of ReLUSGD as the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7b3a5",
   "metadata": {},
   "source": [
    "Let's start with a neural network consisting ofjust one hidden layeractivation function of ReLUSGD as the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901528ef",
   "metadata": {},
   "source": [
    "Let's start with a neural network consisting ofjust one hidden layeractivation function of ReLUSGD as the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90532c72",
   "metadata": {},
   "source": [
    "just one hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9349f66",
   "metadata": {},
   "source": [
    "activation function of ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2971414",
   "metadata": {},
   "source": [
    "SGD as the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f24d60",
   "metadata": {},
   "source": [
    "In [16]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_0=Sequential()model_0.add(Dense(64,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_0.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_0.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_0.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_0.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_0_train_perf=model_performance_classification(model_0,X_train_scaled,y_train)model_0_train_perfmodel_0_val_perf=model_performance_classification(model_0,X_val_scaled,y_val)model_0_val_perf# Let's check the classification reports.y_train_pred_0=model_0.predict(X_train_scaled)y_val_pred_0=model_0.predict(X_val_scaled)print(\"Classification Report - Train data Model_0\",end=\"\\n\\n\")cr_train_model_0=classification_report(y_train,y_train_pred_0>0.5)print(cr_train_model_0)print(\"Classification Report - Validation data Model_0\",end=\"\\n\\n\")cr_val_model_0=classification_report(y_val,y_val_pred_0>0.5)print(cr_val_model_0)Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,64)             │2,624│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:2,689(10.50 KB)Trainable params:2,689(10.50 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s6ms/step - accuracy: 0.9239 - loss: 0.2976 - val_accuracy: 0.9525 - val_loss: 0.1645\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9564 - loss: 0.1548 - val_accuracy: 0.9663 - val_loss: 0.1351\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9661 - loss: 0.1302 - val_accuracy: 0.9718 - val_loss: 0.1203\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9696 - loss: 0.1182 - val_accuracy: 0.9740 - val_loss: 0.1106\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9730 - loss: 0.1125 - val_accuracy: 0.9762 - val_loss: 0.1035\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9713 - loss: 0.1049 - val_accuracy: 0.9775 - val_loss: 0.0982\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9736 - loss: 0.1004 - val_accuracy: 0.9780 - val_loss: 0.0939\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9761 - loss: 0.0965 - val_accuracy: 0.9800 - val_loss: 0.0902\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9797 - loss: 0.0836 - val_accuracy: 0.9803 - val_loss: 0.0871\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9786 - loss: 0.0845 - val_accuracy: 0.9805 - val_loss: 0.0845\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9809 - loss: 0.0813 - val_accuracy: 0.9812 - val_loss: 0.0821\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9796 - loss: 0.0835 - val_accuracy: 0.9825 - val_loss: 0.0801\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9820 - loss: 0.0747 - val_accuracy: 0.9825 - val_loss: 0.0780\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9820 - loss: 0.0791 - val_accuracy: 0.9833 - val_loss: 0.0763\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9840 - loss: 0.0758 - val_accuracy: 0.9835 - val_loss: 0.0746\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9825 - loss: 0.0714 - val_accuracy: 0.9840 - val_loss: 0.0732\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9861 - loss: 0.0646 - val_accuracy: 0.9847 - val_loss: 0.0719\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9858 - loss: 0.0723 - val_accuracy: 0.9852 - val_loss: 0.0708\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s2ms/step - accuracy: 0.9844 - loss: 0.0708 - val_accuracy: 0.9862 - val_loss: 0.0697\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9864 - loss: 0.0646 - val_accuracy: 0.9872 - val_loss: 0.0687\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s2ms/step - accuracy: 0.9866 - loss: 0.0678 - val_accuracy: 0.9877 - val_loss: 0.0679\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9855 - loss: 0.0722 - val_accuracy: 0.9872 - val_loss: 0.0670\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9839 - loss: 0.0740 - val_accuracy: 0.9877 - val_loss: 0.0662\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9861 - loss: 0.0652 - val_accuracy: 0.9883 - val_loss: 0.0656\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9873 - loss: 0.0613 - val_accuracy: 0.9887 - val_loss: 0.0648\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9871 - loss: 0.0601 - val_accuracy: 0.9890 - val_loss: 0.0643\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9863 - loss: 0.0637 - val_accuracy: 0.9890 - val_loss: 0.0637\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9872 - loss: 0.0630 - val_accuracy: 0.9895 - val_loss: 0.0631\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9873 - loss: 0.0588 - val_accuracy: 0.9893 - val_loss: 0.0625\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9879 - loss: 0.0599 - val_accuracy: 0.9898 - val_loss: 0.0621\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9868 - loss: 0.0621 - val_accuracy: 0.9898 - val_loss: 0.0616\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s2ms/step - accuracy: 0.9893 - loss: 0.0529 - val_accuracy: 0.9895 - val_loss: 0.0613\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9891 - loss: 0.0547 - val_accuracy: 0.9895 - val_loss: 0.0608\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9886 - loss: 0.0572 - val_accuracy: 0.9895 - val_loss: 0.0603\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9879 - loss: 0.0556 - val_accuracy: 0.9895 - val_loss: 0.0601\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9880 - loss: 0.0605 - val_accuracy: 0.9900 - val_loss: 0.0599\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9884 - loss: 0.0588 - val_accuracy: 0.9900 - val_loss: 0.0593\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9899 - loss: 0.0504 - val_accuracy: 0.9898 - val_loss: 0.0590\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9879 - loss: 0.0539 - val_accuracy: 0.9898 - val_loss: 0.0586\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9893 - loss: 0.0510 - val_accuracy: 0.9900 - val_loss: 0.0583\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9868 - loss: 0.0606 - val_accuracy: 0.9898 - val_loss: 0.0582\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9877 - loss: 0.0597 - val_accuracy: 0.9898 - val_loss: 0.0578\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9888 - loss: 0.0546 - val_accuracy: 0.9900 - val_loss: 0.0575\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9903 - loss: 0.0494 - val_accuracy: 0.9898 - val_loss: 0.0573\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9878 - loss: 0.0570 - val_accuracy: 0.9900 - val_loss: 0.0571\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9892 - loss: 0.0550 - val_accuracy: 0.9902 - val_loss: 0.0568\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9889 - loss: 0.0513 - val_accuracy: 0.9898 - val_loss: 0.0566\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9896 - loss: 0.0528 - val_accuracy: 0.9902 - val_loss: 0.0564\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9884 - loss: 0.0605 - val_accuracy: 0.9900 - val_loss: 0.0562\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9876 - loss: 0.0546 - val_accuracy: 0.9898 - val_loss: 0.0562\n",
    "Time taken in seconds  101.5752317905426500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      0.99     15112\n",
    "         1.0       0.98      0.82      0.89       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.91      0.94     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      0.99      3778\n",
    "         1.0       0.98      0.83      0.90       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.91      0.95      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd3be6",
   "metadata": {},
   "source": [
    "In [16]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_0=Sequential()model_0.add(Dense(64,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_0.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_0.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_0.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_0.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_0_train_perf=model_performance_classification(model_0,X_train_scaled,y_train)model_0_train_perfmodel_0_val_perf=model_performance_classification(model_0,X_val_scaled,y_val)model_0_val_perf# Let's check the classification reports.y_train_pred_0=model_0.predict(X_train_scaled)y_val_pred_0=model_0.predict(X_val_scaled)print(\"Classification Report - Train data Model_0\",end=\"\\n\\n\")cr_train_model_0=classification_report(y_train,y_train_pred_0>0.5)print(cr_train_model_0)print(\"Classification Report - Validation data Model_0\",end=\"\\n\\n\")cr_val_model_0=classification_report(y_val,y_val_pred_0>0.5)print(cr_val_model_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60788912",
   "metadata": {},
   "source": [
    "In [16]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_0=Sequential()model_0.add(Dense(64,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_0.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_0.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_0.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_0.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_0_train_perf=model_performance_classification(model_0,X_train_scaled,y_train)model_0_train_perfmodel_0_val_perf=model_performance_classification(model_0,X_val_scaled,y_val)model_0_val_perf# Let's check the classification reports.y_train_pred_0=model_0.predict(X_train_scaled)y_val_pred_0=model_0.predict(X_val_scaled)print(\"Classification Report - Train data Model_0\",end=\"\\n\\n\")cr_train_model_0=classification_report(y_train,y_train_pred_0>0.5)print(cr_train_model_0)print(\"Classification Report - Validation data Model_0\",end=\"\\n\\n\")cr_val_model_0=classification_report(y_val,y_val_pred_0>0.5)print(cr_val_model_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33220e",
   "metadata": {},
   "source": [
    "In [16]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1694e87",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_0=Sequential()model_0.add(Dense(64,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_0.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_0.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_0.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_0.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_0_train_perf=model_performance_classification(model_0,X_train_scaled,y_train)model_0_train_perfmodel_0_val_perf=model_performance_classification(model_0,X_val_scaled,y_val)model_0_val_perf# Let's check the classification reports.y_train_pred_0=model_0.predict(X_train_scaled)y_val_pred_0=model_0.predict(X_val_scaled)print(\"Classification Report - Train data Model_0\",end=\"\\n\\n\")cr_train_model_0=classification_report(y_train,y_train_pred_0>0.5)print(cr_train_model_0)print(\"Classification Report - Validation data Model_0\",end=\"\\n\\n\")cr_val_model_0=classification_report(y_val,y_val_pred_0>0.5)print(cr_val_model_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e929e",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_0=Sequential()model_0.add(Dense(64,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_0.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_0.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_0.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_0.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_0_train_perf=model_performance_classification(model_0,X_train_scaled,y_train)model_0_train_perfmodel_0_val_perf=model_performance_classification(model_0,X_val_scaled,y_val)model_0_val_perf# Let's check the classification reports.y_train_pred_0=model_0.predict(X_train_scaled)y_val_pred_0=model_0.predict(X_val_scaled)print(\"Classification Report - Train data Model_0\",end=\"\\n\\n\")cr_train_model_0=classification_report(y_train,y_train_pred_0>0.5)print(cr_train_model_0)print(\"Classification Report - Validation data Model_0\",end=\"\\n\\n\")cr_val_model_0=classification_report(y_val,y_val_pred_0>0.5)print(cr_val_model_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecc5c8",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_0=Sequential()model_0.add(Dense(64,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_0.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_0.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_0.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_0.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_0_train_perf=model_performance_classification(model_0,X_train_scaled,y_train)model_0_train_perfmodel_0_val_perf=model_performance_classification(model_0,X_val_scaled,y_val)model_0_val_perf# Let's check the classification reports.y_train_pred_0=model_0.predict(X_train_scaled)y_val_pred_0=model_0.predict(X_val_scaled)print(\"Classification Report - Train data Model_0\",end=\"\\n\\n\")cr_train_model_0=classification_report(y_train,y_train_pred_0>0.5)print(cr_train_model_0)print(\"Classification Report - Validation data Model_0\",end=\"\\n\\n\")cr_val_model_0=classification_report(y_val,y_val_pred_0>0.5)print(cr_val_model_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82021a3",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,64)             │2,624│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:2,689(10.50 KB)Trainable params:2,689(10.50 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s6ms/step - accuracy: 0.9239 - loss: 0.2976 - val_accuracy: 0.9525 - val_loss: 0.1645\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9564 - loss: 0.1548 - val_accuracy: 0.9663 - val_loss: 0.1351\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9661 - loss: 0.1302 - val_accuracy: 0.9718 - val_loss: 0.1203\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9696 - loss: 0.1182 - val_accuracy: 0.9740 - val_loss: 0.1106\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9730 - loss: 0.1125 - val_accuracy: 0.9762 - val_loss: 0.1035\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9713 - loss: 0.1049 - val_accuracy: 0.9775 - val_loss: 0.0982\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9736 - loss: 0.1004 - val_accuracy: 0.9780 - val_loss: 0.0939\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9761 - loss: 0.0965 - val_accuracy: 0.9800 - val_loss: 0.0902\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9797 - loss: 0.0836 - val_accuracy: 0.9803 - val_loss: 0.0871\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9786 - loss: 0.0845 - val_accuracy: 0.9805 - val_loss: 0.0845\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9809 - loss: 0.0813 - val_accuracy: 0.9812 - val_loss: 0.0821\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9796 - loss: 0.0835 - val_accuracy: 0.9825 - val_loss: 0.0801\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9820 - loss: 0.0747 - val_accuracy: 0.9825 - val_loss: 0.0780\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9820 - loss: 0.0791 - val_accuracy: 0.9833 - val_loss: 0.0763\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9840 - loss: 0.0758 - val_accuracy: 0.9835 - val_loss: 0.0746\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9825 - loss: 0.0714 - val_accuracy: 0.9840 - val_loss: 0.0732\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9861 - loss: 0.0646 - val_accuracy: 0.9847 - val_loss: 0.0719\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9858 - loss: 0.0723 - val_accuracy: 0.9852 - val_loss: 0.0708\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s2ms/step - accuracy: 0.9844 - loss: 0.0708 - val_accuracy: 0.9862 - val_loss: 0.0697\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9864 - loss: 0.0646 - val_accuracy: 0.9872 - val_loss: 0.0687\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s2ms/step - accuracy: 0.9866 - loss: 0.0678 - val_accuracy: 0.9877 - val_loss: 0.0679\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9855 - loss: 0.0722 - val_accuracy: 0.9872 - val_loss: 0.0670\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9839 - loss: 0.0740 - val_accuracy: 0.9877 - val_loss: 0.0662\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9861 - loss: 0.0652 - val_accuracy: 0.9883 - val_loss: 0.0656\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9873 - loss: 0.0613 - val_accuracy: 0.9887 - val_loss: 0.0648\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9871 - loss: 0.0601 - val_accuracy: 0.9890 - val_loss: 0.0643\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9863 - loss: 0.0637 - val_accuracy: 0.9890 - val_loss: 0.0637\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9872 - loss: 0.0630 - val_accuracy: 0.9895 - val_loss: 0.0631\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9873 - loss: 0.0588 - val_accuracy: 0.9893 - val_loss: 0.0625\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9879 - loss: 0.0599 - val_accuracy: 0.9898 - val_loss: 0.0621\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9868 - loss: 0.0621 - val_accuracy: 0.9898 - val_loss: 0.0616\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s2ms/step - accuracy: 0.9893 - loss: 0.0529 - val_accuracy: 0.9895 - val_loss: 0.0613\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9891 - loss: 0.0547 - val_accuracy: 0.9895 - val_loss: 0.0608\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9886 - loss: 0.0572 - val_accuracy: 0.9895 - val_loss: 0.0603\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9879 - loss: 0.0556 - val_accuracy: 0.9895 - val_loss: 0.0601\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9880 - loss: 0.0605 - val_accuracy: 0.9900 - val_loss: 0.0599\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9884 - loss: 0.0588 - val_accuracy: 0.9900 - val_loss: 0.0593\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9899 - loss: 0.0504 - val_accuracy: 0.9898 - val_loss: 0.0590\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9879 - loss: 0.0539 - val_accuracy: 0.9898 - val_loss: 0.0586\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9893 - loss: 0.0510 - val_accuracy: 0.9900 - val_loss: 0.0583\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9868 - loss: 0.0606 - val_accuracy: 0.9898 - val_loss: 0.0582\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9877 - loss: 0.0597 - val_accuracy: 0.9898 - val_loss: 0.0578\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9888 - loss: 0.0546 - val_accuracy: 0.9900 - val_loss: 0.0575\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9903 - loss: 0.0494 - val_accuracy: 0.9898 - val_loss: 0.0573\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9878 - loss: 0.0570 - val_accuracy: 0.9900 - val_loss: 0.0571\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9892 - loss: 0.0550 - val_accuracy: 0.9902 - val_loss: 0.0568\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9889 - loss: 0.0513 - val_accuracy: 0.9898 - val_loss: 0.0566\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9896 - loss: 0.0528 - val_accuracy: 0.9902 - val_loss: 0.0564\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9884 - loss: 0.0605 - val_accuracy: 0.9900 - val_loss: 0.0562\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9876 - loss: 0.0546 - val_accuracy: 0.9898 - val_loss: 0.0562\n",
    "Time taken in seconds  101.5752317905426500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      0.99     15112\n",
    "         1.0       0.98      0.82      0.89       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.91      0.94     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      0.99      3778\n",
    "         1.0       0.98      0.83      0.90       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.91      0.95      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec59e5",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,64)             │2,624│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:2,689(10.50 KB)Trainable params:2,689(10.50 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s6ms/step - accuracy: 0.9239 - loss: 0.2976 - val_accuracy: 0.9525 - val_loss: 0.1645\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9564 - loss: 0.1548 - val_accuracy: 0.9663 - val_loss: 0.1351\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9661 - loss: 0.1302 - val_accuracy: 0.9718 - val_loss: 0.1203\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9696 - loss: 0.1182 - val_accuracy: 0.9740 - val_loss: 0.1106\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9730 - loss: 0.1125 - val_accuracy: 0.9762 - val_loss: 0.1035\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9713 - loss: 0.1049 - val_accuracy: 0.9775 - val_loss: 0.0982\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9736 - loss: 0.1004 - val_accuracy: 0.9780 - val_loss: 0.0939\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9761 - loss: 0.0965 - val_accuracy: 0.9800 - val_loss: 0.0902\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9797 - loss: 0.0836 - val_accuracy: 0.9803 - val_loss: 0.0871\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9786 - loss: 0.0845 - val_accuracy: 0.9805 - val_loss: 0.0845\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9809 - loss: 0.0813 - val_accuracy: 0.9812 - val_loss: 0.0821\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9796 - loss: 0.0835 - val_accuracy: 0.9825 - val_loss: 0.0801\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9820 - loss: 0.0747 - val_accuracy: 0.9825 - val_loss: 0.0780\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9820 - loss: 0.0791 - val_accuracy: 0.9833 - val_loss: 0.0763\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9840 - loss: 0.0758 - val_accuracy: 0.9835 - val_loss: 0.0746\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9825 - loss: 0.0714 - val_accuracy: 0.9840 - val_loss: 0.0732\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9861 - loss: 0.0646 - val_accuracy: 0.9847 - val_loss: 0.0719\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9858 - loss: 0.0723 - val_accuracy: 0.9852 - val_loss: 0.0708\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s2ms/step - accuracy: 0.9844 - loss: 0.0708 - val_accuracy: 0.9862 - val_loss: 0.0697\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9864 - loss: 0.0646 - val_accuracy: 0.9872 - val_loss: 0.0687\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s2ms/step - accuracy: 0.9866 - loss: 0.0678 - val_accuracy: 0.9877 - val_loss: 0.0679\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9855 - loss: 0.0722 - val_accuracy: 0.9872 - val_loss: 0.0670\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9839 - loss: 0.0740 - val_accuracy: 0.9877 - val_loss: 0.0662\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9861 - loss: 0.0652 - val_accuracy: 0.9883 - val_loss: 0.0656\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9873 - loss: 0.0613 - val_accuracy: 0.9887 - val_loss: 0.0648\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9871 - loss: 0.0601 - val_accuracy: 0.9890 - val_loss: 0.0643\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9863 - loss: 0.0637 - val_accuracy: 0.9890 - val_loss: 0.0637\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9872 - loss: 0.0630 - val_accuracy: 0.9895 - val_loss: 0.0631\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9873 - loss: 0.0588 - val_accuracy: 0.9893 - val_loss: 0.0625\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9879 - loss: 0.0599 - val_accuracy: 0.9898 - val_loss: 0.0621\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9868 - loss: 0.0621 - val_accuracy: 0.9898 - val_loss: 0.0616\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s2ms/step - accuracy: 0.9893 - loss: 0.0529 - val_accuracy: 0.9895 - val_loss: 0.0613\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9891 - loss: 0.0547 - val_accuracy: 0.9895 - val_loss: 0.0608\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9886 - loss: 0.0572 - val_accuracy: 0.9895 - val_loss: 0.0603\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9879 - loss: 0.0556 - val_accuracy: 0.9895 - val_loss: 0.0601\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9880 - loss: 0.0605 - val_accuracy: 0.9900 - val_loss: 0.0599\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9884 - loss: 0.0588 - val_accuracy: 0.9900 - val_loss: 0.0593\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9899 - loss: 0.0504 - val_accuracy: 0.9898 - val_loss: 0.0590\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9879 - loss: 0.0539 - val_accuracy: 0.9898 - val_loss: 0.0586\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9893 - loss: 0.0510 - val_accuracy: 0.9900 - val_loss: 0.0583\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9868 - loss: 0.0606 - val_accuracy: 0.9898 - val_loss: 0.0582\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9877 - loss: 0.0597 - val_accuracy: 0.9898 - val_loss: 0.0578\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9888 - loss: 0.0546 - val_accuracy: 0.9900 - val_loss: 0.0575\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9903 - loss: 0.0494 - val_accuracy: 0.9898 - val_loss: 0.0573\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9878 - loss: 0.0570 - val_accuracy: 0.9900 - val_loss: 0.0571\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9892 - loss: 0.0550 - val_accuracy: 0.9902 - val_loss: 0.0568\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9889 - loss: 0.0513 - val_accuracy: 0.9898 - val_loss: 0.0566\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9896 - loss: 0.0528 - val_accuracy: 0.9902 - val_loss: 0.0564\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9884 - loss: 0.0605 - val_accuracy: 0.9900 - val_loss: 0.0562\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9876 - loss: 0.0546 - val_accuracy: 0.9898 - val_loss: 0.0562\n",
    "Time taken in seconds  101.5752317905426500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      0.99     15112\n",
    "         1.0       0.98      0.82      0.89       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.91      0.94     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      0.99      3778\n",
    "         1.0       0.98      0.83      0.90       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.91      0.95      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c3cbf",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23513d9",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201555ae",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,64)             │2,624│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280f2b8",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,64)             │2,624│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81eaee",
   "metadata": {},
   "source": [
    "Total params:2,689(10.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c7b73",
   "metadata": {},
   "source": [
    "Total params:2,689(10.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22b5e1",
   "metadata": {},
   "source": [
    "Trainable params:2,689(10.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc20a98d",
   "metadata": {},
   "source": [
    "Trainable params:2,689(10.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31355a",
   "metadata": {},
   "source": [
    "Non-trainable params:0(0.00 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ebe2e1",
   "metadata": {},
   "source": [
    "Non-trainable params:0(0.00 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b08815",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s6ms/step - accuracy: 0.9239 - loss: 0.2976 - val_accuracy: 0.9525 - val_loss: 0.1645\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9564 - loss: 0.1548 - val_accuracy: 0.9663 - val_loss: 0.1351\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9661 - loss: 0.1302 - val_accuracy: 0.9718 - val_loss: 0.1203\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9696 - loss: 0.1182 - val_accuracy: 0.9740 - val_loss: 0.1106\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9730 - loss: 0.1125 - val_accuracy: 0.9762 - val_loss: 0.1035\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9713 - loss: 0.1049 - val_accuracy: 0.9775 - val_loss: 0.0982\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9736 - loss: 0.1004 - val_accuracy: 0.9780 - val_loss: 0.0939\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9761 - loss: 0.0965 - val_accuracy: 0.9800 - val_loss: 0.0902\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9797 - loss: 0.0836 - val_accuracy: 0.9803 - val_loss: 0.0871\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9786 - loss: 0.0845 - val_accuracy: 0.9805 - val_loss: 0.0845\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9809 - loss: 0.0813 - val_accuracy: 0.9812 - val_loss: 0.0821\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9796 - loss: 0.0835 - val_accuracy: 0.9825 - val_loss: 0.0801\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9820 - loss: 0.0747 - val_accuracy: 0.9825 - val_loss: 0.0780\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9820 - loss: 0.0791 - val_accuracy: 0.9833 - val_loss: 0.0763\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9840 - loss: 0.0758 - val_accuracy: 0.9835 - val_loss: 0.0746\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9825 - loss: 0.0714 - val_accuracy: 0.9840 - val_loss: 0.0732\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9861 - loss: 0.0646 - val_accuracy: 0.9847 - val_loss: 0.0719\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9858 - loss: 0.0723 - val_accuracy: 0.9852 - val_loss: 0.0708\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s2ms/step - accuracy: 0.9844 - loss: 0.0708 - val_accuracy: 0.9862 - val_loss: 0.0697\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9864 - loss: 0.0646 - val_accuracy: 0.9872 - val_loss: 0.0687\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s2ms/step - accuracy: 0.9866 - loss: 0.0678 - val_accuracy: 0.9877 - val_loss: 0.0679\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9855 - loss: 0.0722 - val_accuracy: 0.9872 - val_loss: 0.0670\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9839 - loss: 0.0740 - val_accuracy: 0.9877 - val_loss: 0.0662\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9861 - loss: 0.0652 - val_accuracy: 0.9883 - val_loss: 0.0656\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9873 - loss: 0.0613 - val_accuracy: 0.9887 - val_loss: 0.0648\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9871 - loss: 0.0601 - val_accuracy: 0.9890 - val_loss: 0.0643\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9863 - loss: 0.0637 - val_accuracy: 0.9890 - val_loss: 0.0637\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9872 - loss: 0.0630 - val_accuracy: 0.9895 - val_loss: 0.0631\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9873 - loss: 0.0588 - val_accuracy: 0.9893 - val_loss: 0.0625\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9879 - loss: 0.0599 - val_accuracy: 0.9898 - val_loss: 0.0621\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9868 - loss: 0.0621 - val_accuracy: 0.9898 - val_loss: 0.0616\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s2ms/step - accuracy: 0.9893 - loss: 0.0529 - val_accuracy: 0.9895 - val_loss: 0.0613\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9891 - loss: 0.0547 - val_accuracy: 0.9895 - val_loss: 0.0608\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9886 - loss: 0.0572 - val_accuracy: 0.9895 - val_loss: 0.0603\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9879 - loss: 0.0556 - val_accuracy: 0.9895 - val_loss: 0.0601\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9880 - loss: 0.0605 - val_accuracy: 0.9900 - val_loss: 0.0599\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9884 - loss: 0.0588 - val_accuracy: 0.9900 - val_loss: 0.0593\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9899 - loss: 0.0504 - val_accuracy: 0.9898 - val_loss: 0.0590\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9879 - loss: 0.0539 - val_accuracy: 0.9898 - val_loss: 0.0586\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9893 - loss: 0.0510 - val_accuracy: 0.9900 - val_loss: 0.0583\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9868 - loss: 0.0606 - val_accuracy: 0.9898 - val_loss: 0.0582\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9877 - loss: 0.0597 - val_accuracy: 0.9898 - val_loss: 0.0578\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9888 - loss: 0.0546 - val_accuracy: 0.9900 - val_loss: 0.0575\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9903 - loss: 0.0494 - val_accuracy: 0.9898 - val_loss: 0.0573\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9878 - loss: 0.0570 - val_accuracy: 0.9900 - val_loss: 0.0571\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9892 - loss: 0.0550 - val_accuracy: 0.9902 - val_loss: 0.0568\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9889 - loss: 0.0513 - val_accuracy: 0.9898 - val_loss: 0.0566\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9896 - loss: 0.0528 - val_accuracy: 0.9902 - val_loss: 0.0564\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9884 - loss: 0.0605 - val_accuracy: 0.9900 - val_loss: 0.0562\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9876 - loss: 0.0546 - val_accuracy: 0.9898 - val_loss: 0.0562\n",
    "Time taken in seconds  101.5752317905426"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6970f5",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s6ms/step - accuracy: 0.9239 - loss: 0.2976 - val_accuracy: 0.9525 - val_loss: 0.1645\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9564 - loss: 0.1548 - val_accuracy: 0.9663 - val_loss: 0.1351\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9661 - loss: 0.1302 - val_accuracy: 0.9718 - val_loss: 0.1203\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9696 - loss: 0.1182 - val_accuracy: 0.9740 - val_loss: 0.1106\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9730 - loss: 0.1125 - val_accuracy: 0.9762 - val_loss: 0.1035\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9713 - loss: 0.1049 - val_accuracy: 0.9775 - val_loss: 0.0982\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9736 - loss: 0.1004 - val_accuracy: 0.9780 - val_loss: 0.0939\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9761 - loss: 0.0965 - val_accuracy: 0.9800 - val_loss: 0.0902\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9797 - loss: 0.0836 - val_accuracy: 0.9803 - val_loss: 0.0871\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9786 - loss: 0.0845 - val_accuracy: 0.9805 - val_loss: 0.0845\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9809 - loss: 0.0813 - val_accuracy: 0.9812 - val_loss: 0.0821\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9796 - loss: 0.0835 - val_accuracy: 0.9825 - val_loss: 0.0801\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9820 - loss: 0.0747 - val_accuracy: 0.9825 - val_loss: 0.0780\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9820 - loss: 0.0791 - val_accuracy: 0.9833 - val_loss: 0.0763\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9840 - loss: 0.0758 - val_accuracy: 0.9835 - val_loss: 0.0746\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9825 - loss: 0.0714 - val_accuracy: 0.9840 - val_loss: 0.0732\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9861 - loss: 0.0646 - val_accuracy: 0.9847 - val_loss: 0.0719\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9858 - loss: 0.0723 - val_accuracy: 0.9852 - val_loss: 0.0708\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s2ms/step - accuracy: 0.9844 - loss: 0.0708 - val_accuracy: 0.9862 - val_loss: 0.0697\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9864 - loss: 0.0646 - val_accuracy: 0.9872 - val_loss: 0.0687\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s2ms/step - accuracy: 0.9866 - loss: 0.0678 - val_accuracy: 0.9877 - val_loss: 0.0679\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9855 - loss: 0.0722 - val_accuracy: 0.9872 - val_loss: 0.0670\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9839 - loss: 0.0740 - val_accuracy: 0.9877 - val_loss: 0.0662\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9861 - loss: 0.0652 - val_accuracy: 0.9883 - val_loss: 0.0656\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9873 - loss: 0.0613 - val_accuracy: 0.9887 - val_loss: 0.0648\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9871 - loss: 0.0601 - val_accuracy: 0.9890 - val_loss: 0.0643\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9863 - loss: 0.0637 - val_accuracy: 0.9890 - val_loss: 0.0637\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9872 - loss: 0.0630 - val_accuracy: 0.9895 - val_loss: 0.0631\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9873 - loss: 0.0588 - val_accuracy: 0.9893 - val_loss: 0.0625\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9879 - loss: 0.0599 - val_accuracy: 0.9898 - val_loss: 0.0621\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9868 - loss: 0.0621 - val_accuracy: 0.9898 - val_loss: 0.0616\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s2ms/step - accuracy: 0.9893 - loss: 0.0529 - val_accuracy: 0.9895 - val_loss: 0.0613\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9891 - loss: 0.0547 - val_accuracy: 0.9895 - val_loss: 0.0608\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9886 - loss: 0.0572 - val_accuracy: 0.9895 - val_loss: 0.0603\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9879 - loss: 0.0556 - val_accuracy: 0.9895 - val_loss: 0.0601\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9880 - loss: 0.0605 - val_accuracy: 0.9900 - val_loss: 0.0599\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9884 - loss: 0.0588 - val_accuracy: 0.9900 - val_loss: 0.0593\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9899 - loss: 0.0504 - val_accuracy: 0.9898 - val_loss: 0.0590\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9879 - loss: 0.0539 - val_accuracy: 0.9898 - val_loss: 0.0586\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9893 - loss: 0.0510 - val_accuracy: 0.9900 - val_loss: 0.0583\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9868 - loss: 0.0606 - val_accuracy: 0.9898 - val_loss: 0.0582\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9877 - loss: 0.0597 - val_accuracy: 0.9898 - val_loss: 0.0578\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9888 - loss: 0.0546 - val_accuracy: 0.9900 - val_loss: 0.0575\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9903 - loss: 0.0494 - val_accuracy: 0.9898 - val_loss: 0.0573\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9878 - loss: 0.0570 - val_accuracy: 0.9900 - val_loss: 0.0571\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9892 - loss: 0.0550 - val_accuracy: 0.9902 - val_loss: 0.0568\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9889 - loss: 0.0513 - val_accuracy: 0.9898 - val_loss: 0.0566\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9896 - loss: 0.0528 - val_accuracy: 0.9902 - val_loss: 0.0564\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step - accuracy: 0.9884 - loss: 0.0605 - val_accuracy: 0.9900 - val_loss: 0.0562\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9876 - loss: 0.0546 - val_accuracy: 0.9898 - val_loss: 0.0562\n",
    "Time taken in seconds  101.5752317905426"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d6b3d9",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      0.99     15112\n",
    "         1.0       0.98      0.82      0.89       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.91      0.94     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      0.99      3778\n",
    "         1.0       0.98      0.83      0.90       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.91      0.95      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6aa3f",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      0.99     15112\n",
    "         1.0       0.98      0.82      0.89       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.91      0.94     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      0.99      3778\n",
    "         1.0       0.98      0.83      0.90       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.91      0.95      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed44700",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Model Architecture:Simple 2-layer network: 64 hidden neurons + 1 output neuronReLU activation in hidden layer, sigmoid in output layerTotal parameters: ~2,600 (relatively small model)Training Performance:Fast training time due to simple architectureModerate accuracy: approximately 70-80%Training loss decreases steadily, indicating learningValidation Performance:Gap between training and validation performance suggests overfittingValidation accuracy lower than training accuracyModel memorizes training data rather than generalizingLearning Curves:Training curves show good convergenceValidation curves may plateau or decrease after certain epochsClear signs of overfitting in later epochsBaseline Establishment:Provides baseline performance for comparisonDemonstrates the need for regularization techniquesShows that even simple models can achieve reasonable accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb628eaf",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Model Architecture:Simple 2-layer network: 64 hidden neurons + 1 output neuronReLU activation in hidden layer, sigmoid in output layerTotal parameters: ~2,600 (relatively small model)Training Performance:Fast training time due to simple architectureModerate accuracy: approximately 70-80%Training loss decreases steadily, indicating learningValidation Performance:Gap between training and validation performance suggests overfittingValidation accuracy lower than training accuracyModel memorizes training data rather than generalizingLearning Curves:Training curves show good convergenceValidation curves may plateau or decrease after certain epochsClear signs of overfitting in later epochsBaseline Establishment:Provides baseline performance for comparisonDemonstrates the need for regularization techniquesShows that even simple models can achieve reasonable accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26172f0c",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Model Architecture:Simple 2-layer network: 64 hidden neurons + 1 output neuronReLU activation in hidden layer, sigmoid in output layerTotal parameters: ~2,600 (relatively small model)Training Performance:Fast training time due to simple architectureModerate accuracy: approximately 70-80%Training loss decreases steadily, indicating learningValidation Performance:Gap between training and validation performance suggests overfittingValidation accuracy lower than training accuracyModel memorizes training data rather than generalizingLearning Curves:Training curves show good convergenceValidation curves may plateau or decrease after certain epochsClear signs of overfitting in later epochsBaseline Establishment:Provides baseline performance for comparisonDemonstrates the need for regularization techniquesShows that even simple models can achieve reasonable accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07371c7",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Model Architecture:Simple 2-layer network: 64 hidden neurons + 1 output neuronReLU activation in hidden layer, sigmoid in output layerTotal parameters: ~2,600 (relatively small model)Training Performance:Fast training time due to simple architectureModerate accuracy: approximately 70-80%Training loss decreases steadily, indicating learningValidation Performance:Gap between training and validation performance suggests overfittingValidation accuracy lower than training accuracyModel memorizes training data rather than generalizingLearning Curves:Training curves show good convergenceValidation curves may plateau or decrease after certain epochsClear signs of overfitting in later epochsBaseline Establishment:Provides baseline performance for comparisonDemonstrates the need for regularization techniquesShows that even simple models can achieve reasonable accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ec0a8",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f866ec",
   "metadata": {},
   "source": [
    "Model Architecture:Simple 2-layer network: 64 hidden neurons + 1 output neuronReLU activation in hidden layer, sigmoid in output layerTotal parameters: ~2,600 (relatively small model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a2f95",
   "metadata": {},
   "source": [
    "Model Architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33420618",
   "metadata": {},
   "source": [
    "Simple 2-layer network: 64 hidden neurons + 1 output neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d0567",
   "metadata": {},
   "source": [
    "ReLU activation in hidden layer, sigmoid in output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505f7b5",
   "metadata": {},
   "source": [
    "Total parameters: ~2,600 (relatively small model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4844aca4",
   "metadata": {},
   "source": [
    "Training Performance:Fast training time due to simple architectureModerate accuracy: approximately 70-80%Training loss decreases steadily, indicating learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58456b5",
   "metadata": {},
   "source": [
    "Training Performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486f1d9",
   "metadata": {},
   "source": [
    "Fast training time due to simple architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e79b38",
   "metadata": {},
   "source": [
    "Moderate accuracy: approximately 70-80%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe6d6f",
   "metadata": {},
   "source": [
    "Training loss decreases steadily, indicating learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c61e1c",
   "metadata": {},
   "source": [
    "Validation Performance:Gap between training and validation performance suggests overfittingValidation accuracy lower than training accuracyModel memorizes training data rather than generalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d41a3",
   "metadata": {},
   "source": [
    "Validation Performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2af464",
   "metadata": {},
   "source": [
    "Gap between training and validation performance suggests overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dedd71f",
   "metadata": {},
   "source": [
    "Validation accuracy lower than training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd27f3d0",
   "metadata": {},
   "source": [
    "Model memorizes training data rather than generalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37220082",
   "metadata": {},
   "source": [
    "Learning Curves:Training curves show good convergenceValidation curves may plateau or decrease after certain epochsClear signs of overfitting in later epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f242b",
   "metadata": {},
   "source": [
    "Learning Curves:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4414212",
   "metadata": {},
   "source": [
    "Training curves show good convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e735a31",
   "metadata": {},
   "source": [
    "Validation curves may plateau or decrease after certain epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158933b",
   "metadata": {},
   "source": [
    "Clear signs of overfitting in later epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a754139d",
   "metadata": {},
   "source": [
    "Baseline Establishment:Provides baseline performance for comparisonDemonstrates the need for regularization techniquesShows that even simple models can achieve reasonable accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd94e3",
   "metadata": {},
   "source": [
    "Baseline Establishment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167ca19",
   "metadata": {},
   "source": [
    "Provides baseline performance for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe2b550",
   "metadata": {},
   "source": [
    "Demonstrates the need for regularization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ca3ec",
   "metadata": {},
   "source": [
    "Shows that even simple models can achieve reasonable accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b478e8a3",
   "metadata": {},
   "source": [
    "Model Performance Improvement¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bddde1a",
   "metadata": {},
   "source": [
    "Model Performance Improvement¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06117e12",
   "metadata": {},
   "source": [
    "Model Performance Improvement¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e27842",
   "metadata": {},
   "source": [
    "Model Performance Improvement¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8c06e",
   "metadata": {},
   "source": [
    "Model Performance Improvement¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d494ed",
   "metadata": {},
   "source": [
    "Model 1¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87715d7",
   "metadata": {},
   "source": [
    "Model 1¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21758e46",
   "metadata": {},
   "source": [
    "Model 1¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4831474",
   "metadata": {},
   "source": [
    "Model 1¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c11dfcc",
   "metadata": {},
   "source": [
    "Model 1¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e764f2",
   "metadata": {},
   "source": [
    "In [17]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_1=Sequential()model_1.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_1.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_1.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_1.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_1.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_1.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_1_train_perf=model_performance_classification(model_1,X_train_scaled,y_train)model_1_train_perfmodel_1_val_perf=model_performance_classification(model_1,X_val_scaled,y_val)model_1_val_perfy_train_pred_1=model_1.predict(X_train_scaled)y_val_pred_1=model_1.predict(X_val_scaled)print(\"Classification Report - Train data Model_1\",end=\"\\n\\n\")cr_train_model_1=classification_report(y_train,y_train_pred_1>0.5)print(cr_train_model_1)print(\"Classification Report - Validation data Model_1\",end=\"\\n\\n\")cr_val_model_1=classification_report(y_val,y_val_pred_1>0.5)print(cr_val_model_1)Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:13,569(53.00 KB)Trainable params:13,569(53.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.8447 - loss: 0.3556 - val_accuracy: 0.9470 - val_loss: 0.1623\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9534 - loss: 0.1495 - val_accuracy: 0.9635 - val_loss: 0.1271\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9675 - loss: 0.1187 - val_accuracy: 0.9737 - val_loss: 0.1082\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9730 - loss: 0.1074 - val_accuracy: 0.9770 - val_loss: 0.0959\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9779 - loss: 0.0923 - val_accuracy: 0.9793 - val_loss: 0.0869\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9785 - loss: 0.0913 - val_accuracy: 0.9820 - val_loss: 0.0806\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9829 - loss: 0.0784 - val_accuracy: 0.9850 - val_loss: 0.0755\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9839 - loss: 0.0771 - val_accuracy: 0.9860 - val_loss: 0.0720\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9847 - loss: 0.0701 - val_accuracy: 0.9870 - val_loss: 0.0688\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9858 - loss: 0.0654 - val_accuracy: 0.9885 - val_loss: 0.0667\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9864 - loss: 0.0626 - val_accuracy: 0.9898 - val_loss: 0.0650\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9881 - loss: 0.0567 - val_accuracy: 0.9905 - val_loss: 0.0634\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9886 - loss: 0.0552 - val_accuracy: 0.9908 - val_loss: 0.0619\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9890 - loss: 0.0553 - val_accuracy: 0.9912 - val_loss: 0.0602\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9890 - loss: 0.0590 - val_accuracy: 0.9918 - val_loss: 0.0589\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9885 - loss: 0.0569 - val_accuracy: 0.9912 - val_loss: 0.0585\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9883 - loss: 0.0547 - val_accuracy: 0.9915 - val_loss: 0.0577\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9896 - loss: 0.0542 - val_accuracy: 0.9920 - val_loss: 0.0561\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9889 - loss: 0.0542 - val_accuracy: 0.9918 - val_loss: 0.0563\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9877 - loss: 0.0605 - val_accuracy: 0.9915 - val_loss: 0.0555\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9897 - loss: 0.0551 - val_accuracy: 0.9920 - val_loss: 0.0541\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9887 - loss: 0.0537 - val_accuracy: 0.9920 - val_loss: 0.0536\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9905 - loss: 0.0505 - val_accuracy: 0.9918 - val_loss: 0.0536\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9898 - loss: 0.0525 - val_accuracy: 0.9923 - val_loss: 0.0528\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9907 - loss: 0.0495 - val_accuracy: 0.9923 - val_loss: 0.0523\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9915 - loss: 0.0435 - val_accuracy: 0.9920 - val_loss: 0.0515\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9907 - loss: 0.0452 - val_accuracy: 0.9918 - val_loss: 0.0518\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9919 - loss: 0.0431 - val_accuracy: 0.9920 - val_loss: 0.0520\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9914 - loss: 0.0456 - val_accuracy: 0.9925 - val_loss: 0.0504\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9907 - loss: 0.0475 - val_accuracy: 0.9920 - val_loss: 0.0502\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9895 - loss: 0.0481 - val_accuracy: 0.9925 - val_loss: 0.0501\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9900 - loss: 0.0479 - val_accuracy: 0.9920 - val_loss: 0.0496\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9908 - loss: 0.0454 - val_accuracy: 0.9923 - val_loss: 0.0504\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9905 - loss: 0.0473 - val_accuracy: 0.9925 - val_loss: 0.0491\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9911 - loss: 0.0444 - val_accuracy: 0.9923 - val_loss: 0.0488\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9910 - loss: 0.0459 - val_accuracy: 0.9925 - val_loss: 0.0486\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9916 - loss: 0.0438 - val_accuracy: 0.9918 - val_loss: 0.0485\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9912 - loss: 0.0453 - val_accuracy: 0.9923 - val_loss: 0.0484\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9923 - loss: 0.0416 - val_accuracy: 0.9923 - val_loss: 0.0478\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9903 - loss: 0.0463 - val_accuracy: 0.9923 - val_loss: 0.0484\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9909 - loss: 0.0441 - val_accuracy: 0.9920 - val_loss: 0.0478\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9903 - loss: 0.0457 - val_accuracy: 0.9923 - val_loss: 0.0471\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9918 - loss: 0.0444 - val_accuracy: 0.9923 - val_loss: 0.0480\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9918 - loss: 0.0400 - val_accuracy: 0.9923 - val_loss: 0.0472\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9906 - loss: 0.0444 - val_accuracy: 0.9927 - val_loss: 0.0474\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9917 - loss: 0.0416 - val_accuracy: 0.9927 - val_loss: 0.0474\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9917 - loss: 0.0375 - val_accuracy: 0.9923 - val_loss: 0.0467\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9920 - loss: 0.0400 - val_accuracy: 0.9925 - val_loss: 0.0466\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9913 - loss: 0.0415 - val_accuracy: 0.9923 - val_loss: 0.0462\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9917 - loss: 0.0421 - val_accuracy: 0.9923 - val_loss: 0.0474\n",
    "Time taken in seconds  118.35755324363708500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       0.99      0.86      0.92       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.93      0.96     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.98      0.88      0.93       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.98      0.94      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71116d78",
   "metadata": {},
   "source": [
    "In [17]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_1=Sequential()model_1.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_1.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_1.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_1.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_1.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_1.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_1_train_perf=model_performance_classification(model_1,X_train_scaled,y_train)model_1_train_perfmodel_1_val_perf=model_performance_classification(model_1,X_val_scaled,y_val)model_1_val_perfy_train_pred_1=model_1.predict(X_train_scaled)y_val_pred_1=model_1.predict(X_val_scaled)print(\"Classification Report - Train data Model_1\",end=\"\\n\\n\")cr_train_model_1=classification_report(y_train,y_train_pred_1>0.5)print(cr_train_model_1)print(\"Classification Report - Validation data Model_1\",end=\"\\n\\n\")cr_val_model_1=classification_report(y_val,y_val_pred_1>0.5)print(cr_val_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8888d90",
   "metadata": {},
   "source": [
    "In [17]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_1=Sequential()model_1.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_1.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_1.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_1.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_1.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_1.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_1_train_perf=model_performance_classification(model_1,X_train_scaled,y_train)model_1_train_perfmodel_1_val_perf=model_performance_classification(model_1,X_val_scaled,y_val)model_1_val_perfy_train_pred_1=model_1.predict(X_train_scaled)y_val_pred_1=model_1.predict(X_val_scaled)print(\"Classification Report - Train data Model_1\",end=\"\\n\\n\")cr_train_model_1=classification_report(y_train,y_train_pred_1>0.5)print(cr_train_model_1)print(\"Classification Report - Validation data Model_1\",end=\"\\n\\n\")cr_val_model_1=classification_report(y_val,y_val_pred_1>0.5)print(cr_val_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57571115",
   "metadata": {},
   "source": [
    "In [17]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba2adf",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_1=Sequential()model_1.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_1.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_1.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_1.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_1.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_1.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_1_train_perf=model_performance_classification(model_1,X_train_scaled,y_train)model_1_train_perfmodel_1_val_perf=model_performance_classification(model_1,X_val_scaled,y_val)model_1_val_perfy_train_pred_1=model_1.predict(X_train_scaled)y_val_pred_1=model_1.predict(X_val_scaled)print(\"Classification Report - Train data Model_1\",end=\"\\n\\n\")cr_train_model_1=classification_report(y_train,y_train_pred_1>0.5)print(cr_train_model_1)print(\"Classification Report - Validation data Model_1\",end=\"\\n\\n\")cr_val_model_1=classification_report(y_val,y_val_pred_1>0.5)print(cr_val_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da60b9",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_1=Sequential()model_1.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_1.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_1.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_1.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_1.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_1.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_1_train_perf=model_performance_classification(model_1,X_train_scaled,y_train)model_1_train_perfmodel_1_val_perf=model_performance_classification(model_1,X_val_scaled,y_val)model_1_val_perfy_train_pred_1=model_1.predict(X_train_scaled)y_val_pred_1=model_1.predict(X_val_scaled)print(\"Classification Report - Train data Model_1\",end=\"\\n\\n\")cr_train_model_1=classification_report(y_train,y_train_pred_1>0.5)print(cr_train_model_1)print(\"Classification Report - Validation data Model_1\",end=\"\\n\\n\")cr_val_model_1=classification_report(y_val,y_val_pred_1>0.5)print(cr_val_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191d57f",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_1=Sequential()model_1.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_1.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_1.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_1.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_1.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_1.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_1_train_perf=model_performance_classification(model_1,X_train_scaled,y_train)model_1_train_perfmodel_1_val_perf=model_performance_classification(model_1,X_val_scaled,y_val)model_1_val_perfy_train_pred_1=model_1.predict(X_train_scaled)y_val_pred_1=model_1.predict(X_val_scaled)print(\"Classification Report - Train data Model_1\",end=\"\\n\\n\")cr_train_model_1=classification_report(y_train,y_train_pred_1>0.5)print(cr_train_model_1)print(\"Classification Report - Validation data Model_1\",end=\"\\n\\n\")cr_val_model_1=classification_report(y_val,y_val_pred_1>0.5)print(cr_val_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b573a",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:13,569(53.00 KB)Trainable params:13,569(53.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.8447 - loss: 0.3556 - val_accuracy: 0.9470 - val_loss: 0.1623\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9534 - loss: 0.1495 - val_accuracy: 0.9635 - val_loss: 0.1271\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9675 - loss: 0.1187 - val_accuracy: 0.9737 - val_loss: 0.1082\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9730 - loss: 0.1074 - val_accuracy: 0.9770 - val_loss: 0.0959\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9779 - loss: 0.0923 - val_accuracy: 0.9793 - val_loss: 0.0869\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9785 - loss: 0.0913 - val_accuracy: 0.9820 - val_loss: 0.0806\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9829 - loss: 0.0784 - val_accuracy: 0.9850 - val_loss: 0.0755\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9839 - loss: 0.0771 - val_accuracy: 0.9860 - val_loss: 0.0720\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9847 - loss: 0.0701 - val_accuracy: 0.9870 - val_loss: 0.0688\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9858 - loss: 0.0654 - val_accuracy: 0.9885 - val_loss: 0.0667\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9864 - loss: 0.0626 - val_accuracy: 0.9898 - val_loss: 0.0650\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9881 - loss: 0.0567 - val_accuracy: 0.9905 - val_loss: 0.0634\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9886 - loss: 0.0552 - val_accuracy: 0.9908 - val_loss: 0.0619\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9890 - loss: 0.0553 - val_accuracy: 0.9912 - val_loss: 0.0602\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9890 - loss: 0.0590 - val_accuracy: 0.9918 - val_loss: 0.0589\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9885 - loss: 0.0569 - val_accuracy: 0.9912 - val_loss: 0.0585\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9883 - loss: 0.0547 - val_accuracy: 0.9915 - val_loss: 0.0577\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9896 - loss: 0.0542 - val_accuracy: 0.9920 - val_loss: 0.0561\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9889 - loss: 0.0542 - val_accuracy: 0.9918 - val_loss: 0.0563\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9877 - loss: 0.0605 - val_accuracy: 0.9915 - val_loss: 0.0555\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9897 - loss: 0.0551 - val_accuracy: 0.9920 - val_loss: 0.0541\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9887 - loss: 0.0537 - val_accuracy: 0.9920 - val_loss: 0.0536\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9905 - loss: 0.0505 - val_accuracy: 0.9918 - val_loss: 0.0536\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9898 - loss: 0.0525 - val_accuracy: 0.9923 - val_loss: 0.0528\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9907 - loss: 0.0495 - val_accuracy: 0.9923 - val_loss: 0.0523\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9915 - loss: 0.0435 - val_accuracy: 0.9920 - val_loss: 0.0515\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9907 - loss: 0.0452 - val_accuracy: 0.9918 - val_loss: 0.0518\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9919 - loss: 0.0431 - val_accuracy: 0.9920 - val_loss: 0.0520\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9914 - loss: 0.0456 - val_accuracy: 0.9925 - val_loss: 0.0504\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9907 - loss: 0.0475 - val_accuracy: 0.9920 - val_loss: 0.0502\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9895 - loss: 0.0481 - val_accuracy: 0.9925 - val_loss: 0.0501\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9900 - loss: 0.0479 - val_accuracy: 0.9920 - val_loss: 0.0496\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9908 - loss: 0.0454 - val_accuracy: 0.9923 - val_loss: 0.0504\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9905 - loss: 0.0473 - val_accuracy: 0.9925 - val_loss: 0.0491\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9911 - loss: 0.0444 - val_accuracy: 0.9923 - val_loss: 0.0488\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9910 - loss: 0.0459 - val_accuracy: 0.9925 - val_loss: 0.0486\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9916 - loss: 0.0438 - val_accuracy: 0.9918 - val_loss: 0.0485\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9912 - loss: 0.0453 - val_accuracy: 0.9923 - val_loss: 0.0484\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9923 - loss: 0.0416 - val_accuracy: 0.9923 - val_loss: 0.0478\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9903 - loss: 0.0463 - val_accuracy: 0.9923 - val_loss: 0.0484\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9909 - loss: 0.0441 - val_accuracy: 0.9920 - val_loss: 0.0478\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9903 - loss: 0.0457 - val_accuracy: 0.9923 - val_loss: 0.0471\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9918 - loss: 0.0444 - val_accuracy: 0.9923 - val_loss: 0.0480\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9918 - loss: 0.0400 - val_accuracy: 0.9923 - val_loss: 0.0472\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9906 - loss: 0.0444 - val_accuracy: 0.9927 - val_loss: 0.0474\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9917 - loss: 0.0416 - val_accuracy: 0.9927 - val_loss: 0.0474\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9917 - loss: 0.0375 - val_accuracy: 0.9923 - val_loss: 0.0467\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9920 - loss: 0.0400 - val_accuracy: 0.9925 - val_loss: 0.0466\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9913 - loss: 0.0415 - val_accuracy: 0.9923 - val_loss: 0.0462\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9917 - loss: 0.0421 - val_accuracy: 0.9923 - val_loss: 0.0474\n",
    "Time taken in seconds  118.35755324363708500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       0.99      0.86      0.92       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.93      0.96     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.98      0.88      0.93       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.98      0.94      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea9a36",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:13,569(53.00 KB)Trainable params:13,569(53.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.8447 - loss: 0.3556 - val_accuracy: 0.9470 - val_loss: 0.1623\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9534 - loss: 0.1495 - val_accuracy: 0.9635 - val_loss: 0.1271\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9675 - loss: 0.1187 - val_accuracy: 0.9737 - val_loss: 0.1082\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9730 - loss: 0.1074 - val_accuracy: 0.9770 - val_loss: 0.0959\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9779 - loss: 0.0923 - val_accuracy: 0.9793 - val_loss: 0.0869\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9785 - loss: 0.0913 - val_accuracy: 0.9820 - val_loss: 0.0806\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9829 - loss: 0.0784 - val_accuracy: 0.9850 - val_loss: 0.0755\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9839 - loss: 0.0771 - val_accuracy: 0.9860 - val_loss: 0.0720\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9847 - loss: 0.0701 - val_accuracy: 0.9870 - val_loss: 0.0688\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9858 - loss: 0.0654 - val_accuracy: 0.9885 - val_loss: 0.0667\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9864 - loss: 0.0626 - val_accuracy: 0.9898 - val_loss: 0.0650\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9881 - loss: 0.0567 - val_accuracy: 0.9905 - val_loss: 0.0634\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9886 - loss: 0.0552 - val_accuracy: 0.9908 - val_loss: 0.0619\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9890 - loss: 0.0553 - val_accuracy: 0.9912 - val_loss: 0.0602\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9890 - loss: 0.0590 - val_accuracy: 0.9918 - val_loss: 0.0589\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9885 - loss: 0.0569 - val_accuracy: 0.9912 - val_loss: 0.0585\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9883 - loss: 0.0547 - val_accuracy: 0.9915 - val_loss: 0.0577\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9896 - loss: 0.0542 - val_accuracy: 0.9920 - val_loss: 0.0561\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9889 - loss: 0.0542 - val_accuracy: 0.9918 - val_loss: 0.0563\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9877 - loss: 0.0605 - val_accuracy: 0.9915 - val_loss: 0.0555\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9897 - loss: 0.0551 - val_accuracy: 0.9920 - val_loss: 0.0541\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9887 - loss: 0.0537 - val_accuracy: 0.9920 - val_loss: 0.0536\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9905 - loss: 0.0505 - val_accuracy: 0.9918 - val_loss: 0.0536\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9898 - loss: 0.0525 - val_accuracy: 0.9923 - val_loss: 0.0528\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9907 - loss: 0.0495 - val_accuracy: 0.9923 - val_loss: 0.0523\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9915 - loss: 0.0435 - val_accuracy: 0.9920 - val_loss: 0.0515\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9907 - loss: 0.0452 - val_accuracy: 0.9918 - val_loss: 0.0518\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9919 - loss: 0.0431 - val_accuracy: 0.9920 - val_loss: 0.0520\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9914 - loss: 0.0456 - val_accuracy: 0.9925 - val_loss: 0.0504\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9907 - loss: 0.0475 - val_accuracy: 0.9920 - val_loss: 0.0502\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9895 - loss: 0.0481 - val_accuracy: 0.9925 - val_loss: 0.0501\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9900 - loss: 0.0479 - val_accuracy: 0.9920 - val_loss: 0.0496\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9908 - loss: 0.0454 - val_accuracy: 0.9923 - val_loss: 0.0504\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9905 - loss: 0.0473 - val_accuracy: 0.9925 - val_loss: 0.0491\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9911 - loss: 0.0444 - val_accuracy: 0.9923 - val_loss: 0.0488\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9910 - loss: 0.0459 - val_accuracy: 0.9925 - val_loss: 0.0486\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9916 - loss: 0.0438 - val_accuracy: 0.9918 - val_loss: 0.0485\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9912 - loss: 0.0453 - val_accuracy: 0.9923 - val_loss: 0.0484\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9923 - loss: 0.0416 - val_accuracy: 0.9923 - val_loss: 0.0478\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9903 - loss: 0.0463 - val_accuracy: 0.9923 - val_loss: 0.0484\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9909 - loss: 0.0441 - val_accuracy: 0.9920 - val_loss: 0.0478\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9903 - loss: 0.0457 - val_accuracy: 0.9923 - val_loss: 0.0471\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9918 - loss: 0.0444 - val_accuracy: 0.9923 - val_loss: 0.0480\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9918 - loss: 0.0400 - val_accuracy: 0.9923 - val_loss: 0.0472\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9906 - loss: 0.0444 - val_accuracy: 0.9927 - val_loss: 0.0474\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9917 - loss: 0.0416 - val_accuracy: 0.9927 - val_loss: 0.0474\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9917 - loss: 0.0375 - val_accuracy: 0.9923 - val_loss: 0.0467\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9920 - loss: 0.0400 - val_accuracy: 0.9925 - val_loss: 0.0466\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9913 - loss: 0.0415 - val_accuracy: 0.9923 - val_loss: 0.0462\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9917 - loss: 0.0421 - val_accuracy: 0.9923 - val_loss: 0.0474\n",
    "Time taken in seconds  118.35755324363708500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       0.99      0.86      0.92       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.93      0.96     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.98      0.88      0.93       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.98      0.94      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba3668f",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d3518",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c9000",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6864b",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b7f67d",
   "metadata": {},
   "source": [
    "Total params:13,569(53.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a570f93",
   "metadata": {},
   "source": [
    "Total params:13,569(53.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0522b42",
   "metadata": {},
   "source": [
    "Trainable params:13,569(53.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22663ebc",
   "metadata": {},
   "source": [
    "Trainable params:13,569(53.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc08602b",
   "metadata": {},
   "source": [
    "Non-trainable params:0(0.00 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252f6a0",
   "metadata": {},
   "source": [
    "Non-trainable params:0(0.00 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcfea3f",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.8447 - loss: 0.3556 - val_accuracy: 0.9470 - val_loss: 0.1623\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9534 - loss: 0.1495 - val_accuracy: 0.9635 - val_loss: 0.1271\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9675 - loss: 0.1187 - val_accuracy: 0.9737 - val_loss: 0.1082\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9730 - loss: 0.1074 - val_accuracy: 0.9770 - val_loss: 0.0959\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9779 - loss: 0.0923 - val_accuracy: 0.9793 - val_loss: 0.0869\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9785 - loss: 0.0913 - val_accuracy: 0.9820 - val_loss: 0.0806\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9829 - loss: 0.0784 - val_accuracy: 0.9850 - val_loss: 0.0755\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9839 - loss: 0.0771 - val_accuracy: 0.9860 - val_loss: 0.0720\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9847 - loss: 0.0701 - val_accuracy: 0.9870 - val_loss: 0.0688\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9858 - loss: 0.0654 - val_accuracy: 0.9885 - val_loss: 0.0667\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9864 - loss: 0.0626 - val_accuracy: 0.9898 - val_loss: 0.0650\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9881 - loss: 0.0567 - val_accuracy: 0.9905 - val_loss: 0.0634\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9886 - loss: 0.0552 - val_accuracy: 0.9908 - val_loss: 0.0619\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9890 - loss: 0.0553 - val_accuracy: 0.9912 - val_loss: 0.0602\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9890 - loss: 0.0590 - val_accuracy: 0.9918 - val_loss: 0.0589\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9885 - loss: 0.0569 - val_accuracy: 0.9912 - val_loss: 0.0585\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9883 - loss: 0.0547 - val_accuracy: 0.9915 - val_loss: 0.0577\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9896 - loss: 0.0542 - val_accuracy: 0.9920 - val_loss: 0.0561\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9889 - loss: 0.0542 - val_accuracy: 0.9918 - val_loss: 0.0563\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9877 - loss: 0.0605 - val_accuracy: 0.9915 - val_loss: 0.0555\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9897 - loss: 0.0551 - val_accuracy: 0.9920 - val_loss: 0.0541\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9887 - loss: 0.0537 - val_accuracy: 0.9920 - val_loss: 0.0536\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9905 - loss: 0.0505 - val_accuracy: 0.9918 - val_loss: 0.0536\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9898 - loss: 0.0525 - val_accuracy: 0.9923 - val_loss: 0.0528\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9907 - loss: 0.0495 - val_accuracy: 0.9923 - val_loss: 0.0523\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9915 - loss: 0.0435 - val_accuracy: 0.9920 - val_loss: 0.0515\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9907 - loss: 0.0452 - val_accuracy: 0.9918 - val_loss: 0.0518\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9919 - loss: 0.0431 - val_accuracy: 0.9920 - val_loss: 0.0520\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9914 - loss: 0.0456 - val_accuracy: 0.9925 - val_loss: 0.0504\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9907 - loss: 0.0475 - val_accuracy: 0.9920 - val_loss: 0.0502\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9895 - loss: 0.0481 - val_accuracy: 0.9925 - val_loss: 0.0501\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9900 - loss: 0.0479 - val_accuracy: 0.9920 - val_loss: 0.0496\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9908 - loss: 0.0454 - val_accuracy: 0.9923 - val_loss: 0.0504\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9905 - loss: 0.0473 - val_accuracy: 0.9925 - val_loss: 0.0491\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9911 - loss: 0.0444 - val_accuracy: 0.9923 - val_loss: 0.0488\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9910 - loss: 0.0459 - val_accuracy: 0.9925 - val_loss: 0.0486\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9916 - loss: 0.0438 - val_accuracy: 0.9918 - val_loss: 0.0485\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9912 - loss: 0.0453 - val_accuracy: 0.9923 - val_loss: 0.0484\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9923 - loss: 0.0416 - val_accuracy: 0.9923 - val_loss: 0.0478\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9903 - loss: 0.0463 - val_accuracy: 0.9923 - val_loss: 0.0484\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9909 - loss: 0.0441 - val_accuracy: 0.9920 - val_loss: 0.0478\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9903 - loss: 0.0457 - val_accuracy: 0.9923 - val_loss: 0.0471\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9918 - loss: 0.0444 - val_accuracy: 0.9923 - val_loss: 0.0480\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9918 - loss: 0.0400 - val_accuracy: 0.9923 - val_loss: 0.0472\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9906 - loss: 0.0444 - val_accuracy: 0.9927 - val_loss: 0.0474\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9917 - loss: 0.0416 - val_accuracy: 0.9927 - val_loss: 0.0474\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9917 - loss: 0.0375 - val_accuracy: 0.9923 - val_loss: 0.0467\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9920 - loss: 0.0400 - val_accuracy: 0.9925 - val_loss: 0.0466\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9913 - loss: 0.0415 - val_accuracy: 0.9923 - val_loss: 0.0462\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9917 - loss: 0.0421 - val_accuracy: 0.9923 - val_loss: 0.0474\n",
    "Time taken in seconds  118.35755324363708"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7754f418",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.8447 - loss: 0.3556 - val_accuracy: 0.9470 - val_loss: 0.1623\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9534 - loss: 0.1495 - val_accuracy: 0.9635 - val_loss: 0.1271\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9675 - loss: 0.1187 - val_accuracy: 0.9737 - val_loss: 0.1082\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9730 - loss: 0.1074 - val_accuracy: 0.9770 - val_loss: 0.0959\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9779 - loss: 0.0923 - val_accuracy: 0.9793 - val_loss: 0.0869\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9785 - loss: 0.0913 - val_accuracy: 0.9820 - val_loss: 0.0806\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9829 - loss: 0.0784 - val_accuracy: 0.9850 - val_loss: 0.0755\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9839 - loss: 0.0771 - val_accuracy: 0.9860 - val_loss: 0.0720\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9847 - loss: 0.0701 - val_accuracy: 0.9870 - val_loss: 0.0688\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9858 - loss: 0.0654 - val_accuracy: 0.9885 - val_loss: 0.0667\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9864 - loss: 0.0626 - val_accuracy: 0.9898 - val_loss: 0.0650\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9881 - loss: 0.0567 - val_accuracy: 0.9905 - val_loss: 0.0634\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9886 - loss: 0.0552 - val_accuracy: 0.9908 - val_loss: 0.0619\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9890 - loss: 0.0553 - val_accuracy: 0.9912 - val_loss: 0.0602\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9890 - loss: 0.0590 - val_accuracy: 0.9918 - val_loss: 0.0589\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9885 - loss: 0.0569 - val_accuracy: 0.9912 - val_loss: 0.0585\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9883 - loss: 0.0547 - val_accuracy: 0.9915 - val_loss: 0.0577\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9896 - loss: 0.0542 - val_accuracy: 0.9920 - val_loss: 0.0561\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9889 - loss: 0.0542 - val_accuracy: 0.9918 - val_loss: 0.0563\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9877 - loss: 0.0605 - val_accuracy: 0.9915 - val_loss: 0.0555\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9897 - loss: 0.0551 - val_accuracy: 0.9920 - val_loss: 0.0541\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9887 - loss: 0.0537 - val_accuracy: 0.9920 - val_loss: 0.0536\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9905 - loss: 0.0505 - val_accuracy: 0.9918 - val_loss: 0.0536\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9898 - loss: 0.0525 - val_accuracy: 0.9923 - val_loss: 0.0528\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9907 - loss: 0.0495 - val_accuracy: 0.9923 - val_loss: 0.0523\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9915 - loss: 0.0435 - val_accuracy: 0.9920 - val_loss: 0.0515\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9907 - loss: 0.0452 - val_accuracy: 0.9918 - val_loss: 0.0518\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9919 - loss: 0.0431 - val_accuracy: 0.9920 - val_loss: 0.0520\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9914 - loss: 0.0456 - val_accuracy: 0.9925 - val_loss: 0.0504\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9907 - loss: 0.0475 - val_accuracy: 0.9920 - val_loss: 0.0502\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9895 - loss: 0.0481 - val_accuracy: 0.9925 - val_loss: 0.0501\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9900 - loss: 0.0479 - val_accuracy: 0.9920 - val_loss: 0.0496\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9908 - loss: 0.0454 - val_accuracy: 0.9923 - val_loss: 0.0504\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9905 - loss: 0.0473 - val_accuracy: 0.9925 - val_loss: 0.0491\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9911 - loss: 0.0444 - val_accuracy: 0.9923 - val_loss: 0.0488\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9910 - loss: 0.0459 - val_accuracy: 0.9925 - val_loss: 0.0486\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9916 - loss: 0.0438 - val_accuracy: 0.9918 - val_loss: 0.0485\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9912 - loss: 0.0453 - val_accuracy: 0.9923 - val_loss: 0.0484\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9923 - loss: 0.0416 - val_accuracy: 0.9923 - val_loss: 0.0478\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9903 - loss: 0.0463 - val_accuracy: 0.9923 - val_loss: 0.0484\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9909 - loss: 0.0441 - val_accuracy: 0.9920 - val_loss: 0.0478\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9903 - loss: 0.0457 - val_accuracy: 0.9923 - val_loss: 0.0471\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9918 - loss: 0.0444 - val_accuracy: 0.9923 - val_loss: 0.0480\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9918 - loss: 0.0400 - val_accuracy: 0.9923 - val_loss: 0.0472\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9906 - loss: 0.0444 - val_accuracy: 0.9927 - val_loss: 0.0474\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9917 - loss: 0.0416 - val_accuracy: 0.9927 - val_loss: 0.0474\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9917 - loss: 0.0375 - val_accuracy: 0.9923 - val_loss: 0.0467\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9920 - loss: 0.0400 - val_accuracy: 0.9925 - val_loss: 0.0466\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9913 - loss: 0.0415 - val_accuracy: 0.9923 - val_loss: 0.0462\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9917 - loss: 0.0421 - val_accuracy: 0.9923 - val_loss: 0.0474\n",
    "Time taken in seconds  118.35755324363708"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60270340",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       0.99      0.86      0.92       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.93      0.96     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.98      0.88      0.93       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.98      0.94      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b4d64",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       0.99      0.86      0.92       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.93      0.96     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_1\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.98      0.88      0.93       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.98      0.94      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab4500",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Architecture Improvements:Deeper network: 128 → 64 → 1 neuronsIncreased model capacity for learning complex patternsTotal parameters: ~8,500 (3x more than Model 0)Performance Gains:Improved accuracy: approximately 75-85%Better learning of complex failure patternsMore stable training processOverfitting Control:Dropout layers (30%, 20%) help reduce overfittingSmaller gap between training and validation performanceBetter generalization compared to Model 0Training Characteristics:Longer training time due to increased complexityMore stable training curvesBetter convergence patternsModel Robustness:More robust feature learningBetter handling of the class imbalanceImproved overall model reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c882706",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Architecture Improvements:Deeper network: 128 → 64 → 1 neuronsIncreased model capacity for learning complex patternsTotal parameters: ~8,500 (3x more than Model 0)Performance Gains:Improved accuracy: approximately 75-85%Better learning of complex failure patternsMore stable training processOverfitting Control:Dropout layers (30%, 20%) help reduce overfittingSmaller gap between training and validation performanceBetter generalization compared to Model 0Training Characteristics:Longer training time due to increased complexityMore stable training curvesBetter convergence patternsModel Robustness:More robust feature learningBetter handling of the class imbalanceImproved overall model reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146d690",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Architecture Improvements:Deeper network: 128 → 64 → 1 neuronsIncreased model capacity for learning complex patternsTotal parameters: ~8,500 (3x more than Model 0)Performance Gains:Improved accuracy: approximately 75-85%Better learning of complex failure patternsMore stable training processOverfitting Control:Dropout layers (30%, 20%) help reduce overfittingSmaller gap between training and validation performanceBetter generalization compared to Model 0Training Characteristics:Longer training time due to increased complexityMore stable training curvesBetter convergence patternsModel Robustness:More robust feature learningBetter handling of the class imbalanceImproved overall model reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d555f6c",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Architecture Improvements:Deeper network: 128 → 64 → 1 neuronsIncreased model capacity for learning complex patternsTotal parameters: ~8,500 (3x more than Model 0)Performance Gains:Improved accuracy: approximately 75-85%Better learning of complex failure patternsMore stable training processOverfitting Control:Dropout layers (30%, 20%) help reduce overfittingSmaller gap between training and validation performanceBetter generalization compared to Model 0Training Characteristics:Longer training time due to increased complexityMore stable training curvesBetter convergence patternsModel Robustness:More robust feature learningBetter handling of the class imbalanceImproved overall model reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e57554",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4144d6",
   "metadata": {},
   "source": [
    "Architecture Improvements:Deeper network: 128 → 64 → 1 neuronsIncreased model capacity for learning complex patternsTotal parameters: ~8,500 (3x more than Model 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94defa16",
   "metadata": {},
   "source": [
    "Architecture Improvements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463fc767",
   "metadata": {},
   "source": [
    "Deeper network: 128 → 64 → 1 neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b93892",
   "metadata": {},
   "source": [
    "Increased model capacity for learning complex patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894ca3e",
   "metadata": {},
   "source": [
    "Total parameters: ~8,500 (3x more than Model 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccdc418",
   "metadata": {},
   "source": [
    "Performance Gains:Improved accuracy: approximately 75-85%Better learning of complex failure patternsMore stable training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9602497",
   "metadata": {},
   "source": [
    "Performance Gains:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e3b0c2",
   "metadata": {},
   "source": [
    "Improved accuracy: approximately 75-85%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef17f5",
   "metadata": {},
   "source": [
    "Better learning of complex failure patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3dfd8",
   "metadata": {},
   "source": [
    "More stable training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da00015",
   "metadata": {},
   "source": [
    "Overfitting Control:Dropout layers (30%, 20%) help reduce overfittingSmaller gap between training and validation performanceBetter generalization compared to Model 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87e3184",
   "metadata": {},
   "source": [
    "Overfitting Control:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b48bb7b",
   "metadata": {},
   "source": [
    "Dropout layers (30%, 20%) help reduce overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78d0a9",
   "metadata": {},
   "source": [
    "Smaller gap between training and validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ad12f",
   "metadata": {},
   "source": [
    "Better generalization compared to Model 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc719f22",
   "metadata": {},
   "source": [
    "Training Characteristics:Longer training time due to increased complexityMore stable training curvesBetter convergence patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7eb8c1",
   "metadata": {},
   "source": [
    "Training Characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c2803d",
   "metadata": {},
   "source": [
    "Longer training time due to increased complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23946b2e",
   "metadata": {},
   "source": [
    "More stable training curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f3e04",
   "metadata": {},
   "source": [
    "Better convergence patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415b58b",
   "metadata": {},
   "source": [
    "Model Robustness:More robust feature learningBetter handling of the class imbalanceImproved overall model reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2b3f8",
   "metadata": {},
   "source": [
    "Model Robustness:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcc557",
   "metadata": {},
   "source": [
    "More robust feature learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814a010",
   "metadata": {},
   "source": [
    "Better handling of the class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019ff580",
   "metadata": {},
   "source": [
    "Improved overall model reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a525480f",
   "metadata": {},
   "source": [
    "Model 2¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4affa9",
   "metadata": {},
   "source": [
    "Model 2¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cc823",
   "metadata": {},
   "source": [
    "Model 2¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64344c24",
   "metadata": {},
   "source": [
    "Model 2¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5066dfc",
   "metadata": {},
   "source": [
    "Model 2¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab9d2b1",
   "metadata": {},
   "source": [
    "In [18]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkfromtensorflow.keras.layersimportDropoutmodel_2=Sequential()model_2.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_2.add(Dropout(0.5))# Define the dropout ratemodel_2.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_2.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_2.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_2.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_2_train_perf=model_performance_classification(model_2,X_train_scaled,y_train)model_2_train_perfmodel_2_val_perf=model_performance_classification(model_2,X_val_scaled,y_val)model_2_val_perfy_train_pred_2=model_2.predict(X_train_scaled)y_val_pred_2=model_2.predict(X_val_scaled)print(\"Classification Report - Train data Model_2\",end=\"\\n\\n\")cr_train_model_2=classification_report(y_train,y_train_pred_2>0.5)print(cr_train_model_2)print(\"Classification Report - Validation data Model_2\",end=\"\\n\\n\")cr_val_model_2=classification_report(y_val,y_val_pred_2>0.5)print(cr_val_model_2)Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,32)             │2,080│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │33│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:15,617(61.00 KB)Trainable params:15,617(61.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s7ms/step - accuracy: 0.9199 - loss: 0.2999 - val_accuracy: 0.9520 - val_loss: 0.1615\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9496 - loss: 0.1694 - val_accuracy: 0.9693 - val_loss: 0.1255\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9596 - loss: 0.1381 - val_accuracy: 0.9737 - val_loss: 0.1054\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9656 - loss: 0.1193 - val_accuracy: 0.9783 - val_loss: 0.0921\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9696 - loss: 0.1118 - val_accuracy: 0.9793 - val_loss: 0.0825\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9678 - loss: 0.1105 - val_accuracy: 0.9808 - val_loss: 0.0762\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9730 - loss: 0.0941 - val_accuracy: 0.9827 - val_loss: 0.0702\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9733 - loss: 0.0960 - val_accuracy: 0.9837 - val_loss: 0.0676\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9776 - loss: 0.0835 - val_accuracy: 0.9855 - val_loss: 0.0639\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9787 - loss: 0.0808 - val_accuracy: 0.9870 - val_loss: 0.0614\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9768 - loss: 0.0885 - val_accuracy: 0.9872 - val_loss: 0.0603\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9813 - loss: 0.0762 - val_accuracy: 0.9875 - val_loss: 0.0583\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9810 - loss: 0.0759 - val_accuracy: 0.9880 - val_loss: 0.0568\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9821 - loss: 0.0736 - val_accuracy: 0.9862 - val_loss: 0.0570\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9830 - loss: 0.0706 - val_accuracy: 0.9872 - val_loss: 0.0552\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9831 - loss: 0.0650 - val_accuracy: 0.9887 - val_loss: 0.0536\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9833 - loss: 0.0668 - val_accuracy: 0.9890 - val_loss: 0.0523\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9835 - loss: 0.0671 - val_accuracy: 0.9887 - val_loss: 0.0517\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9846 - loss: 0.0638 - val_accuracy: 0.9893 - val_loss: 0.0502\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9832 - loss: 0.0676 - val_accuracy: 0.9887 - val_loss: 0.0508\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9832 - loss: 0.0672 - val_accuracy: 0.9883 - val_loss: 0.0515\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9858 - loss: 0.0592 - val_accuracy: 0.9893 - val_loss: 0.0491\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9875 - loss: 0.0542 - val_accuracy: 0.9893 - val_loss: 0.0486\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9868 - loss: 0.0623 - val_accuracy: 0.9895 - val_loss: 0.0484\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9831 - loss: 0.0634 - val_accuracy: 0.9900 - val_loss: 0.0474\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9845 - loss: 0.0593 - val_accuracy: 0.9895 - val_loss: 0.0478\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9866 - loss: 0.0551 - val_accuracy: 0.9900 - val_loss: 0.0460\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0604 - val_accuracy: 0.9893 - val_loss: 0.0466\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9842 - loss: 0.0702 - val_accuracy: 0.9905 - val_loss: 0.0458\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0575 - val_accuracy: 0.9898 - val_loss: 0.0461\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9874 - loss: 0.0533 - val_accuracy: 0.9912 - val_loss: 0.0446\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━4s5ms/step - accuracy: 0.9856 - loss: 0.0584 - val_accuracy: 0.9898 - val_loss: 0.0454\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9850 - loss: 0.0572 - val_accuracy: 0.9902 - val_loss: 0.0451\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9860 - loss: 0.0610 - val_accuracy: 0.9905 - val_loss: 0.0444\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9856 - loss: 0.0584 - val_accuracy: 0.9902 - val_loss: 0.0445\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0659 - val_accuracy: 0.9908 - val_loss: 0.0441\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9878 - loss: 0.0533 - val_accuracy: 0.9900 - val_loss: 0.0445\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9862 - loss: 0.0535 - val_accuracy: 0.9915 - val_loss: 0.0433\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9884 - loss: 0.0494 - val_accuracy: 0.9920 - val_loss: 0.0421\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9869 - loss: 0.0529 - val_accuracy: 0.9902 - val_loss: 0.0440\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9864 - loss: 0.0547 - val_accuracy: 0.9912 - val_loss: 0.0429\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9857 - loss: 0.0569 - val_accuracy: 0.9908 - val_loss: 0.0430\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9875 - loss: 0.0561 - val_accuracy: 0.9923 - val_loss: 0.0422\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9885 - loss: 0.0486 - val_accuracy: 0.9923 - val_loss: 0.0414\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9865 - loss: 0.0553 - val_accuracy: 0.9923 - val_loss: 0.0413\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9892 - loss: 0.0489 - val_accuracy: 0.9923 - val_loss: 0.0411\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9884 - loss: 0.0486 - val_accuracy: 0.9915 - val_loss: 0.0419\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9879 - loss: 0.0486 - val_accuracy: 0.9920 - val_loss: 0.0405\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9895 - loss: 0.0457 - val_accuracy: 0.9925 - val_loss: 0.0401\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9879 - loss: 0.0533 - val_accuracy: 0.9925 - val_loss: 0.0404\n",
    "Time taken in seconds  118.99163842201233500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_2\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       0.99      0.84      0.91       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.92      0.95     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_2\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.99      0.87      0.93       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.94      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b328b",
   "metadata": {},
   "source": [
    "In [18]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkfromtensorflow.keras.layersimportDropoutmodel_2=Sequential()model_2.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_2.add(Dropout(0.5))# Define the dropout ratemodel_2.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_2.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_2.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_2.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_2_train_perf=model_performance_classification(model_2,X_train_scaled,y_train)model_2_train_perfmodel_2_val_perf=model_performance_classification(model_2,X_val_scaled,y_val)model_2_val_perfy_train_pred_2=model_2.predict(X_train_scaled)y_val_pred_2=model_2.predict(X_val_scaled)print(\"Classification Report - Train data Model_2\",end=\"\\n\\n\")cr_train_model_2=classification_report(y_train,y_train_pred_2>0.5)print(cr_train_model_2)print(\"Classification Report - Validation data Model_2\",end=\"\\n\\n\")cr_val_model_2=classification_report(y_val,y_val_pred_2>0.5)print(cr_val_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34fa185",
   "metadata": {},
   "source": [
    "In [18]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkfromtensorflow.keras.layersimportDropoutmodel_2=Sequential()model_2.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_2.add(Dropout(0.5))# Define the dropout ratemodel_2.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_2.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_2.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_2.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_2_train_perf=model_performance_classification(model_2,X_train_scaled,y_train)model_2_train_perfmodel_2_val_perf=model_performance_classification(model_2,X_val_scaled,y_val)model_2_val_perfy_train_pred_2=model_2.predict(X_train_scaled)y_val_pred_2=model_2.predict(X_val_scaled)print(\"Classification Report - Train data Model_2\",end=\"\\n\\n\")cr_train_model_2=classification_report(y_train,y_train_pred_2>0.5)print(cr_train_model_2)print(\"Classification Report - Validation data Model_2\",end=\"\\n\\n\")cr_val_model_2=classification_report(y_val,y_val_pred_2>0.5)print(cr_val_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728af390",
   "metadata": {},
   "source": [
    "In [18]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954b4321",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkfromtensorflow.keras.layersimportDropoutmodel_2=Sequential()model_2.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_2.add(Dropout(0.5))# Define the dropout ratemodel_2.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_2.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_2.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_2.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_2_train_perf=model_performance_classification(model_2,X_train_scaled,y_train)model_2_train_perfmodel_2_val_perf=model_performance_classification(model_2,X_val_scaled,y_val)model_2_val_perfy_train_pred_2=model_2.predict(X_train_scaled)y_val_pred_2=model_2.predict(X_val_scaled)print(\"Classification Report - Train data Model_2\",end=\"\\n\\n\")cr_train_model_2=classification_report(y_train,y_train_pred_2>0.5)print(cr_train_model_2)print(\"Classification Report - Validation data Model_2\",end=\"\\n\\n\")cr_val_model_2=classification_report(y_val,y_val_pred_2>0.5)print(cr_val_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0dfdf",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkfromtensorflow.keras.layersimportDropoutmodel_2=Sequential()model_2.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_2.add(Dropout(0.5))# Define the dropout ratemodel_2.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_2.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_2.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_2.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_2_train_perf=model_performance_classification(model_2,X_train_scaled,y_train)model_2_train_perfmodel_2_val_perf=model_performance_classification(model_2,X_val_scaled,y_val)model_2_val_perfy_train_pred_2=model_2.predict(X_train_scaled)y_val_pred_2=model_2.predict(X_val_scaled)print(\"Classification Report - Train data Model_2\",end=\"\\n\\n\")cr_train_model_2=classification_report(y_train,y_train_pred_2>0.5)print(cr_train_model_2)print(\"Classification Report - Validation data Model_2\",end=\"\\n\\n\")cr_val_model_2=classification_report(y_val,y_val_pred_2>0.5)print(cr_val_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94ecfd",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkfromtensorflow.keras.layersimportDropoutmodel_2=Sequential()model_2.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_2.add(Dropout(0.5))# Define the dropout ratemodel_2.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_2.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_2.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_2.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_2.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_2_train_perf=model_performance_classification(model_2,X_train_scaled,y_train)model_2_train_perfmodel_2_val_perf=model_performance_classification(model_2,X_val_scaled,y_val)model_2_val_perfy_train_pred_2=model_2.predict(X_train_scaled)y_val_pred_2=model_2.predict(X_val_scaled)print(\"Classification Report - Train data Model_2\",end=\"\\n\\n\")cr_train_model_2=classification_report(y_train,y_train_pred_2>0.5)print(cr_train_model_2)print(\"Classification Report - Validation data Model_2\",end=\"\\n\\n\")cr_val_model_2=classification_report(y_val,y_val_pred_2>0.5)print(cr_val_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a308f5e0",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,32)             │2,080│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │33│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:15,617(61.00 KB)Trainable params:15,617(61.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s7ms/step - accuracy: 0.9199 - loss: 0.2999 - val_accuracy: 0.9520 - val_loss: 0.1615\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9496 - loss: 0.1694 - val_accuracy: 0.9693 - val_loss: 0.1255\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9596 - loss: 0.1381 - val_accuracy: 0.9737 - val_loss: 0.1054\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9656 - loss: 0.1193 - val_accuracy: 0.9783 - val_loss: 0.0921\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9696 - loss: 0.1118 - val_accuracy: 0.9793 - val_loss: 0.0825\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9678 - loss: 0.1105 - val_accuracy: 0.9808 - val_loss: 0.0762\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9730 - loss: 0.0941 - val_accuracy: 0.9827 - val_loss: 0.0702\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9733 - loss: 0.0960 - val_accuracy: 0.9837 - val_loss: 0.0676\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9776 - loss: 0.0835 - val_accuracy: 0.9855 - val_loss: 0.0639\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9787 - loss: 0.0808 - val_accuracy: 0.9870 - val_loss: 0.0614\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9768 - loss: 0.0885 - val_accuracy: 0.9872 - val_loss: 0.0603\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9813 - loss: 0.0762 - val_accuracy: 0.9875 - val_loss: 0.0583\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9810 - loss: 0.0759 - val_accuracy: 0.9880 - val_loss: 0.0568\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9821 - loss: 0.0736 - val_accuracy: 0.9862 - val_loss: 0.0570\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9830 - loss: 0.0706 - val_accuracy: 0.9872 - val_loss: 0.0552\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9831 - loss: 0.0650 - val_accuracy: 0.9887 - val_loss: 0.0536\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9833 - loss: 0.0668 - val_accuracy: 0.9890 - val_loss: 0.0523\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9835 - loss: 0.0671 - val_accuracy: 0.9887 - val_loss: 0.0517\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9846 - loss: 0.0638 - val_accuracy: 0.9893 - val_loss: 0.0502\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9832 - loss: 0.0676 - val_accuracy: 0.9887 - val_loss: 0.0508\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9832 - loss: 0.0672 - val_accuracy: 0.9883 - val_loss: 0.0515\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9858 - loss: 0.0592 - val_accuracy: 0.9893 - val_loss: 0.0491\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9875 - loss: 0.0542 - val_accuracy: 0.9893 - val_loss: 0.0486\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9868 - loss: 0.0623 - val_accuracy: 0.9895 - val_loss: 0.0484\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9831 - loss: 0.0634 - val_accuracy: 0.9900 - val_loss: 0.0474\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9845 - loss: 0.0593 - val_accuracy: 0.9895 - val_loss: 0.0478\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9866 - loss: 0.0551 - val_accuracy: 0.9900 - val_loss: 0.0460\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0604 - val_accuracy: 0.9893 - val_loss: 0.0466\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9842 - loss: 0.0702 - val_accuracy: 0.9905 - val_loss: 0.0458\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0575 - val_accuracy: 0.9898 - val_loss: 0.0461\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9874 - loss: 0.0533 - val_accuracy: 0.9912 - val_loss: 0.0446\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━4s5ms/step - accuracy: 0.9856 - loss: 0.0584 - val_accuracy: 0.9898 - val_loss: 0.0454\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9850 - loss: 0.0572 - val_accuracy: 0.9902 - val_loss: 0.0451\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9860 - loss: 0.0610 - val_accuracy: 0.9905 - val_loss: 0.0444\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9856 - loss: 0.0584 - val_accuracy: 0.9902 - val_loss: 0.0445\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0659 - val_accuracy: 0.9908 - val_loss: 0.0441\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9878 - loss: 0.0533 - val_accuracy: 0.9900 - val_loss: 0.0445\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9862 - loss: 0.0535 - val_accuracy: 0.9915 - val_loss: 0.0433\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9884 - loss: 0.0494 - val_accuracy: 0.9920 - val_loss: 0.0421\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9869 - loss: 0.0529 - val_accuracy: 0.9902 - val_loss: 0.0440\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9864 - loss: 0.0547 - val_accuracy: 0.9912 - val_loss: 0.0429\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9857 - loss: 0.0569 - val_accuracy: 0.9908 - val_loss: 0.0430\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9875 - loss: 0.0561 - val_accuracy: 0.9923 - val_loss: 0.0422\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9885 - loss: 0.0486 - val_accuracy: 0.9923 - val_loss: 0.0414\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9865 - loss: 0.0553 - val_accuracy: 0.9923 - val_loss: 0.0413\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9892 - loss: 0.0489 - val_accuracy: 0.9923 - val_loss: 0.0411\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9884 - loss: 0.0486 - val_accuracy: 0.9915 - val_loss: 0.0419\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9879 - loss: 0.0486 - val_accuracy: 0.9920 - val_loss: 0.0405\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9895 - loss: 0.0457 - val_accuracy: 0.9925 - val_loss: 0.0401\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9879 - loss: 0.0533 - val_accuracy: 0.9925 - val_loss: 0.0404\n",
    "Time taken in seconds  118.99163842201233500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_2\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       0.99      0.84      0.91       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.92      0.95     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_2\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.99      0.87      0.93       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.94      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2241b9",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,32)             │2,080│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │33│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:15,617(61.00 KB)Trainable params:15,617(61.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s7ms/step - accuracy: 0.9199 - loss: 0.2999 - val_accuracy: 0.9520 - val_loss: 0.1615\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9496 - loss: 0.1694 - val_accuracy: 0.9693 - val_loss: 0.1255\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9596 - loss: 0.1381 - val_accuracy: 0.9737 - val_loss: 0.1054\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9656 - loss: 0.1193 - val_accuracy: 0.9783 - val_loss: 0.0921\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9696 - loss: 0.1118 - val_accuracy: 0.9793 - val_loss: 0.0825\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9678 - loss: 0.1105 - val_accuracy: 0.9808 - val_loss: 0.0762\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9730 - loss: 0.0941 - val_accuracy: 0.9827 - val_loss: 0.0702\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9733 - loss: 0.0960 - val_accuracy: 0.9837 - val_loss: 0.0676\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9776 - loss: 0.0835 - val_accuracy: 0.9855 - val_loss: 0.0639\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9787 - loss: 0.0808 - val_accuracy: 0.9870 - val_loss: 0.0614\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9768 - loss: 0.0885 - val_accuracy: 0.9872 - val_loss: 0.0603\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9813 - loss: 0.0762 - val_accuracy: 0.9875 - val_loss: 0.0583\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9810 - loss: 0.0759 - val_accuracy: 0.9880 - val_loss: 0.0568\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9821 - loss: 0.0736 - val_accuracy: 0.9862 - val_loss: 0.0570\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9830 - loss: 0.0706 - val_accuracy: 0.9872 - val_loss: 0.0552\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9831 - loss: 0.0650 - val_accuracy: 0.9887 - val_loss: 0.0536\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9833 - loss: 0.0668 - val_accuracy: 0.9890 - val_loss: 0.0523\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9835 - loss: 0.0671 - val_accuracy: 0.9887 - val_loss: 0.0517\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9846 - loss: 0.0638 - val_accuracy: 0.9893 - val_loss: 0.0502\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9832 - loss: 0.0676 - val_accuracy: 0.9887 - val_loss: 0.0508\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9832 - loss: 0.0672 - val_accuracy: 0.9883 - val_loss: 0.0515\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9858 - loss: 0.0592 - val_accuracy: 0.9893 - val_loss: 0.0491\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9875 - loss: 0.0542 - val_accuracy: 0.9893 - val_loss: 0.0486\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9868 - loss: 0.0623 - val_accuracy: 0.9895 - val_loss: 0.0484\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9831 - loss: 0.0634 - val_accuracy: 0.9900 - val_loss: 0.0474\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9845 - loss: 0.0593 - val_accuracy: 0.9895 - val_loss: 0.0478\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9866 - loss: 0.0551 - val_accuracy: 0.9900 - val_loss: 0.0460\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0604 - val_accuracy: 0.9893 - val_loss: 0.0466\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9842 - loss: 0.0702 - val_accuracy: 0.9905 - val_loss: 0.0458\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0575 - val_accuracy: 0.9898 - val_loss: 0.0461\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9874 - loss: 0.0533 - val_accuracy: 0.9912 - val_loss: 0.0446\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━4s5ms/step - accuracy: 0.9856 - loss: 0.0584 - val_accuracy: 0.9898 - val_loss: 0.0454\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9850 - loss: 0.0572 - val_accuracy: 0.9902 - val_loss: 0.0451\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9860 - loss: 0.0610 - val_accuracy: 0.9905 - val_loss: 0.0444\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9856 - loss: 0.0584 - val_accuracy: 0.9902 - val_loss: 0.0445\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0659 - val_accuracy: 0.9908 - val_loss: 0.0441\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9878 - loss: 0.0533 - val_accuracy: 0.9900 - val_loss: 0.0445\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9862 - loss: 0.0535 - val_accuracy: 0.9915 - val_loss: 0.0433\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9884 - loss: 0.0494 - val_accuracy: 0.9920 - val_loss: 0.0421\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9869 - loss: 0.0529 - val_accuracy: 0.9902 - val_loss: 0.0440\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9864 - loss: 0.0547 - val_accuracy: 0.9912 - val_loss: 0.0429\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9857 - loss: 0.0569 - val_accuracy: 0.9908 - val_loss: 0.0430\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9875 - loss: 0.0561 - val_accuracy: 0.9923 - val_loss: 0.0422\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9885 - loss: 0.0486 - val_accuracy: 0.9923 - val_loss: 0.0414\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9865 - loss: 0.0553 - val_accuracy: 0.9923 - val_loss: 0.0413\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9892 - loss: 0.0489 - val_accuracy: 0.9923 - val_loss: 0.0411\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9884 - loss: 0.0486 - val_accuracy: 0.9915 - val_loss: 0.0419\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9879 - loss: 0.0486 - val_accuracy: 0.9920 - val_loss: 0.0405\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9895 - loss: 0.0457 - val_accuracy: 0.9925 - val_loss: 0.0401\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9879 - loss: 0.0533 - val_accuracy: 0.9925 - val_loss: 0.0404\n",
    "Time taken in seconds  118.99163842201233500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_2\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       0.99      0.84      0.91       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.92      0.95     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_2\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.99      0.87      0.93       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.94      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e709e",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968deed2",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e6256",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,32)             │2,080│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │33│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17f16f",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,32)             │2,080│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │33│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c035069",
   "metadata": {},
   "source": [
    "Total params:15,617(61.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003e718",
   "metadata": {},
   "source": [
    "Total params:15,617(61.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776a45e",
   "metadata": {},
   "source": [
    "Trainable params:15,617(61.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546cb31",
   "metadata": {},
   "source": [
    "Trainable params:15,617(61.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ded81",
   "metadata": {},
   "source": [
    "Non-trainable params:0(0.00 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7761ba",
   "metadata": {},
   "source": [
    "Non-trainable params:0(0.00 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22fc48",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s7ms/step - accuracy: 0.9199 - loss: 0.2999 - val_accuracy: 0.9520 - val_loss: 0.1615\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9496 - loss: 0.1694 - val_accuracy: 0.9693 - val_loss: 0.1255\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9596 - loss: 0.1381 - val_accuracy: 0.9737 - val_loss: 0.1054\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9656 - loss: 0.1193 - val_accuracy: 0.9783 - val_loss: 0.0921\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9696 - loss: 0.1118 - val_accuracy: 0.9793 - val_loss: 0.0825\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9678 - loss: 0.1105 - val_accuracy: 0.9808 - val_loss: 0.0762\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9730 - loss: 0.0941 - val_accuracy: 0.9827 - val_loss: 0.0702\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9733 - loss: 0.0960 - val_accuracy: 0.9837 - val_loss: 0.0676\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9776 - loss: 0.0835 - val_accuracy: 0.9855 - val_loss: 0.0639\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9787 - loss: 0.0808 - val_accuracy: 0.9870 - val_loss: 0.0614\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9768 - loss: 0.0885 - val_accuracy: 0.9872 - val_loss: 0.0603\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9813 - loss: 0.0762 - val_accuracy: 0.9875 - val_loss: 0.0583\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9810 - loss: 0.0759 - val_accuracy: 0.9880 - val_loss: 0.0568\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9821 - loss: 0.0736 - val_accuracy: 0.9862 - val_loss: 0.0570\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9830 - loss: 0.0706 - val_accuracy: 0.9872 - val_loss: 0.0552\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9831 - loss: 0.0650 - val_accuracy: 0.9887 - val_loss: 0.0536\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9833 - loss: 0.0668 - val_accuracy: 0.9890 - val_loss: 0.0523\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9835 - loss: 0.0671 - val_accuracy: 0.9887 - val_loss: 0.0517\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9846 - loss: 0.0638 - val_accuracy: 0.9893 - val_loss: 0.0502\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9832 - loss: 0.0676 - val_accuracy: 0.9887 - val_loss: 0.0508\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9832 - loss: 0.0672 - val_accuracy: 0.9883 - val_loss: 0.0515\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9858 - loss: 0.0592 - val_accuracy: 0.9893 - val_loss: 0.0491\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9875 - loss: 0.0542 - val_accuracy: 0.9893 - val_loss: 0.0486\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9868 - loss: 0.0623 - val_accuracy: 0.9895 - val_loss: 0.0484\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9831 - loss: 0.0634 - val_accuracy: 0.9900 - val_loss: 0.0474\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9845 - loss: 0.0593 - val_accuracy: 0.9895 - val_loss: 0.0478\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9866 - loss: 0.0551 - val_accuracy: 0.9900 - val_loss: 0.0460\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0604 - val_accuracy: 0.9893 - val_loss: 0.0466\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9842 - loss: 0.0702 - val_accuracy: 0.9905 - val_loss: 0.0458\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0575 - val_accuracy: 0.9898 - val_loss: 0.0461\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9874 - loss: 0.0533 - val_accuracy: 0.9912 - val_loss: 0.0446\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━4s5ms/step - accuracy: 0.9856 - loss: 0.0584 - val_accuracy: 0.9898 - val_loss: 0.0454\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9850 - loss: 0.0572 - val_accuracy: 0.9902 - val_loss: 0.0451\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9860 - loss: 0.0610 - val_accuracy: 0.9905 - val_loss: 0.0444\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9856 - loss: 0.0584 - val_accuracy: 0.9902 - val_loss: 0.0445\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0659 - val_accuracy: 0.9908 - val_loss: 0.0441\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9878 - loss: 0.0533 - val_accuracy: 0.9900 - val_loss: 0.0445\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9862 - loss: 0.0535 - val_accuracy: 0.9915 - val_loss: 0.0433\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9884 - loss: 0.0494 - val_accuracy: 0.9920 - val_loss: 0.0421\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9869 - loss: 0.0529 - val_accuracy: 0.9902 - val_loss: 0.0440\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9864 - loss: 0.0547 - val_accuracy: 0.9912 - val_loss: 0.0429\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9857 - loss: 0.0569 - val_accuracy: 0.9908 - val_loss: 0.0430\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9875 - loss: 0.0561 - val_accuracy: 0.9923 - val_loss: 0.0422\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9885 - loss: 0.0486 - val_accuracy: 0.9923 - val_loss: 0.0414\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9865 - loss: 0.0553 - val_accuracy: 0.9923 - val_loss: 0.0413\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9892 - loss: 0.0489 - val_accuracy: 0.9923 - val_loss: 0.0411\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9884 - loss: 0.0486 - val_accuracy: 0.9915 - val_loss: 0.0419\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9879 - loss: 0.0486 - val_accuracy: 0.9920 - val_loss: 0.0405\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9895 - loss: 0.0457 - val_accuracy: 0.9925 - val_loss: 0.0401\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9879 - loss: 0.0533 - val_accuracy: 0.9925 - val_loss: 0.0404\n",
    "Time taken in seconds  118.99163842201233"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d85ea6",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s7ms/step - accuracy: 0.9199 - loss: 0.2999 - val_accuracy: 0.9520 - val_loss: 0.1615\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9496 - loss: 0.1694 - val_accuracy: 0.9693 - val_loss: 0.1255\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9596 - loss: 0.1381 - val_accuracy: 0.9737 - val_loss: 0.1054\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9656 - loss: 0.1193 - val_accuracy: 0.9783 - val_loss: 0.0921\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9696 - loss: 0.1118 - val_accuracy: 0.9793 - val_loss: 0.0825\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9678 - loss: 0.1105 - val_accuracy: 0.9808 - val_loss: 0.0762\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9730 - loss: 0.0941 - val_accuracy: 0.9827 - val_loss: 0.0702\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9733 - loss: 0.0960 - val_accuracy: 0.9837 - val_loss: 0.0676\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9776 - loss: 0.0835 - val_accuracy: 0.9855 - val_loss: 0.0639\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9787 - loss: 0.0808 - val_accuracy: 0.9870 - val_loss: 0.0614\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9768 - loss: 0.0885 - val_accuracy: 0.9872 - val_loss: 0.0603\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9813 - loss: 0.0762 - val_accuracy: 0.9875 - val_loss: 0.0583\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9810 - loss: 0.0759 - val_accuracy: 0.9880 - val_loss: 0.0568\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9821 - loss: 0.0736 - val_accuracy: 0.9862 - val_loss: 0.0570\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9830 - loss: 0.0706 - val_accuracy: 0.9872 - val_loss: 0.0552\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9831 - loss: 0.0650 - val_accuracy: 0.9887 - val_loss: 0.0536\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9833 - loss: 0.0668 - val_accuracy: 0.9890 - val_loss: 0.0523\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9835 - loss: 0.0671 - val_accuracy: 0.9887 - val_loss: 0.0517\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9846 - loss: 0.0638 - val_accuracy: 0.9893 - val_loss: 0.0502\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9832 - loss: 0.0676 - val_accuracy: 0.9887 - val_loss: 0.0508\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9832 - loss: 0.0672 - val_accuracy: 0.9883 - val_loss: 0.0515\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9858 - loss: 0.0592 - val_accuracy: 0.9893 - val_loss: 0.0491\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9875 - loss: 0.0542 - val_accuracy: 0.9893 - val_loss: 0.0486\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9868 - loss: 0.0623 - val_accuracy: 0.9895 - val_loss: 0.0484\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9831 - loss: 0.0634 - val_accuracy: 0.9900 - val_loss: 0.0474\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9845 - loss: 0.0593 - val_accuracy: 0.9895 - val_loss: 0.0478\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9866 - loss: 0.0551 - val_accuracy: 0.9900 - val_loss: 0.0460\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0604 - val_accuracy: 0.9893 - val_loss: 0.0466\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9842 - loss: 0.0702 - val_accuracy: 0.9905 - val_loss: 0.0458\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0575 - val_accuracy: 0.9898 - val_loss: 0.0461\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9874 - loss: 0.0533 - val_accuracy: 0.9912 - val_loss: 0.0446\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━4s5ms/step - accuracy: 0.9856 - loss: 0.0584 - val_accuracy: 0.9898 - val_loss: 0.0454\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9850 - loss: 0.0572 - val_accuracy: 0.9902 - val_loss: 0.0451\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9860 - loss: 0.0610 - val_accuracy: 0.9905 - val_loss: 0.0444\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9856 - loss: 0.0584 - val_accuracy: 0.9902 - val_loss: 0.0445\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9849 - loss: 0.0659 - val_accuracy: 0.9908 - val_loss: 0.0441\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9878 - loss: 0.0533 - val_accuracy: 0.9900 - val_loss: 0.0445\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9862 - loss: 0.0535 - val_accuracy: 0.9915 - val_loss: 0.0433\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9884 - loss: 0.0494 - val_accuracy: 0.9920 - val_loss: 0.0421\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9869 - loss: 0.0529 - val_accuracy: 0.9902 - val_loss: 0.0440\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9864 - loss: 0.0547 - val_accuracy: 0.9912 - val_loss: 0.0429\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9857 - loss: 0.0569 - val_accuracy: 0.9908 - val_loss: 0.0430\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9875 - loss: 0.0561 - val_accuracy: 0.9923 - val_loss: 0.0422\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9885 - loss: 0.0486 - val_accuracy: 0.9923 - val_loss: 0.0414\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9865 - loss: 0.0553 - val_accuracy: 0.9923 - val_loss: 0.0413\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9892 - loss: 0.0489 - val_accuracy: 0.9923 - val_loss: 0.0411\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9884 - loss: 0.0486 - val_accuracy: 0.9915 - val_loss: 0.0419\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9879 - loss: 0.0486 - val_accuracy: 0.9920 - val_loss: 0.0405\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9895 - loss: 0.0457 - val_accuracy: 0.9925 - val_loss: 0.0401\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9879 - loss: 0.0533 - val_accuracy: 0.9925 - val_loss: 0.0404\n",
    "Time taken in seconds  118.99163842201233"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11065d8a",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_2\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       0.99      0.84      0.91       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.92      0.95     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_2\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.99      0.87      0.93       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.94      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85891ad5",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_2\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       0.99      0.84      0.91       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.92      0.95     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_2\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.99      0.87      0.93       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.94      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99188276",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Regularization Impact:50% dropout rate significantly reduces overfittingForces model to learn redundant feature representationsBetter balance between training and validation performancePerformance Balance:Training and validation curves are more closely alignedReduced gap between training and validation metricsMore reliable performance estimatesModel Robustness:Model generalizes better to unseen dataLess sensitive to noise in training dataMore stable predictionsArchitecture Benefits:Deeper network (128 → 64 → 32 → 1) with dropoutBetter feature learning through multiple layersImproved handling of complex failure patternsValidation Performance:Likely the best validation performance among first three modelsBetter F1-score due to improved generalizationMore reliable model for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01224e7b",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Regularization Impact:50% dropout rate significantly reduces overfittingForces model to learn redundant feature representationsBetter balance between training and validation performancePerformance Balance:Training and validation curves are more closely alignedReduced gap between training and validation metricsMore reliable performance estimatesModel Robustness:Model generalizes better to unseen dataLess sensitive to noise in training dataMore stable predictionsArchitecture Benefits:Deeper network (128 → 64 → 32 → 1) with dropoutBetter feature learning through multiple layersImproved handling of complex failure patternsValidation Performance:Likely the best validation performance among first three modelsBetter F1-score due to improved generalizationMore reliable model for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6660041",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Regularization Impact:50% dropout rate significantly reduces overfittingForces model to learn redundant feature representationsBetter balance between training and validation performancePerformance Balance:Training and validation curves are more closely alignedReduced gap between training and validation metricsMore reliable performance estimatesModel Robustness:Model generalizes better to unseen dataLess sensitive to noise in training dataMore stable predictionsArchitecture Benefits:Deeper network (128 → 64 → 32 → 1) with dropoutBetter feature learning through multiple layersImproved handling of complex failure patternsValidation Performance:Likely the best validation performance among first three modelsBetter F1-score due to improved generalizationMore reliable model for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88204926",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Regularization Impact:50% dropout rate significantly reduces overfittingForces model to learn redundant feature representationsBetter balance between training and validation performancePerformance Balance:Training and validation curves are more closely alignedReduced gap between training and validation metricsMore reliable performance estimatesModel Robustness:Model generalizes better to unseen dataLess sensitive to noise in training dataMore stable predictionsArchitecture Benefits:Deeper network (128 → 64 → 32 → 1) with dropoutBetter feature learning through multiple layersImproved handling of complex failure patternsValidation Performance:Likely the best validation performance among first three modelsBetter F1-score due to improved generalizationMore reliable model for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec71ffd",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711de38",
   "metadata": {},
   "source": [
    "Regularization Impact:50% dropout rate significantly reduces overfittingForces model to learn redundant feature representationsBetter balance between training and validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672080f",
   "metadata": {},
   "source": [
    "Regularization Impact:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aae3e1",
   "metadata": {},
   "source": [
    "50% dropout rate significantly reduces overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e57e9",
   "metadata": {},
   "source": [
    "Forces model to learn redundant feature representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57e357",
   "metadata": {},
   "source": [
    "Better balance between training and validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad3c26",
   "metadata": {},
   "source": [
    "Performance Balance:Training and validation curves are more closely alignedReduced gap between training and validation metricsMore reliable performance estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70379a65",
   "metadata": {},
   "source": [
    "Performance Balance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bacd72",
   "metadata": {},
   "source": [
    "Training and validation curves are more closely aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bab53f",
   "metadata": {},
   "source": [
    "Reduced gap between training and validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8b460",
   "metadata": {},
   "source": [
    "More reliable performance estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438951a",
   "metadata": {},
   "source": [
    "Model Robustness:Model generalizes better to unseen dataLess sensitive to noise in training dataMore stable predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edcad25",
   "metadata": {},
   "source": [
    "Model Robustness:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b23238",
   "metadata": {},
   "source": [
    "Model generalizes better to unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b12cdb",
   "metadata": {},
   "source": [
    "Less sensitive to noise in training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f680aa0",
   "metadata": {},
   "source": [
    "More stable predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735314e5",
   "metadata": {},
   "source": [
    "Architecture Benefits:Deeper network (128 → 64 → 32 → 1) with dropoutBetter feature learning through multiple layersImproved handling of complex failure patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c32439",
   "metadata": {},
   "source": [
    "Architecture Benefits:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0a1be",
   "metadata": {},
   "source": [
    "Deeper network (128 → 64 → 32 → 1) with dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0fa316",
   "metadata": {},
   "source": [
    "Better feature learning through multiple layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fcf16b",
   "metadata": {},
   "source": [
    "Improved handling of complex failure patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58156f9",
   "metadata": {},
   "source": [
    "Validation Performance:Likely the best validation performance among first three modelsBetter F1-score due to improved generalizationMore reliable model for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6bf765",
   "metadata": {},
   "source": [
    "Validation Performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf3473",
   "metadata": {},
   "source": [
    "Likely the best validation performance among first three models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbc79d",
   "metadata": {},
   "source": [
    "Better F1-score due to improved generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4938a5",
   "metadata": {},
   "source": [
    "More reliable model for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b086cc",
   "metadata": {},
   "source": [
    "Model 3¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76609498",
   "metadata": {},
   "source": [
    "Model 3¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d267845e",
   "metadata": {},
   "source": [
    "Model 3¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bbbc42",
   "metadata": {},
   "source": [
    "Model 3¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e7d66b",
   "metadata": {},
   "source": [
    "Model 3¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4f9a9",
   "metadata": {},
   "source": [
    "In [19]:# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))# Convert y_train to integers# Create a dictionary mapping class indices to their respective class weightscw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"Class weights:\",cw_dict)# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()model_3=Sequential()model_3.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_3.add(Dropout(0.3))# Define the dropout ratemodel_3.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_3.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_3.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_3.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_3_train_perf=model_performance_classification(model_3,X_train_scaled,y_train)model_3_train_perfmodel_3_val_perf=model_performance_classification(model_3,X_val_scaled,y_val)model_3_val_perfy_train_pred_3=model_3.predict(X_train_scaled)y_val_pred_3=model_3.predict(X_val_scaled)print(\"Classification Report - Train data Model_3\",end=\"\\n\\n\")cr_train_model_3=classification_report(y_train,y_train_pred_3>0.5)print(cr_train_model_3)print(\"Classification Report - Validation data Model_3\",end=\"\\n\\n\")cr_val_model_3=classification_report(y_val,y_val_pred_3>0.5)print(cr_val_model_3)Class weights: {0: np.float64(1.0587612493382743), 1: np.float64(18.01801801801802)}Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,32)             │2,080│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │33│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:15,617(61.00 KB)Trainable params:15,617(61.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━7s10ms/step - accuracy: 0.7493 - loss: 0.8955 - val_accuracy: 0.9230 - val_loss: 0.2544\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━5s9ms/step - accuracy: 0.9254 - loss: 0.5270 - val_accuracy: 0.9492 - val_loss: 0.2082\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9472 - loss: 0.4838 - val_accuracy: 0.9810 - val_loss: 0.1346\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9566 - loss: 0.4455 - val_accuracy: 0.9525 - val_loss: 0.2008\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9586 - loss: 0.4021 - val_accuracy: 0.9770 - val_loss: 0.1644\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9656 - loss: 0.3981 - val_accuracy: 0.9868 - val_loss: 0.1182\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9733 - loss: 0.3700 - val_accuracy: 0.9870 - val_loss: 0.1302\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9736 - loss: 0.3813 - val_accuracy: 0.9868 - val_loss: 0.1167\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9750 - loss: 0.3778 - val_accuracy: 0.9858 - val_loss: 0.1197\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9749 - loss: 0.3637 - val_accuracy: 0.9895 - val_loss: 0.0847\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9760 - loss: 0.3538 - val_accuracy: 0.9787 - val_loss: 0.1179\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9738 - loss: 0.3530 - val_accuracy: 0.9822 - val_loss: 0.1142\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9811 - loss: 0.3086 - val_accuracy: 0.9810 - val_loss: 0.1083\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9770 - loss: 0.3218 - val_accuracy: 0.9865 - val_loss: 0.1176\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9788 - loss: 0.3194 - val_accuracy: 0.9868 - val_loss: 0.1000\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9777 - loss: 0.3256 - val_accuracy: 0.9927 - val_loss: 0.0964\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9813 - loss: 0.3764 - val_accuracy: 0.9880 - val_loss: 0.0989\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9801 - loss: 0.3088 - val_accuracy: 0.9367 - val_loss: 0.2433\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9737 - loss: 0.3159 - val_accuracy: 0.9877 - val_loss: 0.1143\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9728 - loss: 0.3321 - val_accuracy: 0.9880 - val_loss: 0.1020\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9830 - loss: 0.3020 - val_accuracy: 0.9908 - val_loss: 0.0843\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9784 - loss: 0.3303 - val_accuracy: 0.9885 - val_loss: 0.1097\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9798 - loss: 0.3292 - val_accuracy: 0.9898 - val_loss: 0.0802\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9805 - loss: 0.3287 - val_accuracy: 0.9845 - val_loss: 0.1112\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9818 - loss: 0.2988 - val_accuracy: 0.9735 - val_loss: 0.1313\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9791 - loss: 0.3160 - val_accuracy: 0.9885 - val_loss: 0.0974\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9792 - loss: 0.2991 - val_accuracy: 0.9880 - val_loss: 0.0933\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━4s5ms/step - accuracy: 0.9839 - loss: 0.2522 - val_accuracy: 0.9775 - val_loss: 0.1243\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9770 - loss: 0.3059 - val_accuracy: 0.9820 - val_loss: 0.0983\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9777 - loss: 0.3129 - val_accuracy: 0.9898 - val_loss: 0.0681\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9785 - loss: 0.3255 - val_accuracy: 0.9920 - val_loss: 0.0667\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9827 - loss: 0.2845 - val_accuracy: 0.9900 - val_loss: 0.0856\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9818 - loss: 0.2771 - val_accuracy: 0.9810 - val_loss: 0.1113\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9820 - loss: 0.3112 - val_accuracy: 0.9905 - val_loss: 0.0773\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9779 - loss: 0.2814 - val_accuracy: 0.9860 - val_loss: 0.0949\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9822 - loss: 0.2912 - val_accuracy: 0.9910 - val_loss: 0.0912\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9842 - loss: 0.2471 - val_accuracy: 0.9862 - val_loss: 0.1072\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9806 - loss: 0.2682 - val_accuracy: 0.9852 - val_loss: 0.1308\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9826 - loss: 0.2457 - val_accuracy: 0.9822 - val_loss: 0.1024\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9802 - loss: 0.2951 - val_accuracy: 0.9835 - val_loss: 0.1048\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9811 - loss: 0.2589 - val_accuracy: 0.9845 - val_loss: 0.1091\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9812 - loss: 0.2660 - val_accuracy: 0.9902 - val_loss: 0.0756\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9796 - loss: 0.2946 - val_accuracy: 0.9870 - val_loss: 0.1008\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9825 - loss: 0.2689 - val_accuracy: 0.9862 - val_loss: 0.1047\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9816 - loss: 0.2397 - val_accuracy: 0.9860 - val_loss: 0.0977\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9839 - loss: 0.2109 - val_accuracy: 0.9847 - val_loss: 0.0975\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9789 - loss: 0.2715 - val_accuracy: 0.9900 - val_loss: 0.0755\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9829 - loss: 0.2275 - val_accuracy: 0.9902 - val_loss: 0.0818\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9841 - loss: 0.2248 - val_accuracy: 0.9850 - val_loss: 0.1051\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9827 - loss: 0.2573 - val_accuracy: 0.9827 - val_loss: 0.1045\n",
    "Time taken in seconds  115.92812919616699500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_3\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     15112\n",
    "         1.0       0.86      0.94      0.90       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.93      0.97      0.95     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_3\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99      3778\n",
    "         1.0       0.80      0.92      0.86       222\n",
    "\n",
    "    accuracy                           0.98      4000\n",
    "   macro avg       0.90      0.95      0.92      4000\n",
    "weighted avg       0.98      0.98      0.98      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688bba03",
   "metadata": {},
   "source": [
    "In [19]:# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))# Convert y_train to integers# Create a dictionary mapping class indices to their respective class weightscw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"Class weights:\",cw_dict)# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()model_3=Sequential()model_3.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_3.add(Dropout(0.3))# Define the dropout ratemodel_3.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_3.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_3.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_3.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_3_train_perf=model_performance_classification(model_3,X_train_scaled,y_train)model_3_train_perfmodel_3_val_perf=model_performance_classification(model_3,X_val_scaled,y_val)model_3_val_perfy_train_pred_3=model_3.predict(X_train_scaled)y_val_pred_3=model_3.predict(X_val_scaled)print(\"Classification Report - Train data Model_3\",end=\"\\n\\n\")cr_train_model_3=classification_report(y_train,y_train_pred_3>0.5)print(cr_train_model_3)print(\"Classification Report - Validation data Model_3\",end=\"\\n\\n\")cr_val_model_3=classification_report(y_val,y_val_pred_3>0.5)print(cr_val_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44f0232",
   "metadata": {},
   "source": [
    "In [19]:# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))# Convert y_train to integers# Create a dictionary mapping class indices to their respective class weightscw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"Class weights:\",cw_dict)# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()model_3=Sequential()model_3.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_3.add(Dropout(0.3))# Define the dropout ratemodel_3.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_3.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_3.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_3.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_3_train_perf=model_performance_classification(model_3,X_train_scaled,y_train)model_3_train_perfmodel_3_val_perf=model_performance_classification(model_3,X_val_scaled,y_val)model_3_val_perfy_train_pred_3=model_3.predict(X_train_scaled)y_val_pred_3=model_3.predict(X_val_scaled)print(\"Classification Report - Train data Model_3\",end=\"\\n\\n\")cr_train_model_3=classification_report(y_train,y_train_pred_3>0.5)print(cr_train_model_3)print(\"Classification Report - Validation data Model_3\",end=\"\\n\\n\")cr_val_model_3=classification_report(y_val,y_val_pred_3>0.5)print(cr_val_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d1263",
   "metadata": {},
   "source": [
    "In [19]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb463f",
   "metadata": {},
   "source": [
    "# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))# Convert y_train to integers# Create a dictionary mapping class indices to their respective class weightscw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"Class weights:\",cw_dict)# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()model_3=Sequential()model_3.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_3.add(Dropout(0.3))# Define the dropout ratemodel_3.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_3.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_3.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_3.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_3_train_perf=model_performance_classification(model_3,X_train_scaled,y_train)model_3_train_perfmodel_3_val_perf=model_performance_classification(model_3,X_val_scaled,y_val)model_3_val_perfy_train_pred_3=model_3.predict(X_train_scaled)y_val_pred_3=model_3.predict(X_val_scaled)print(\"Classification Report - Train data Model_3\",end=\"\\n\\n\")cr_train_model_3=classification_report(y_train,y_train_pred_3>0.5)print(cr_train_model_3)print(\"Classification Report - Validation data Model_3\",end=\"\\n\\n\")cr_val_model_3=classification_report(y_val,y_val_pred_3>0.5)print(cr_val_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae7151",
   "metadata": {},
   "source": [
    "# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))# Convert y_train to integers# Create a dictionary mapping class indices to their respective class weightscw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"Class weights:\",cw_dict)# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()model_3=Sequential()model_3.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_3.add(Dropout(0.3))# Define the dropout ratemodel_3.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_3.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_3.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_3.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_3_train_perf=model_performance_classification(model_3,X_train_scaled,y_train)model_3_train_perfmodel_3_val_perf=model_performance_classification(model_3,X_val_scaled,y_val)model_3_val_perfy_train_pred_3=model_3.predict(X_train_scaled)y_val_pred_3=model_3.predict(X_val_scaled)print(\"Classification Report - Train data Model_3\",end=\"\\n\\n\")cr_train_model_3=classification_report(y_train,y_train_pred_3>0.5)print(cr_train_model_3)print(\"Classification Report - Validation data Model_3\",end=\"\\n\\n\")cr_val_model_3=classification_report(y_val,y_val_pred_3>0.5)print(cr_val_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99419f5c",
   "metadata": {},
   "source": [
    "# Calculate class weights for imbalanced datasetcw=(y_train.shape[0])/np.bincount(y_train.astype(int))# Convert y_train to integers# Create a dictionary mapping class indices to their respective class weightscw_dict={}foriinrange(cw.shape[0]):cw_dict[i]=cw[i]print(\"Class weights:\",cw_dict)# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()model_3=Sequential()model_3.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_3.add(Dropout(0.3))# Define the dropout ratemodel_3.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(32,activation=\"relu\"))# Define the number of neurons and activation functionmodel_3.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_3.summary()optimizer=tf.keras.optimizers.SGD()# defining SGD as the optimizer to be usedmodel_3.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_3.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_3_train_perf=model_performance_classification(model_3,X_train_scaled,y_train)model_3_train_perfmodel_3_val_perf=model_performance_classification(model_3,X_val_scaled,y_val)model_3_val_perfy_train_pred_3=model_3.predict(X_train_scaled)y_val_pred_3=model_3.predict(X_val_scaled)print(\"Classification Report - Train data Model_3\",end=\"\\n\\n\")cr_train_model_3=classification_report(y_train,y_train_pred_3>0.5)print(cr_train_model_3)print(\"Classification Report - Validation data Model_3\",end=\"\\n\\n\")cr_val_model_3=classification_report(y_val,y_val_pred_3>0.5)print(cr_val_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b00915",
   "metadata": {},
   "source": [
    "Class weights: {0: np.float64(1.0587612493382743), 1: np.float64(18.01801801801802)}Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,32)             │2,080│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │33│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:15,617(61.00 KB)Trainable params:15,617(61.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━7s10ms/step - accuracy: 0.7493 - loss: 0.8955 - val_accuracy: 0.9230 - val_loss: 0.2544\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━5s9ms/step - accuracy: 0.9254 - loss: 0.5270 - val_accuracy: 0.9492 - val_loss: 0.2082\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9472 - loss: 0.4838 - val_accuracy: 0.9810 - val_loss: 0.1346\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9566 - loss: 0.4455 - val_accuracy: 0.9525 - val_loss: 0.2008\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9586 - loss: 0.4021 - val_accuracy: 0.9770 - val_loss: 0.1644\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9656 - loss: 0.3981 - val_accuracy: 0.9868 - val_loss: 0.1182\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9733 - loss: 0.3700 - val_accuracy: 0.9870 - val_loss: 0.1302\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9736 - loss: 0.3813 - val_accuracy: 0.9868 - val_loss: 0.1167\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9750 - loss: 0.3778 - val_accuracy: 0.9858 - val_loss: 0.1197\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9749 - loss: 0.3637 - val_accuracy: 0.9895 - val_loss: 0.0847\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9760 - loss: 0.3538 - val_accuracy: 0.9787 - val_loss: 0.1179\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9738 - loss: 0.3530 - val_accuracy: 0.9822 - val_loss: 0.1142\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9811 - loss: 0.3086 - val_accuracy: 0.9810 - val_loss: 0.1083\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9770 - loss: 0.3218 - val_accuracy: 0.9865 - val_loss: 0.1176\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9788 - loss: 0.3194 - val_accuracy: 0.9868 - val_loss: 0.1000\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9777 - loss: 0.3256 - val_accuracy: 0.9927 - val_loss: 0.0964\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9813 - loss: 0.3764 - val_accuracy: 0.9880 - val_loss: 0.0989\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9801 - loss: 0.3088 - val_accuracy: 0.9367 - val_loss: 0.2433\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9737 - loss: 0.3159 - val_accuracy: 0.9877 - val_loss: 0.1143\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9728 - loss: 0.3321 - val_accuracy: 0.9880 - val_loss: 0.1020\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9830 - loss: 0.3020 - val_accuracy: 0.9908 - val_loss: 0.0843\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9784 - loss: 0.3303 - val_accuracy: 0.9885 - val_loss: 0.1097\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9798 - loss: 0.3292 - val_accuracy: 0.9898 - val_loss: 0.0802\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9805 - loss: 0.3287 - val_accuracy: 0.9845 - val_loss: 0.1112\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9818 - loss: 0.2988 - val_accuracy: 0.9735 - val_loss: 0.1313\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9791 - loss: 0.3160 - val_accuracy: 0.9885 - val_loss: 0.0974\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9792 - loss: 0.2991 - val_accuracy: 0.9880 - val_loss: 0.0933\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━4s5ms/step - accuracy: 0.9839 - loss: 0.2522 - val_accuracy: 0.9775 - val_loss: 0.1243\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9770 - loss: 0.3059 - val_accuracy: 0.9820 - val_loss: 0.0983\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9777 - loss: 0.3129 - val_accuracy: 0.9898 - val_loss: 0.0681\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9785 - loss: 0.3255 - val_accuracy: 0.9920 - val_loss: 0.0667\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9827 - loss: 0.2845 - val_accuracy: 0.9900 - val_loss: 0.0856\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9818 - loss: 0.2771 - val_accuracy: 0.9810 - val_loss: 0.1113\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9820 - loss: 0.3112 - val_accuracy: 0.9905 - val_loss: 0.0773\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9779 - loss: 0.2814 - val_accuracy: 0.9860 - val_loss: 0.0949\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9822 - loss: 0.2912 - val_accuracy: 0.9910 - val_loss: 0.0912\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9842 - loss: 0.2471 - val_accuracy: 0.9862 - val_loss: 0.1072\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9806 - loss: 0.2682 - val_accuracy: 0.9852 - val_loss: 0.1308\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9826 - loss: 0.2457 - val_accuracy: 0.9822 - val_loss: 0.1024\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9802 - loss: 0.2951 - val_accuracy: 0.9835 - val_loss: 0.1048\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9811 - loss: 0.2589 - val_accuracy: 0.9845 - val_loss: 0.1091\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9812 - loss: 0.2660 - val_accuracy: 0.9902 - val_loss: 0.0756\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9796 - loss: 0.2946 - val_accuracy: 0.9870 - val_loss: 0.1008\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9825 - loss: 0.2689 - val_accuracy: 0.9862 - val_loss: 0.1047\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9816 - loss: 0.2397 - val_accuracy: 0.9860 - val_loss: 0.0977\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9839 - loss: 0.2109 - val_accuracy: 0.9847 - val_loss: 0.0975\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9789 - loss: 0.2715 - val_accuracy: 0.9900 - val_loss: 0.0755\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9829 - loss: 0.2275 - val_accuracy: 0.9902 - val_loss: 0.0818\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9841 - loss: 0.2248 - val_accuracy: 0.9850 - val_loss: 0.1051\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9827 - loss: 0.2573 - val_accuracy: 0.9827 - val_loss: 0.1045\n",
    "Time taken in seconds  115.92812919616699500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_3\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     15112\n",
    "         1.0       0.86      0.94      0.90       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.93      0.97      0.95     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_3\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99      3778\n",
    "         1.0       0.80      0.92      0.86       222\n",
    "\n",
    "    accuracy                           0.98      4000\n",
    "   macro avg       0.90      0.95      0.92      4000\n",
    "weighted avg       0.98      0.98      0.98      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6977f5aa",
   "metadata": {},
   "source": [
    "Class weights: {0: np.float64(1.0587612493382743), 1: np.float64(18.01801801801802)}Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,32)             │2,080│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │33│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:15,617(61.00 KB)Trainable params:15,617(61.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━7s10ms/step - accuracy: 0.7493 - loss: 0.8955 - val_accuracy: 0.9230 - val_loss: 0.2544\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━5s9ms/step - accuracy: 0.9254 - loss: 0.5270 - val_accuracy: 0.9492 - val_loss: 0.2082\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9472 - loss: 0.4838 - val_accuracy: 0.9810 - val_loss: 0.1346\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9566 - loss: 0.4455 - val_accuracy: 0.9525 - val_loss: 0.2008\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9586 - loss: 0.4021 - val_accuracy: 0.9770 - val_loss: 0.1644\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9656 - loss: 0.3981 - val_accuracy: 0.9868 - val_loss: 0.1182\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9733 - loss: 0.3700 - val_accuracy: 0.9870 - val_loss: 0.1302\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9736 - loss: 0.3813 - val_accuracy: 0.9868 - val_loss: 0.1167\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9750 - loss: 0.3778 - val_accuracy: 0.9858 - val_loss: 0.1197\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9749 - loss: 0.3637 - val_accuracy: 0.9895 - val_loss: 0.0847\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9760 - loss: 0.3538 - val_accuracy: 0.9787 - val_loss: 0.1179\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9738 - loss: 0.3530 - val_accuracy: 0.9822 - val_loss: 0.1142\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9811 - loss: 0.3086 - val_accuracy: 0.9810 - val_loss: 0.1083\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9770 - loss: 0.3218 - val_accuracy: 0.9865 - val_loss: 0.1176\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9788 - loss: 0.3194 - val_accuracy: 0.9868 - val_loss: 0.1000\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9777 - loss: 0.3256 - val_accuracy: 0.9927 - val_loss: 0.0964\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9813 - loss: 0.3764 - val_accuracy: 0.9880 - val_loss: 0.0989\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9801 - loss: 0.3088 - val_accuracy: 0.9367 - val_loss: 0.2433\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9737 - loss: 0.3159 - val_accuracy: 0.9877 - val_loss: 0.1143\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9728 - loss: 0.3321 - val_accuracy: 0.9880 - val_loss: 0.1020\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9830 - loss: 0.3020 - val_accuracy: 0.9908 - val_loss: 0.0843\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9784 - loss: 0.3303 - val_accuracy: 0.9885 - val_loss: 0.1097\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9798 - loss: 0.3292 - val_accuracy: 0.9898 - val_loss: 0.0802\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9805 - loss: 0.3287 - val_accuracy: 0.9845 - val_loss: 0.1112\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9818 - loss: 0.2988 - val_accuracy: 0.9735 - val_loss: 0.1313\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9791 - loss: 0.3160 - val_accuracy: 0.9885 - val_loss: 0.0974\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9792 - loss: 0.2991 - val_accuracy: 0.9880 - val_loss: 0.0933\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━4s5ms/step - accuracy: 0.9839 - loss: 0.2522 - val_accuracy: 0.9775 - val_loss: 0.1243\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9770 - loss: 0.3059 - val_accuracy: 0.9820 - val_loss: 0.0983\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9777 - loss: 0.3129 - val_accuracy: 0.9898 - val_loss: 0.0681\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9785 - loss: 0.3255 - val_accuracy: 0.9920 - val_loss: 0.0667\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9827 - loss: 0.2845 - val_accuracy: 0.9900 - val_loss: 0.0856\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9818 - loss: 0.2771 - val_accuracy: 0.9810 - val_loss: 0.1113\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9820 - loss: 0.3112 - val_accuracy: 0.9905 - val_loss: 0.0773\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9779 - loss: 0.2814 - val_accuracy: 0.9860 - val_loss: 0.0949\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9822 - loss: 0.2912 - val_accuracy: 0.9910 - val_loss: 0.0912\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9842 - loss: 0.2471 - val_accuracy: 0.9862 - val_loss: 0.1072\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9806 - loss: 0.2682 - val_accuracy: 0.9852 - val_loss: 0.1308\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9826 - loss: 0.2457 - val_accuracy: 0.9822 - val_loss: 0.1024\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9802 - loss: 0.2951 - val_accuracy: 0.9835 - val_loss: 0.1048\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9811 - loss: 0.2589 - val_accuracy: 0.9845 - val_loss: 0.1091\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9812 - loss: 0.2660 - val_accuracy: 0.9902 - val_loss: 0.0756\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9796 - loss: 0.2946 - val_accuracy: 0.9870 - val_loss: 0.1008\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9825 - loss: 0.2689 - val_accuracy: 0.9862 - val_loss: 0.1047\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9816 - loss: 0.2397 - val_accuracy: 0.9860 - val_loss: 0.0977\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9839 - loss: 0.2109 - val_accuracy: 0.9847 - val_loss: 0.0975\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9789 - loss: 0.2715 - val_accuracy: 0.9900 - val_loss: 0.0755\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9829 - loss: 0.2275 - val_accuracy: 0.9902 - val_loss: 0.0818\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9841 - loss: 0.2248 - val_accuracy: 0.9850 - val_loss: 0.1051\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9827 - loss: 0.2573 - val_accuracy: 0.9827 - val_loss: 0.1045\n",
    "Time taken in seconds  115.92812919616699500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_3\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     15112\n",
    "         1.0       0.86      0.94      0.90       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.93      0.97      0.95     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_3\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99      3778\n",
    "         1.0       0.80      0.92      0.86       222\n",
    "\n",
    "    accuracy                           0.98      4000\n",
    "   macro avg       0.90      0.95      0.92      4000\n",
    "weighted avg       0.98      0.98      0.98      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21422ec",
   "metadata": {},
   "source": [
    "Class weights: {0: np.float64(1.0587612493382743), 1: np.float64(18.01801801801802)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11baba0",
   "metadata": {},
   "source": [
    "Class weights: {0: np.float64(1.0587612493382743), 1: np.float64(18.01801801801802)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222287d3",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c39ae",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f12d6a",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,32)             │2,080│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │33│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866c417",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,32)             │2,080│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │33│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ca794",
   "metadata": {},
   "source": [
    "Total params:15,617(61.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7035f8",
   "metadata": {},
   "source": [
    "Total params:15,617(61.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07450377",
   "metadata": {},
   "source": [
    "Trainable params:15,617(61.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e4080",
   "metadata": {},
   "source": [
    "Trainable params:15,617(61.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817338ff",
   "metadata": {},
   "source": [
    "Non-trainable params:0(0.00 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84993dd3",
   "metadata": {},
   "source": [
    "Non-trainable params:0(0.00 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2f795",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━7s10ms/step - accuracy: 0.7493 - loss: 0.8955 - val_accuracy: 0.9230 - val_loss: 0.2544\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━5s9ms/step - accuracy: 0.9254 - loss: 0.5270 - val_accuracy: 0.9492 - val_loss: 0.2082\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9472 - loss: 0.4838 - val_accuracy: 0.9810 - val_loss: 0.1346\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9566 - loss: 0.4455 - val_accuracy: 0.9525 - val_loss: 0.2008\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9586 - loss: 0.4021 - val_accuracy: 0.9770 - val_loss: 0.1644\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9656 - loss: 0.3981 - val_accuracy: 0.9868 - val_loss: 0.1182\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9733 - loss: 0.3700 - val_accuracy: 0.9870 - val_loss: 0.1302\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9736 - loss: 0.3813 - val_accuracy: 0.9868 - val_loss: 0.1167\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9750 - loss: 0.3778 - val_accuracy: 0.9858 - val_loss: 0.1197\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9749 - loss: 0.3637 - val_accuracy: 0.9895 - val_loss: 0.0847\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9760 - loss: 0.3538 - val_accuracy: 0.9787 - val_loss: 0.1179\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9738 - loss: 0.3530 - val_accuracy: 0.9822 - val_loss: 0.1142\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9811 - loss: 0.3086 - val_accuracy: 0.9810 - val_loss: 0.1083\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9770 - loss: 0.3218 - val_accuracy: 0.9865 - val_loss: 0.1176\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9788 - loss: 0.3194 - val_accuracy: 0.9868 - val_loss: 0.1000\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9777 - loss: 0.3256 - val_accuracy: 0.9927 - val_loss: 0.0964\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9813 - loss: 0.3764 - val_accuracy: 0.9880 - val_loss: 0.0989\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9801 - loss: 0.3088 - val_accuracy: 0.9367 - val_loss: 0.2433\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9737 - loss: 0.3159 - val_accuracy: 0.9877 - val_loss: 0.1143\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9728 - loss: 0.3321 - val_accuracy: 0.9880 - val_loss: 0.1020\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9830 - loss: 0.3020 - val_accuracy: 0.9908 - val_loss: 0.0843\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9784 - loss: 0.3303 - val_accuracy: 0.9885 - val_loss: 0.1097\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9798 - loss: 0.3292 - val_accuracy: 0.9898 - val_loss: 0.0802\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9805 - loss: 0.3287 - val_accuracy: 0.9845 - val_loss: 0.1112\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9818 - loss: 0.2988 - val_accuracy: 0.9735 - val_loss: 0.1313\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9791 - loss: 0.3160 - val_accuracy: 0.9885 - val_loss: 0.0974\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9792 - loss: 0.2991 - val_accuracy: 0.9880 - val_loss: 0.0933\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━4s5ms/step - accuracy: 0.9839 - loss: 0.2522 - val_accuracy: 0.9775 - val_loss: 0.1243\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9770 - loss: 0.3059 - val_accuracy: 0.9820 - val_loss: 0.0983\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9777 - loss: 0.3129 - val_accuracy: 0.9898 - val_loss: 0.0681\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9785 - loss: 0.3255 - val_accuracy: 0.9920 - val_loss: 0.0667\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9827 - loss: 0.2845 - val_accuracy: 0.9900 - val_loss: 0.0856\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9818 - loss: 0.2771 - val_accuracy: 0.9810 - val_loss: 0.1113\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9820 - loss: 0.3112 - val_accuracy: 0.9905 - val_loss: 0.0773\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9779 - loss: 0.2814 - val_accuracy: 0.9860 - val_loss: 0.0949\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9822 - loss: 0.2912 - val_accuracy: 0.9910 - val_loss: 0.0912\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9842 - loss: 0.2471 - val_accuracy: 0.9862 - val_loss: 0.1072\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9806 - loss: 0.2682 - val_accuracy: 0.9852 - val_loss: 0.1308\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9826 - loss: 0.2457 - val_accuracy: 0.9822 - val_loss: 0.1024\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9802 - loss: 0.2951 - val_accuracy: 0.9835 - val_loss: 0.1048\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9811 - loss: 0.2589 - val_accuracy: 0.9845 - val_loss: 0.1091\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9812 - loss: 0.2660 - val_accuracy: 0.9902 - val_loss: 0.0756\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9796 - loss: 0.2946 - val_accuracy: 0.9870 - val_loss: 0.1008\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9825 - loss: 0.2689 - val_accuracy: 0.9862 - val_loss: 0.1047\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9816 - loss: 0.2397 - val_accuracy: 0.9860 - val_loss: 0.0977\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9839 - loss: 0.2109 - val_accuracy: 0.9847 - val_loss: 0.0975\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9789 - loss: 0.2715 - val_accuracy: 0.9900 - val_loss: 0.0755\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9829 - loss: 0.2275 - val_accuracy: 0.9902 - val_loss: 0.0818\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9841 - loss: 0.2248 - val_accuracy: 0.9850 - val_loss: 0.1051\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9827 - loss: 0.2573 - val_accuracy: 0.9827 - val_loss: 0.1045\n",
    "Time taken in seconds  115.92812919616699"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10c901b",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━7s10ms/step - accuracy: 0.7493 - loss: 0.8955 - val_accuracy: 0.9230 - val_loss: 0.2544\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━5s9ms/step - accuracy: 0.9254 - loss: 0.5270 - val_accuracy: 0.9492 - val_loss: 0.2082\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9472 - loss: 0.4838 - val_accuracy: 0.9810 - val_loss: 0.1346\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9566 - loss: 0.4455 - val_accuracy: 0.9525 - val_loss: 0.2008\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9586 - loss: 0.4021 - val_accuracy: 0.9770 - val_loss: 0.1644\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9656 - loss: 0.3981 - val_accuracy: 0.9868 - val_loss: 0.1182\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9733 - loss: 0.3700 - val_accuracy: 0.9870 - val_loss: 0.1302\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9736 - loss: 0.3813 - val_accuracy: 0.9868 - val_loss: 0.1167\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9750 - loss: 0.3778 - val_accuracy: 0.9858 - val_loss: 0.1197\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9749 - loss: 0.3637 - val_accuracy: 0.9895 - val_loss: 0.0847\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9760 - loss: 0.3538 - val_accuracy: 0.9787 - val_loss: 0.1179\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9738 - loss: 0.3530 - val_accuracy: 0.9822 - val_loss: 0.1142\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9811 - loss: 0.3086 - val_accuracy: 0.9810 - val_loss: 0.1083\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9770 - loss: 0.3218 - val_accuracy: 0.9865 - val_loss: 0.1176\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9788 - loss: 0.3194 - val_accuracy: 0.9868 - val_loss: 0.1000\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9777 - loss: 0.3256 - val_accuracy: 0.9927 - val_loss: 0.0964\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9813 - loss: 0.3764 - val_accuracy: 0.9880 - val_loss: 0.0989\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9801 - loss: 0.3088 - val_accuracy: 0.9367 - val_loss: 0.2433\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9737 - loss: 0.3159 - val_accuracy: 0.9877 - val_loss: 0.1143\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9728 - loss: 0.3321 - val_accuracy: 0.9880 - val_loss: 0.1020\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9830 - loss: 0.3020 - val_accuracy: 0.9908 - val_loss: 0.0843\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9784 - loss: 0.3303 - val_accuracy: 0.9885 - val_loss: 0.1097\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9798 - loss: 0.3292 - val_accuracy: 0.9898 - val_loss: 0.0802\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9805 - loss: 0.3287 - val_accuracy: 0.9845 - val_loss: 0.1112\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9818 - loss: 0.2988 - val_accuracy: 0.9735 - val_loss: 0.1313\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9791 - loss: 0.3160 - val_accuracy: 0.9885 - val_loss: 0.0974\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9792 - loss: 0.2991 - val_accuracy: 0.9880 - val_loss: 0.0933\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━4s5ms/step - accuracy: 0.9839 - loss: 0.2522 - val_accuracy: 0.9775 - val_loss: 0.1243\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9770 - loss: 0.3059 - val_accuracy: 0.9820 - val_loss: 0.0983\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9777 - loss: 0.3129 - val_accuracy: 0.9898 - val_loss: 0.0681\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9785 - loss: 0.3255 - val_accuracy: 0.9920 - val_loss: 0.0667\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9827 - loss: 0.2845 - val_accuracy: 0.9900 - val_loss: 0.0856\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9818 - loss: 0.2771 - val_accuracy: 0.9810 - val_loss: 0.1113\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9820 - loss: 0.3112 - val_accuracy: 0.9905 - val_loss: 0.0773\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9779 - loss: 0.2814 - val_accuracy: 0.9860 - val_loss: 0.0949\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9822 - loss: 0.2912 - val_accuracy: 0.9910 - val_loss: 0.0912\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9842 - loss: 0.2471 - val_accuracy: 0.9862 - val_loss: 0.1072\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9806 - loss: 0.2682 - val_accuracy: 0.9852 - val_loss: 0.1308\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9826 - loss: 0.2457 - val_accuracy: 0.9822 - val_loss: 0.1024\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9802 - loss: 0.2951 - val_accuracy: 0.9835 - val_loss: 0.1048\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9811 - loss: 0.2589 - val_accuracy: 0.9845 - val_loss: 0.1091\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9812 - loss: 0.2660 - val_accuracy: 0.9902 - val_loss: 0.0756\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9796 - loss: 0.2946 - val_accuracy: 0.9870 - val_loss: 0.1008\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9825 - loss: 0.2689 - val_accuracy: 0.9862 - val_loss: 0.1047\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9816 - loss: 0.2397 - val_accuracy: 0.9860 - val_loss: 0.0977\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9839 - loss: 0.2109 - val_accuracy: 0.9847 - val_loss: 0.0975\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9789 - loss: 0.2715 - val_accuracy: 0.9900 - val_loss: 0.0755\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9829 - loss: 0.2275 - val_accuracy: 0.9902 - val_loss: 0.0818\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9841 - loss: 0.2248 - val_accuracy: 0.9850 - val_loss: 0.1051\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9827 - loss: 0.2573 - val_accuracy: 0.9827 - val_loss: 0.1045\n",
    "Time taken in seconds  115.92812919616699"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2098714e",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_3\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     15112\n",
    "         1.0       0.86      0.94      0.90       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.93      0.97      0.95     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_3\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99      3778\n",
    "         1.0       0.80      0.92      0.86       222\n",
    "\n",
    "    accuracy                           0.98      4000\n",
    "   macro avg       0.90      0.95      0.92      4000\n",
    "weighted avg       0.98      0.98      0.98      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197668e",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_3\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     15112\n",
    "         1.0       0.86      0.94      0.90       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.93      0.97      0.95     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_3\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99      3778\n",
    "         1.0       0.80      0.92      0.86       222\n",
    "\n",
    "    accuracy                           0.98      4000\n",
    "   macro avg       0.90      0.95      0.92      4000\n",
    "weighted avg       0.98      0.98      0.98      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b71fc",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Class Imbalance Handling:Class weights significantly improve recall for minority class (failures)Model now gives more importance to failure predictionsBetter alignment with business objectivesBusiness Impact:Reduced false negatives (missed failures)Lower risk of expensive replacement costsBetter detection of actual failure conditionsPerformance Trade-offs:May see slight decrease in precisionSignificant improvement in recallBetter balanced F1-score overallModel Behavior:Model becomes more sensitive to failure signalsHigher false positive rate but lower false negative rateBetter suited for predictive maintenance applicationsTraining Characteristics:Training focuses more on minority class examplesLoss function now penalizes missed failures more heavilyMore balanced learning across classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5d531",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Class Imbalance Handling:Class weights significantly improve recall for minority class (failures)Model now gives more importance to failure predictionsBetter alignment with business objectivesBusiness Impact:Reduced false negatives (missed failures)Lower risk of expensive replacement costsBetter detection of actual failure conditionsPerformance Trade-offs:May see slight decrease in precisionSignificant improvement in recallBetter balanced F1-score overallModel Behavior:Model becomes more sensitive to failure signalsHigher false positive rate but lower false negative rateBetter suited for predictive maintenance applicationsTraining Characteristics:Training focuses more on minority class examplesLoss function now penalizes missed failures more heavilyMore balanced learning across classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71649d",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Class Imbalance Handling:Class weights significantly improve recall for minority class (failures)Model now gives more importance to failure predictionsBetter alignment with business objectivesBusiness Impact:Reduced false negatives (missed failures)Lower risk of expensive replacement costsBetter detection of actual failure conditionsPerformance Trade-offs:May see slight decrease in precisionSignificant improvement in recallBetter balanced F1-score overallModel Behavior:Model becomes more sensitive to failure signalsHigher false positive rate but lower false negative rateBetter suited for predictive maintenance applicationsTraining Characteristics:Training focuses more on minority class examplesLoss function now penalizes missed failures more heavilyMore balanced learning across classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab8c5b6",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Class Imbalance Handling:Class weights significantly improve recall for minority class (failures)Model now gives more importance to failure predictionsBetter alignment with business objectivesBusiness Impact:Reduced false negatives (missed failures)Lower risk of expensive replacement costsBetter detection of actual failure conditionsPerformance Trade-offs:May see slight decrease in precisionSignificant improvement in recallBetter balanced F1-score overallModel Behavior:Model becomes more sensitive to failure signalsHigher false positive rate but lower false negative rateBetter suited for predictive maintenance applicationsTraining Characteristics:Training focuses more on minority class examplesLoss function now penalizes missed failures more heavilyMore balanced learning across classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a8fb8",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38832fb",
   "metadata": {},
   "source": [
    "Class Imbalance Handling:Class weights significantly improve recall for minority class (failures)Model now gives more importance to failure predictionsBetter alignment with business objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e4871",
   "metadata": {},
   "source": [
    "Class Imbalance Handling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c54469",
   "metadata": {},
   "source": [
    "Class weights significantly improve recall for minority class (failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939c159",
   "metadata": {},
   "source": [
    "Model now gives more importance to failure predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923bab13",
   "metadata": {},
   "source": [
    "Better alignment with business objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be47d5c6",
   "metadata": {},
   "source": [
    "Business Impact:Reduced false negatives (missed failures)Lower risk of expensive replacement costsBetter detection of actual failure conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256809d4",
   "metadata": {},
   "source": [
    "Business Impact:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb71b92",
   "metadata": {},
   "source": [
    "Reduced false negatives (missed failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605025d9",
   "metadata": {},
   "source": [
    "Lower risk of expensive replacement costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60494319",
   "metadata": {},
   "source": [
    "Better detection of actual failure conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f892d1",
   "metadata": {},
   "source": [
    "Performance Trade-offs:May see slight decrease in precisionSignificant improvement in recallBetter balanced F1-score overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a096e7",
   "metadata": {},
   "source": [
    "Performance Trade-offs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7552b0c9",
   "metadata": {},
   "source": [
    "May see slight decrease in precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27bb763",
   "metadata": {},
   "source": [
    "Significant improvement in recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307da2b9",
   "metadata": {},
   "source": [
    "Better balanced F1-score overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de10a8",
   "metadata": {},
   "source": [
    "Model Behavior:Model becomes more sensitive to failure signalsHigher false positive rate but lower false negative rateBetter suited for predictive maintenance applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc924d",
   "metadata": {},
   "source": [
    "Model Behavior:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a8f7e6",
   "metadata": {},
   "source": [
    "Model becomes more sensitive to failure signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c1f594",
   "metadata": {},
   "source": [
    "Higher false positive rate but lower false negative rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ea7e41",
   "metadata": {},
   "source": [
    "Better suited for predictive maintenance applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c09f55",
   "metadata": {},
   "source": [
    "Training Characteristics:Training focuses more on minority class examplesLoss function now penalizes missed failures more heavilyMore balanced learning across classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea06279f",
   "metadata": {},
   "source": [
    "Training Characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205c4d6",
   "metadata": {},
   "source": [
    "Training focuses more on minority class examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8266cdeb",
   "metadata": {},
   "source": [
    "Loss function now penalizes missed failures more heavily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c75321",
   "metadata": {},
   "source": [
    "More balanced learning across classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b744f9",
   "metadata": {},
   "source": [
    "Model 4¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15367ca",
   "metadata": {},
   "source": [
    "Model 4¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a4964",
   "metadata": {},
   "source": [
    "Model 4¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db5e37",
   "metadata": {},
   "source": [
    "Model 4¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe40910",
   "metadata": {},
   "source": [
    "Model 4¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d45fdd",
   "metadata": {},
   "source": [
    "In [20]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_4=Sequential()model_4.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_4.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_4.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_4.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_4.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_4.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_4_train_perf=model_performance_classification(model_4,X_train_scaled,y_train)model_4_train_perfmodel_4_val_perf=model_performance_classification(model_4,X_val_scaled,y_val)model_4_val_perfy_train_pred_4=model_4.predict(X_train_scaled)y_val_pred_4=model_4.predict(X_val_scaled)print(\"Classification Report - Train data Model_4\",end=\"\\n\\n\")cr_train_model_4=classification_report(y_train,y_train_pred_4>0.5)print(cr_train_model_4)print(\"Classification Report - Validation data Model_4\",end=\"\\n\\n\")cr_val_model_4=classification_report(y_val,y_val_pred_4>0.5)print(cr_val_model_4)Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:13,569(53.00 KB)Trainable params:13,569(53.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s6ms/step - accuracy: 0.9587 - loss: 0.1611 - val_accuracy: 0.9870 - val_loss: 0.0620\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9875 - loss: 0.0590 - val_accuracy: 0.9910 - val_loss: 0.0502\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9889 - loss: 0.0506 - val_accuracy: 0.9940 - val_loss: 0.0450\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9924 - loss: 0.0422 - val_accuracy: 0.9935 - val_loss: 0.0439\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9923 - loss: 0.0409 - val_accuracy: 0.9908 - val_loss: 0.0445\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9921 - loss: 0.0404 - val_accuracy: 0.9937 - val_loss: 0.0406\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9914 - loss: 0.0407 - val_accuracy: 0.9933 - val_loss: 0.0402\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9928 - loss: 0.0410 - val_accuracy: 0.9933 - val_loss: 0.0425\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9935 - loss: 0.0366 - val_accuracy: 0.9935 - val_loss: 0.0412\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9935 - loss: 0.0337 - val_accuracy: 0.9910 - val_loss: 0.0450\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9937 - loss: 0.0333 - val_accuracy: 0.9915 - val_loss: 0.0448\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9938 - loss: 0.0295 - val_accuracy: 0.9937 - val_loss: 0.0405\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9944 - loss: 0.0258 - val_accuracy: 0.9935 - val_loss: 0.0406\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9920 - loss: 0.0359 - val_accuracy: 0.9930 - val_loss: 0.0450\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9934 - loss: 0.0313 - val_accuracy: 0.9925 - val_loss: 0.0413\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9948 - loss: 0.0265 - val_accuracy: 0.9933 - val_loss: 0.0418\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9937 - loss: 0.0307 - val_accuracy: 0.9935 - val_loss: 0.0387\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9942 - loss: 0.0278 - val_accuracy: 0.9935 - val_loss: 0.0392\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9939 - loss: 0.0261 - val_accuracy: 0.9935 - val_loss: 0.0413\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9937 - loss: 0.0272 - val_accuracy: 0.9918 - val_loss: 0.0487\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9943 - loss: 0.0231 - val_accuracy: 0.9923 - val_loss: 0.0487\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9942 - loss: 0.0248 - val_accuracy: 0.9930 - val_loss: 0.0449\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9949 - loss: 0.0224 - val_accuracy: 0.9925 - val_loss: 0.0461\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9955 - loss: 0.0192 - val_accuracy: 0.9930 - val_loss: 0.0439\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9945 - loss: 0.0217 - val_accuracy: 0.9925 - val_loss: 0.0487\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9944 - loss: 0.0224 - val_accuracy: 0.9920 - val_loss: 0.0471\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.9918 - val_loss: 0.0520\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9950 - loss: 0.0192 - val_accuracy: 0.9923 - val_loss: 0.0535\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9956 - loss: 0.0173 - val_accuracy: 0.9927 - val_loss: 0.0487\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9953 - loss: 0.0187 - val_accuracy: 0.9923 - val_loss: 0.0523\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9957 - loss: 0.0134 - val_accuracy: 0.9855 - val_loss: 0.0637\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9949 - loss: 0.0179 - val_accuracy: 0.9920 - val_loss: 0.0527\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9959 - loss: 0.0143 - val_accuracy: 0.9905 - val_loss: 0.0565\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9959 - loss: 0.0155 - val_accuracy: 0.9923 - val_loss: 0.0550\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9955 - loss: 0.0144 - val_accuracy: 0.9908 - val_loss: 0.0559\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9954 - loss: 0.0140 - val_accuracy: 0.9900 - val_loss: 0.0592\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9940 - loss: 0.0179 - val_accuracy: 0.9923 - val_loss: 0.0582\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9957 - loss: 0.0115 - val_accuracy: 0.9920 - val_loss: 0.0580\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9953 - loss: 0.0130 - val_accuracy: 0.9920 - val_loss: 0.0597\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9918 - val_loss: 0.0621\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9912 - val_loss: 0.0636\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9966 - loss: 0.0116 - val_accuracy: 0.9918 - val_loss: 0.0615\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9969 - loss: 0.0098 - val_accuracy: 0.9918 - val_loss: 0.0674\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9966 - loss: 0.0108 - val_accuracy: 0.9905 - val_loss: 0.0658\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9908 - val_loss: 0.0615\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9965 - loss: 0.0106 - val_accuracy: 0.9877 - val_loss: 0.0707\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9965 - loss: 0.0109 - val_accuracy: 0.9875 - val_loss: 0.0751\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9967 - loss: 0.0091 - val_accuracy: 0.9898 - val_loss: 0.0707\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9960 - loss: 0.0111 - val_accuracy: 0.9872 - val_loss: 0.0781\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9961 - loss: 0.0110 - val_accuracy: 0.9908 - val_loss: 0.0677\n",
    "Time taken in seconds  118.47824621200562500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_4\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     15112\n",
    "         1.0       0.99      0.97      0.98       888\n",
    "\n",
    "    accuracy                           1.00     16000\n",
    "   macro avg       0.99      0.98      0.99     16000\n",
    "weighted avg       1.00      1.00      1.00     16000\n",
    "\n",
    "Classification Report - Validation data Model_4\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.93      0.90      0.92       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.96      0.95      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea16e1",
   "metadata": {},
   "source": [
    "In [20]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_4=Sequential()model_4.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_4.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_4.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_4.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_4.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_4.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_4_train_perf=model_performance_classification(model_4,X_train_scaled,y_train)model_4_train_perfmodel_4_val_perf=model_performance_classification(model_4,X_val_scaled,y_val)model_4_val_perfy_train_pred_4=model_4.predict(X_train_scaled)y_val_pred_4=model_4.predict(X_val_scaled)print(\"Classification Report - Train data Model_4\",end=\"\\n\\n\")cr_train_model_4=classification_report(y_train,y_train_pred_4>0.5)print(cr_train_model_4)print(\"Classification Report - Validation data Model_4\",end=\"\\n\\n\")cr_val_model_4=classification_report(y_val,y_val_pred_4>0.5)print(cr_val_model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e16309",
   "metadata": {},
   "source": [
    "In [20]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_4=Sequential()model_4.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_4.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_4.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_4.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_4.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_4.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_4_train_perf=model_performance_classification(model_4,X_train_scaled,y_train)model_4_train_perfmodel_4_val_perf=model_performance_classification(model_4,X_val_scaled,y_val)model_4_val_perfy_train_pred_4=model_4.predict(X_train_scaled)y_val_pred_4=model_4.predict(X_val_scaled)print(\"Classification Report - Train data Model_4\",end=\"\\n\\n\")cr_train_model_4=classification_report(y_train,y_train_pred_4>0.5)print(cr_train_model_4)print(\"Classification Report - Validation data Model_4\",end=\"\\n\\n\")cr_val_model_4=classification_report(y_val,y_val_pred_4>0.5)print(cr_val_model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835e1ff",
   "metadata": {},
   "source": [
    "In [20]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267688c",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_4=Sequential()model_4.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_4.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_4.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_4.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_4.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_4.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_4_train_perf=model_performance_classification(model_4,X_train_scaled,y_train)model_4_train_perfmodel_4_val_perf=model_performance_classification(model_4,X_val_scaled,y_val)model_4_val_perfy_train_pred_4=model_4.predict(X_train_scaled)y_val_pred_4=model_4.predict(X_val_scaled)print(\"Classification Report - Train data Model_4\",end=\"\\n\\n\")cr_train_model_4=classification_report(y_train,y_train_pred_4>0.5)print(cr_train_model_4)print(\"Classification Report - Validation data Model_4\",end=\"\\n\\n\")cr_val_model_4=classification_report(y_val,y_val_pred_4>0.5)print(cr_val_model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8ac34f",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_4=Sequential()model_4.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_4.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_4.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_4.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_4.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_4.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_4_train_perf=model_performance_classification(model_4,X_train_scaled,y_train)model_4_train_perfmodel_4_val_perf=model_performance_classification(model_4,X_val_scaled,y_val)model_4_val_perfy_train_pred_4=model_4.predict(X_train_scaled)y_val_pred_4=model_4.predict(X_val_scaled)print(\"Classification Report - Train data Model_4\",end=\"\\n\\n\")cr_train_model_4=classification_report(y_train,y_train_pred_4>0.5)print(cr_train_model_4)print(\"Classification Report - Validation data Model_4\",end=\"\\n\\n\")cr_val_model_4=classification_report(y_val,y_val_pred_4>0.5)print(cr_val_model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a18df",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_4=Sequential()model_4.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_4.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_4.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_4.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_4.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_4.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_4_train_perf=model_performance_classification(model_4,X_train_scaled,y_train)model_4_train_perfmodel_4_val_perf=model_performance_classification(model_4,X_val_scaled,y_val)model_4_val_perfy_train_pred_4=model_4.predict(X_train_scaled)y_val_pred_4=model_4.predict(X_val_scaled)print(\"Classification Report - Train data Model_4\",end=\"\\n\\n\")cr_train_model_4=classification_report(y_train,y_train_pred_4>0.5)print(cr_train_model_4)print(\"Classification Report - Validation data Model_4\",end=\"\\n\\n\")cr_val_model_4=classification_report(y_val,y_val_pred_4>0.5)print(cr_val_model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ade08",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:13,569(53.00 KB)Trainable params:13,569(53.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s6ms/step - accuracy: 0.9587 - loss: 0.1611 - val_accuracy: 0.9870 - val_loss: 0.0620\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9875 - loss: 0.0590 - val_accuracy: 0.9910 - val_loss: 0.0502\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9889 - loss: 0.0506 - val_accuracy: 0.9940 - val_loss: 0.0450\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9924 - loss: 0.0422 - val_accuracy: 0.9935 - val_loss: 0.0439\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9923 - loss: 0.0409 - val_accuracy: 0.9908 - val_loss: 0.0445\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9921 - loss: 0.0404 - val_accuracy: 0.9937 - val_loss: 0.0406\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9914 - loss: 0.0407 - val_accuracy: 0.9933 - val_loss: 0.0402\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9928 - loss: 0.0410 - val_accuracy: 0.9933 - val_loss: 0.0425\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9935 - loss: 0.0366 - val_accuracy: 0.9935 - val_loss: 0.0412\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9935 - loss: 0.0337 - val_accuracy: 0.9910 - val_loss: 0.0450\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9937 - loss: 0.0333 - val_accuracy: 0.9915 - val_loss: 0.0448\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9938 - loss: 0.0295 - val_accuracy: 0.9937 - val_loss: 0.0405\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9944 - loss: 0.0258 - val_accuracy: 0.9935 - val_loss: 0.0406\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9920 - loss: 0.0359 - val_accuracy: 0.9930 - val_loss: 0.0450\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9934 - loss: 0.0313 - val_accuracy: 0.9925 - val_loss: 0.0413\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9948 - loss: 0.0265 - val_accuracy: 0.9933 - val_loss: 0.0418\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9937 - loss: 0.0307 - val_accuracy: 0.9935 - val_loss: 0.0387\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9942 - loss: 0.0278 - val_accuracy: 0.9935 - val_loss: 0.0392\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9939 - loss: 0.0261 - val_accuracy: 0.9935 - val_loss: 0.0413\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9937 - loss: 0.0272 - val_accuracy: 0.9918 - val_loss: 0.0487\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9943 - loss: 0.0231 - val_accuracy: 0.9923 - val_loss: 0.0487\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9942 - loss: 0.0248 - val_accuracy: 0.9930 - val_loss: 0.0449\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9949 - loss: 0.0224 - val_accuracy: 0.9925 - val_loss: 0.0461\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9955 - loss: 0.0192 - val_accuracy: 0.9930 - val_loss: 0.0439\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9945 - loss: 0.0217 - val_accuracy: 0.9925 - val_loss: 0.0487\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9944 - loss: 0.0224 - val_accuracy: 0.9920 - val_loss: 0.0471\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.9918 - val_loss: 0.0520\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9950 - loss: 0.0192 - val_accuracy: 0.9923 - val_loss: 0.0535\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9956 - loss: 0.0173 - val_accuracy: 0.9927 - val_loss: 0.0487\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9953 - loss: 0.0187 - val_accuracy: 0.9923 - val_loss: 0.0523\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9957 - loss: 0.0134 - val_accuracy: 0.9855 - val_loss: 0.0637\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9949 - loss: 0.0179 - val_accuracy: 0.9920 - val_loss: 0.0527\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9959 - loss: 0.0143 - val_accuracy: 0.9905 - val_loss: 0.0565\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9959 - loss: 0.0155 - val_accuracy: 0.9923 - val_loss: 0.0550\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9955 - loss: 0.0144 - val_accuracy: 0.9908 - val_loss: 0.0559\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9954 - loss: 0.0140 - val_accuracy: 0.9900 - val_loss: 0.0592\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9940 - loss: 0.0179 - val_accuracy: 0.9923 - val_loss: 0.0582\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9957 - loss: 0.0115 - val_accuracy: 0.9920 - val_loss: 0.0580\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9953 - loss: 0.0130 - val_accuracy: 0.9920 - val_loss: 0.0597\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9918 - val_loss: 0.0621\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9912 - val_loss: 0.0636\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9966 - loss: 0.0116 - val_accuracy: 0.9918 - val_loss: 0.0615\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9969 - loss: 0.0098 - val_accuracy: 0.9918 - val_loss: 0.0674\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9966 - loss: 0.0108 - val_accuracy: 0.9905 - val_loss: 0.0658\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9908 - val_loss: 0.0615\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9965 - loss: 0.0106 - val_accuracy: 0.9877 - val_loss: 0.0707\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9965 - loss: 0.0109 - val_accuracy: 0.9875 - val_loss: 0.0751\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9967 - loss: 0.0091 - val_accuracy: 0.9898 - val_loss: 0.0707\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9960 - loss: 0.0111 - val_accuracy: 0.9872 - val_loss: 0.0781\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9961 - loss: 0.0110 - val_accuracy: 0.9908 - val_loss: 0.0677\n",
    "Time taken in seconds  118.47824621200562500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_4\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     15112\n",
    "         1.0       0.99      0.97      0.98       888\n",
    "\n",
    "    accuracy                           1.00     16000\n",
    "   macro avg       0.99      0.98      0.99     16000\n",
    "weighted avg       1.00      1.00      1.00     16000\n",
    "\n",
    "Classification Report - Validation data Model_4\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.93      0.90      0.92       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.96      0.95      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3fc4f6",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:13,569(53.00 KB)Trainable params:13,569(53.00 KB)Non-trainable params:0(0.00 B)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s6ms/step - accuracy: 0.9587 - loss: 0.1611 - val_accuracy: 0.9870 - val_loss: 0.0620\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9875 - loss: 0.0590 - val_accuracy: 0.9910 - val_loss: 0.0502\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9889 - loss: 0.0506 - val_accuracy: 0.9940 - val_loss: 0.0450\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9924 - loss: 0.0422 - val_accuracy: 0.9935 - val_loss: 0.0439\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9923 - loss: 0.0409 - val_accuracy: 0.9908 - val_loss: 0.0445\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9921 - loss: 0.0404 - val_accuracy: 0.9937 - val_loss: 0.0406\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9914 - loss: 0.0407 - val_accuracy: 0.9933 - val_loss: 0.0402\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9928 - loss: 0.0410 - val_accuracy: 0.9933 - val_loss: 0.0425\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9935 - loss: 0.0366 - val_accuracy: 0.9935 - val_loss: 0.0412\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9935 - loss: 0.0337 - val_accuracy: 0.9910 - val_loss: 0.0450\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9937 - loss: 0.0333 - val_accuracy: 0.9915 - val_loss: 0.0448\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9938 - loss: 0.0295 - val_accuracy: 0.9937 - val_loss: 0.0405\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9944 - loss: 0.0258 - val_accuracy: 0.9935 - val_loss: 0.0406\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9920 - loss: 0.0359 - val_accuracy: 0.9930 - val_loss: 0.0450\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9934 - loss: 0.0313 - val_accuracy: 0.9925 - val_loss: 0.0413\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9948 - loss: 0.0265 - val_accuracy: 0.9933 - val_loss: 0.0418\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9937 - loss: 0.0307 - val_accuracy: 0.9935 - val_loss: 0.0387\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9942 - loss: 0.0278 - val_accuracy: 0.9935 - val_loss: 0.0392\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9939 - loss: 0.0261 - val_accuracy: 0.9935 - val_loss: 0.0413\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9937 - loss: 0.0272 - val_accuracy: 0.9918 - val_loss: 0.0487\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9943 - loss: 0.0231 - val_accuracy: 0.9923 - val_loss: 0.0487\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9942 - loss: 0.0248 - val_accuracy: 0.9930 - val_loss: 0.0449\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9949 - loss: 0.0224 - val_accuracy: 0.9925 - val_loss: 0.0461\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9955 - loss: 0.0192 - val_accuracy: 0.9930 - val_loss: 0.0439\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9945 - loss: 0.0217 - val_accuracy: 0.9925 - val_loss: 0.0487\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9944 - loss: 0.0224 - val_accuracy: 0.9920 - val_loss: 0.0471\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.9918 - val_loss: 0.0520\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9950 - loss: 0.0192 - val_accuracy: 0.9923 - val_loss: 0.0535\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9956 - loss: 0.0173 - val_accuracy: 0.9927 - val_loss: 0.0487\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9953 - loss: 0.0187 - val_accuracy: 0.9923 - val_loss: 0.0523\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9957 - loss: 0.0134 - val_accuracy: 0.9855 - val_loss: 0.0637\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9949 - loss: 0.0179 - val_accuracy: 0.9920 - val_loss: 0.0527\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9959 - loss: 0.0143 - val_accuracy: 0.9905 - val_loss: 0.0565\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9959 - loss: 0.0155 - val_accuracy: 0.9923 - val_loss: 0.0550\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9955 - loss: 0.0144 - val_accuracy: 0.9908 - val_loss: 0.0559\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9954 - loss: 0.0140 - val_accuracy: 0.9900 - val_loss: 0.0592\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9940 - loss: 0.0179 - val_accuracy: 0.9923 - val_loss: 0.0582\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9957 - loss: 0.0115 - val_accuracy: 0.9920 - val_loss: 0.0580\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9953 - loss: 0.0130 - val_accuracy: 0.9920 - val_loss: 0.0597\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9918 - val_loss: 0.0621\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9912 - val_loss: 0.0636\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9966 - loss: 0.0116 - val_accuracy: 0.9918 - val_loss: 0.0615\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9969 - loss: 0.0098 - val_accuracy: 0.9918 - val_loss: 0.0674\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9966 - loss: 0.0108 - val_accuracy: 0.9905 - val_loss: 0.0658\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9908 - val_loss: 0.0615\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9965 - loss: 0.0106 - val_accuracy: 0.9877 - val_loss: 0.0707\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9965 - loss: 0.0109 - val_accuracy: 0.9875 - val_loss: 0.0751\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9967 - loss: 0.0091 - val_accuracy: 0.9898 - val_loss: 0.0707\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9960 - loss: 0.0111 - val_accuracy: 0.9872 - val_loss: 0.0781\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9961 - loss: 0.0110 - val_accuracy: 0.9908 - val_loss: 0.0677\n",
    "Time taken in seconds  118.47824621200562500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_4\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     15112\n",
    "         1.0       0.99      0.97      0.98       888\n",
    "\n",
    "    accuracy                           1.00     16000\n",
    "   macro avg       0.99      0.98      0.99     16000\n",
    "weighted avg       1.00      1.00      1.00     16000\n",
    "\n",
    "Classification Report - Validation data Model_4\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.93      0.90      0.92       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.96      0.95      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88ab7d",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9403155",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871c5ef",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8bc58",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b06be",
   "metadata": {},
   "source": [
    "Total params:13,569(53.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52dd847",
   "metadata": {},
   "source": [
    "Total params:13,569(53.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1578b5",
   "metadata": {},
   "source": [
    "Trainable params:13,569(53.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfcf025",
   "metadata": {},
   "source": [
    "Trainable params:13,569(53.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5eec0d",
   "metadata": {},
   "source": [
    "Non-trainable params:0(0.00 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1992858a",
   "metadata": {},
   "source": [
    "Non-trainable params:0(0.00 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d672ce",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s6ms/step - accuracy: 0.9587 - loss: 0.1611 - val_accuracy: 0.9870 - val_loss: 0.0620\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9875 - loss: 0.0590 - val_accuracy: 0.9910 - val_loss: 0.0502\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9889 - loss: 0.0506 - val_accuracy: 0.9940 - val_loss: 0.0450\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9924 - loss: 0.0422 - val_accuracy: 0.9935 - val_loss: 0.0439\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9923 - loss: 0.0409 - val_accuracy: 0.9908 - val_loss: 0.0445\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9921 - loss: 0.0404 - val_accuracy: 0.9937 - val_loss: 0.0406\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9914 - loss: 0.0407 - val_accuracy: 0.9933 - val_loss: 0.0402\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9928 - loss: 0.0410 - val_accuracy: 0.9933 - val_loss: 0.0425\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9935 - loss: 0.0366 - val_accuracy: 0.9935 - val_loss: 0.0412\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9935 - loss: 0.0337 - val_accuracy: 0.9910 - val_loss: 0.0450\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9937 - loss: 0.0333 - val_accuracy: 0.9915 - val_loss: 0.0448\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9938 - loss: 0.0295 - val_accuracy: 0.9937 - val_loss: 0.0405\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9944 - loss: 0.0258 - val_accuracy: 0.9935 - val_loss: 0.0406\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9920 - loss: 0.0359 - val_accuracy: 0.9930 - val_loss: 0.0450\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9934 - loss: 0.0313 - val_accuracy: 0.9925 - val_loss: 0.0413\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9948 - loss: 0.0265 - val_accuracy: 0.9933 - val_loss: 0.0418\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9937 - loss: 0.0307 - val_accuracy: 0.9935 - val_loss: 0.0387\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9942 - loss: 0.0278 - val_accuracy: 0.9935 - val_loss: 0.0392\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9939 - loss: 0.0261 - val_accuracy: 0.9935 - val_loss: 0.0413\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9937 - loss: 0.0272 - val_accuracy: 0.9918 - val_loss: 0.0487\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9943 - loss: 0.0231 - val_accuracy: 0.9923 - val_loss: 0.0487\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9942 - loss: 0.0248 - val_accuracy: 0.9930 - val_loss: 0.0449\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9949 - loss: 0.0224 - val_accuracy: 0.9925 - val_loss: 0.0461\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9955 - loss: 0.0192 - val_accuracy: 0.9930 - val_loss: 0.0439\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9945 - loss: 0.0217 - val_accuracy: 0.9925 - val_loss: 0.0487\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9944 - loss: 0.0224 - val_accuracy: 0.9920 - val_loss: 0.0471\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.9918 - val_loss: 0.0520\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9950 - loss: 0.0192 - val_accuracy: 0.9923 - val_loss: 0.0535\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9956 - loss: 0.0173 - val_accuracy: 0.9927 - val_loss: 0.0487\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9953 - loss: 0.0187 - val_accuracy: 0.9923 - val_loss: 0.0523\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9957 - loss: 0.0134 - val_accuracy: 0.9855 - val_loss: 0.0637\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9949 - loss: 0.0179 - val_accuracy: 0.9920 - val_loss: 0.0527\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9959 - loss: 0.0143 - val_accuracy: 0.9905 - val_loss: 0.0565\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9959 - loss: 0.0155 - val_accuracy: 0.9923 - val_loss: 0.0550\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9955 - loss: 0.0144 - val_accuracy: 0.9908 - val_loss: 0.0559\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9954 - loss: 0.0140 - val_accuracy: 0.9900 - val_loss: 0.0592\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9940 - loss: 0.0179 - val_accuracy: 0.9923 - val_loss: 0.0582\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9957 - loss: 0.0115 - val_accuracy: 0.9920 - val_loss: 0.0580\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9953 - loss: 0.0130 - val_accuracy: 0.9920 - val_loss: 0.0597\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9918 - val_loss: 0.0621\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9912 - val_loss: 0.0636\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9966 - loss: 0.0116 - val_accuracy: 0.9918 - val_loss: 0.0615\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9969 - loss: 0.0098 - val_accuracy: 0.9918 - val_loss: 0.0674\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9966 - loss: 0.0108 - val_accuracy: 0.9905 - val_loss: 0.0658\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9908 - val_loss: 0.0615\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9965 - loss: 0.0106 - val_accuracy: 0.9877 - val_loss: 0.0707\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9965 - loss: 0.0109 - val_accuracy: 0.9875 - val_loss: 0.0751\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9967 - loss: 0.0091 - val_accuracy: 0.9898 - val_loss: 0.0707\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9960 - loss: 0.0111 - val_accuracy: 0.9872 - val_loss: 0.0781\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9961 - loss: 0.0110 - val_accuracy: 0.9908 - val_loss: 0.0677\n",
    "Time taken in seconds  118.47824621200562"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bc1ba",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s6ms/step - accuracy: 0.9587 - loss: 0.1611 - val_accuracy: 0.9870 - val_loss: 0.0620\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9875 - loss: 0.0590 - val_accuracy: 0.9910 - val_loss: 0.0502\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9889 - loss: 0.0506 - val_accuracy: 0.9940 - val_loss: 0.0450\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9924 - loss: 0.0422 - val_accuracy: 0.9935 - val_loss: 0.0439\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9923 - loss: 0.0409 - val_accuracy: 0.9908 - val_loss: 0.0445\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9921 - loss: 0.0404 - val_accuracy: 0.9937 - val_loss: 0.0406\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9914 - loss: 0.0407 - val_accuracy: 0.9933 - val_loss: 0.0402\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9928 - loss: 0.0410 - val_accuracy: 0.9933 - val_loss: 0.0425\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9935 - loss: 0.0366 - val_accuracy: 0.9935 - val_loss: 0.0412\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9935 - loss: 0.0337 - val_accuracy: 0.9910 - val_loss: 0.0450\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9937 - loss: 0.0333 - val_accuracy: 0.9915 - val_loss: 0.0448\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9938 - loss: 0.0295 - val_accuracy: 0.9937 - val_loss: 0.0405\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9944 - loss: 0.0258 - val_accuracy: 0.9935 - val_loss: 0.0406\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9920 - loss: 0.0359 - val_accuracy: 0.9930 - val_loss: 0.0450\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9934 - loss: 0.0313 - val_accuracy: 0.9925 - val_loss: 0.0413\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9948 - loss: 0.0265 - val_accuracy: 0.9933 - val_loss: 0.0418\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9937 - loss: 0.0307 - val_accuracy: 0.9935 - val_loss: 0.0387\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9942 - loss: 0.0278 - val_accuracy: 0.9935 - val_loss: 0.0392\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9939 - loss: 0.0261 - val_accuracy: 0.9935 - val_loss: 0.0413\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9937 - loss: 0.0272 - val_accuracy: 0.9918 - val_loss: 0.0487\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9943 - loss: 0.0231 - val_accuracy: 0.9923 - val_loss: 0.0487\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9942 - loss: 0.0248 - val_accuracy: 0.9930 - val_loss: 0.0449\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9949 - loss: 0.0224 - val_accuracy: 0.9925 - val_loss: 0.0461\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9955 - loss: 0.0192 - val_accuracy: 0.9930 - val_loss: 0.0439\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9945 - loss: 0.0217 - val_accuracy: 0.9925 - val_loss: 0.0487\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9944 - loss: 0.0224 - val_accuracy: 0.9920 - val_loss: 0.0471\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.9918 - val_loss: 0.0520\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9950 - loss: 0.0192 - val_accuracy: 0.9923 - val_loss: 0.0535\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9956 - loss: 0.0173 - val_accuracy: 0.9927 - val_loss: 0.0487\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9953 - loss: 0.0187 - val_accuracy: 0.9923 - val_loss: 0.0523\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9957 - loss: 0.0134 - val_accuracy: 0.9855 - val_loss: 0.0637\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9949 - loss: 0.0179 - val_accuracy: 0.9920 - val_loss: 0.0527\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9959 - loss: 0.0143 - val_accuracy: 0.9905 - val_loss: 0.0565\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9959 - loss: 0.0155 - val_accuracy: 0.9923 - val_loss: 0.0550\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9955 - loss: 0.0144 - val_accuracy: 0.9908 - val_loss: 0.0559\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9954 - loss: 0.0140 - val_accuracy: 0.9900 - val_loss: 0.0592\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9940 - loss: 0.0179 - val_accuracy: 0.9923 - val_loss: 0.0582\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9957 - loss: 0.0115 - val_accuracy: 0.9920 - val_loss: 0.0580\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9953 - loss: 0.0130 - val_accuracy: 0.9920 - val_loss: 0.0597\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9918 - val_loss: 0.0621\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9912 - val_loss: 0.0636\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9966 - loss: 0.0116 - val_accuracy: 0.9918 - val_loss: 0.0615\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9969 - loss: 0.0098 - val_accuracy: 0.9918 - val_loss: 0.0674\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9966 - loss: 0.0108 - val_accuracy: 0.9905 - val_loss: 0.0658\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9908 - val_loss: 0.0615\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━1s3ms/step - accuracy: 0.9965 - loss: 0.0106 - val_accuracy: 0.9877 - val_loss: 0.0707\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9965 - loss: 0.0109 - val_accuracy: 0.9875 - val_loss: 0.0751\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9967 - loss: 0.0091 - val_accuracy: 0.9898 - val_loss: 0.0707\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9960 - loss: 0.0111 - val_accuracy: 0.9872 - val_loss: 0.0781\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9961 - loss: 0.0110 - val_accuracy: 0.9908 - val_loss: 0.0677\n",
    "Time taken in seconds  118.47824621200562"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b908d",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_4\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     15112\n",
    "         1.0       0.99      0.97      0.98       888\n",
    "\n",
    "    accuracy                           1.00     16000\n",
    "   macro avg       0.99      0.98      0.99     16000\n",
    "weighted avg       1.00      1.00      1.00     16000\n",
    "\n",
    "Classification Report - Validation data Model_4\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.93      0.90      0.92       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.96      0.95      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09af888",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_4\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     15112\n",
    "         1.0       0.99      0.97      0.98       888\n",
    "\n",
    "    accuracy                           1.00     16000\n",
    "   macro avg       0.99      0.98      0.99     16000\n",
    "weighted avg       1.00      1.00      1.00     16000\n",
    "\n",
    "Classification Report - Validation data Model_4\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.93      0.90      0.92       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.96      0.95      0.96      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361160a",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Optimizer Comparison:Adam optimizer shows faster convergence than SGDAdaptive learning rates improve training efficiencyMore stable training process with fewer oscillationsConvergence Characteristics:Faster convergence to optimal solutionSmoother loss curves with fewer spikesBetter handling of different learning rates for different parametersPerformance Stability:More consistent training across different runsLess sensitive to initial learning rate settingsBetter final performance compared to SGDTraining Efficiency:Fewer epochs needed to reach good performanceMore efficient parameter updatesBetter handling of sparse gradientsModel Quality:Similar or slightly better final performanceMore reliable training processBetter suited for complex neural network architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b86c9e",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Optimizer Comparison:Adam optimizer shows faster convergence than SGDAdaptive learning rates improve training efficiencyMore stable training process with fewer oscillationsConvergence Characteristics:Faster convergence to optimal solutionSmoother loss curves with fewer spikesBetter handling of different learning rates for different parametersPerformance Stability:More consistent training across different runsLess sensitive to initial learning rate settingsBetter final performance compared to SGDTraining Efficiency:Fewer epochs needed to reach good performanceMore efficient parameter updatesBetter handling of sparse gradientsModel Quality:Similar or slightly better final performanceMore reliable training processBetter suited for complex neural network architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f749b05",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Optimizer Comparison:Adam optimizer shows faster convergence than SGDAdaptive learning rates improve training efficiencyMore stable training process with fewer oscillationsConvergence Characteristics:Faster convergence to optimal solutionSmoother loss curves with fewer spikesBetter handling of different learning rates for different parametersPerformance Stability:More consistent training across different runsLess sensitive to initial learning rate settingsBetter final performance compared to SGDTraining Efficiency:Fewer epochs needed to reach good performanceMore efficient parameter updatesBetter handling of sparse gradientsModel Quality:Similar or slightly better final performanceMore reliable training processBetter suited for complex neural network architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8fb9bc",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Optimizer Comparison:Adam optimizer shows faster convergence than SGDAdaptive learning rates improve training efficiencyMore stable training process with fewer oscillationsConvergence Characteristics:Faster convergence to optimal solutionSmoother loss curves with fewer spikesBetter handling of different learning rates for different parametersPerformance Stability:More consistent training across different runsLess sensitive to initial learning rate settingsBetter final performance compared to SGDTraining Efficiency:Fewer epochs needed to reach good performanceMore efficient parameter updatesBetter handling of sparse gradientsModel Quality:Similar or slightly better final performanceMore reliable training processBetter suited for complex neural network architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f098dc",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e6b31",
   "metadata": {},
   "source": [
    "Optimizer Comparison:Adam optimizer shows faster convergence than SGDAdaptive learning rates improve training efficiencyMore stable training process with fewer oscillations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d11b4d",
   "metadata": {},
   "source": [
    "Optimizer Comparison:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5bcb8",
   "metadata": {},
   "source": [
    "Adam optimizer shows faster convergence than SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9243ec",
   "metadata": {},
   "source": [
    "Adaptive learning rates improve training efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ce86f",
   "metadata": {},
   "source": [
    "More stable training process with fewer oscillations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd0b8e1",
   "metadata": {},
   "source": [
    "Convergence Characteristics:Faster convergence to optimal solutionSmoother loss curves with fewer spikesBetter handling of different learning rates for different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f541aad",
   "metadata": {},
   "source": [
    "Convergence Characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7260621",
   "metadata": {},
   "source": [
    "Faster convergence to optimal solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740db6f",
   "metadata": {},
   "source": [
    "Smoother loss curves with fewer spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f38638",
   "metadata": {},
   "source": [
    "Better handling of different learning rates for different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41256c",
   "metadata": {},
   "source": [
    "Performance Stability:More consistent training across different runsLess sensitive to initial learning rate settingsBetter final performance compared to SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d235d322",
   "metadata": {},
   "source": [
    "Performance Stability:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3e426",
   "metadata": {},
   "source": [
    "More consistent training across different runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151293e",
   "metadata": {},
   "source": [
    "Less sensitive to initial learning rate settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067e795",
   "metadata": {},
   "source": [
    "Better final performance compared to SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1119b7d",
   "metadata": {},
   "source": [
    "Training Efficiency:Fewer epochs needed to reach good performanceMore efficient parameter updatesBetter handling of sparse gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7baeee8",
   "metadata": {},
   "source": [
    "Training Efficiency:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc136b11",
   "metadata": {},
   "source": [
    "Fewer epochs needed to reach good performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc122e4",
   "metadata": {},
   "source": [
    "More efficient parameter updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ed584",
   "metadata": {},
   "source": [
    "Better handling of sparse gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c73ee3",
   "metadata": {},
   "source": [
    "Model Quality:Similar or slightly better final performanceMore reliable training processBetter suited for complex neural network architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0869e554",
   "metadata": {},
   "source": [
    "Model Quality:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109bec3e",
   "metadata": {},
   "source": [
    "Similar or slightly better final performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0116994",
   "metadata": {},
   "source": [
    "More reliable training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6abc4a",
   "metadata": {},
   "source": [
    "Better suited for complex neural network architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6493eb6",
   "metadata": {},
   "source": [
    "Model 5¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2717b7a",
   "metadata": {},
   "source": [
    "Model 5¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052becf5",
   "metadata": {},
   "source": [
    "Model 5¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c51aab",
   "metadata": {},
   "source": [
    "Model 5¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec7410",
   "metadata": {},
   "source": [
    "Model 5¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8068fd88",
   "metadata": {},
   "source": [
    "In [21]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_5=Sequential()model_5.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.3))# Define the dropout ratemodel_5.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.2))# Define the dropout ratemodel_5.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_5.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_5.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_5.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_5_train_perf=model_performance_classification(model_5,X_train_scaled,y_train)model_5_train_perfmodel_5_val_perf=model_performance_classification(model_5,X_val_scaled,y_val)model_5_val_perfy_train_pred_5=model_5.predict(X_train_scaled)y_val_pred_5=model_5.predict(X_val_scaled)print(\"Classification Report - Train data Model_5\",end=\"\\n\\n\")cr_train_model_5=classification_report(y_train,y_train_pred_5>0.5)print(cr_train_model_5)print(\"Classification Report - Validation data Model_5\",end=\"\\n\\n\")cr_val_model_5=classification_report(y_val,y_val_pred_5>0.5)print(cr_val_model_5)Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization             │ (None,128)            │512│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_1           │ (None,64)             │256│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_1 (Dropout)             │ (None,64)             │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:14,337(56.00 KB)Trainable params:13,953(54.50 KB)Non-trainable params:384(1.50 KB)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s5ms/step - accuracy: 0.8049 - loss: 0.4314 - val_accuracy: 0.9865 - val_loss: 0.0584\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9792 - loss: 0.0855 - val_accuracy: 0.9895 - val_loss: 0.0486\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9847 - loss: 0.0601 - val_accuracy: 0.9915 - val_loss: 0.0430\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9849 - loss: 0.0610 - val_accuracy: 0.9925 - val_loss: 0.0443\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9880 - loss: 0.0522 - val_accuracy: 0.9942 - val_loss: 0.0405\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9895 - loss: 0.0464 - val_accuracy: 0.9927 - val_loss: 0.0419\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9878 - loss: 0.0499 - val_accuracy: 0.9937 - val_loss: 0.0385\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━4s3ms/step - accuracy: 0.9886 - loss: 0.0484 - val_accuracy: 0.9930 - val_loss: 0.0401\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9889 - loss: 0.0508 - val_accuracy: 0.9935 - val_loss: 0.0384\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9898 - loss: 0.0500 - val_accuracy: 0.9927 - val_loss: 0.0387\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9907 - loss: 0.0440 - val_accuracy: 0.9930 - val_loss: 0.0375\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9894 - loss: 0.0519 - val_accuracy: 0.9933 - val_loss: 0.0376\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9884 - loss: 0.0505 - val_accuracy: 0.9935 - val_loss: 0.0388\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9887 - loss: 0.0521 - val_accuracy: 0.9940 - val_loss: 0.0371\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9898 - loss: 0.0475 - val_accuracy: 0.9937 - val_loss: 0.0377\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9905 - loss: 0.0490 - val_accuracy: 0.9937 - val_loss: 0.0373\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9891 - loss: 0.0486 - val_accuracy: 0.9935 - val_loss: 0.0370\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9891 - loss: 0.0533 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9910 - loss: 0.0450 - val_accuracy: 0.9937 - val_loss: 0.0359\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9914 - loss: 0.0399 - val_accuracy: 0.9935 - val_loss: 0.0376\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9904 - loss: 0.0445 - val_accuracy: 0.9937 - val_loss: 0.0360\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9911 - loss: 0.0458 - val_accuracy: 0.9933 - val_loss: 0.0366\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9899 - loss: 0.0441 - val_accuracy: 0.9940 - val_loss: 0.0359\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9912 - loss: 0.0450 - val_accuracy: 0.9935 - val_loss: 0.0365\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9920 - loss: 0.0398 - val_accuracy: 0.9940 - val_loss: 0.0373\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9917 - loss: 0.0372 - val_accuracy: 0.9940 - val_loss: 0.0355\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9913 - loss: 0.0399 - val_accuracy: 0.9940 - val_loss: 0.0355\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9915 - loss: 0.0391 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9915 - loss: 0.0422 - val_accuracy: 0.9940 - val_loss: 0.0377\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9915 - loss: 0.0403 - val_accuracy: 0.9935 - val_loss: 0.0379\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9920 - loss: 0.0381 - val_accuracy: 0.9937 - val_loss: 0.0378\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9924 - loss: 0.0385 - val_accuracy: 0.9937 - val_loss: 0.0361\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9920 - loss: 0.0406 - val_accuracy: 0.9937 - val_loss: 0.0363\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9913 - loss: 0.0430 - val_accuracy: 0.9930 - val_loss: 0.0383\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9913 - loss: 0.0403 - val_accuracy: 0.9937 - val_loss: 0.0367\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9918 - loss: 0.0353 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9921 - loss: 0.0331 - val_accuracy: 0.9937 - val_loss: 0.0364\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9923 - loss: 0.0369 - val_accuracy: 0.9937 - val_loss: 0.0363\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9914 - loss: 0.0410 - val_accuracy: 0.9937 - val_loss: 0.0374\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9923 - loss: 0.0356 - val_accuracy: 0.9937 - val_loss: 0.0377\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9922 - loss: 0.0377 - val_accuracy: 0.9942 - val_loss: 0.0375\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9912 - loss: 0.0480 - val_accuracy: 0.9945 - val_loss: 0.0367\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9917 - loss: 0.0366 - val_accuracy: 0.9948 - val_loss: 0.0357\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9919 - loss: 0.0375 - val_accuracy: 0.9948 - val_loss: 0.0345\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9918 - loss: 0.0378 - val_accuracy: 0.9937 - val_loss: 0.0357\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9929 - loss: 0.0336 - val_accuracy: 0.9942 - val_loss: 0.0362\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9928 - loss: 0.0315 - val_accuracy: 0.9940 - val_loss: 0.0362\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9928 - loss: 0.0335 - val_accuracy: 0.9935 - val_loss: 0.0369\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9918 - loss: 0.0379 - val_accuracy: 0.9942 - val_loss: 0.0359\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9935 - loss: 0.0326 - val_accuracy: 0.9945 - val_loss: 0.0374\n",
    "Time taken in seconds  133.36353707313538500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_5\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       1.00      0.90      0.95       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.95      0.97     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_5\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.99      0.91      0.95       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.96      0.97      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa33836",
   "metadata": {},
   "source": [
    "In [21]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_5=Sequential()model_5.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.3))# Define the dropout ratemodel_5.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.2))# Define the dropout ratemodel_5.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_5.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_5.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_5.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_5_train_perf=model_performance_classification(model_5,X_train_scaled,y_train)model_5_train_perfmodel_5_val_perf=model_performance_classification(model_5,X_val_scaled,y_val)model_5_val_perfy_train_pred_5=model_5.predict(X_train_scaled)y_val_pred_5=model_5.predict(X_val_scaled)print(\"Classification Report - Train data Model_5\",end=\"\\n\\n\")cr_train_model_5=classification_report(y_train,y_train_pred_5>0.5)print(cr_train_model_5)print(\"Classification Report - Validation data Model_5\",end=\"\\n\\n\")cr_val_model_5=classification_report(y_val,y_val_pred_5>0.5)print(cr_val_model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694cb29d",
   "metadata": {},
   "source": [
    "In [21]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_5=Sequential()model_5.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.3))# Define the dropout ratemodel_5.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.2))# Define the dropout ratemodel_5.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_5.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_5.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_5.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_5_train_perf=model_performance_classification(model_5,X_train_scaled,y_train)model_5_train_perfmodel_5_val_perf=model_performance_classification(model_5,X_val_scaled,y_val)model_5_val_perfy_train_pred_5=model_5.predict(X_train_scaled)y_val_pred_5=model_5.predict(X_val_scaled)print(\"Classification Report - Train data Model_5\",end=\"\\n\\n\")cr_train_model_5=classification_report(y_train,y_train_pred_5>0.5)print(cr_train_model_5)print(\"Classification Report - Validation data Model_5\",end=\"\\n\\n\")cr_val_model_5=classification_report(y_val,y_val_pred_5>0.5)print(cr_val_model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0bed7",
   "metadata": {},
   "source": [
    "In [21]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd846976",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_5=Sequential()model_5.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.3))# Define the dropout ratemodel_5.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.2))# Define the dropout ratemodel_5.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_5.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_5.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_5.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_5_train_perf=model_performance_classification(model_5,X_train_scaled,y_train)model_5_train_perfmodel_5_val_perf=model_performance_classification(model_5,X_val_scaled,y_val)model_5_val_perfy_train_pred_5=model_5.predict(X_train_scaled)y_val_pred_5=model_5.predict(X_val_scaled)print(\"Classification Report - Train data Model_5\",end=\"\\n\\n\")cr_train_model_5=classification_report(y_train,y_train_pred_5>0.5)print(cr_train_model_5)print(\"Classification Report - Validation data Model_5\",end=\"\\n\\n\")cr_val_model_5=classification_report(y_val,y_val_pred_5>0.5)print(cr_val_model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec3c53",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_5=Sequential()model_5.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.3))# Define the dropout ratemodel_5.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.2))# Define the dropout ratemodel_5.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_5.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_5.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_5.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_5_train_perf=model_performance_classification(model_5,X_train_scaled,y_train)model_5_train_perfmodel_5_val_perf=model_performance_classification(model_5,X_val_scaled,y_val)model_5_val_perfy_train_pred_5=model_5.predict(X_train_scaled)y_val_pred_5=model_5.predict(X_val_scaled)print(\"Classification Report - Train data Model_5\",end=\"\\n\\n\")cr_train_model_5=classification_report(y_train,y_train_pred_5>0.5)print(cr_train_model_5)print(\"Classification Report - Validation data Model_5\",end=\"\\n\\n\")cr_val_model_5=classification_report(y_val,y_val_pred_5>0.5)print(cr_val_model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9b424",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_5=Sequential()model_5.add(Dense(128,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.3))# Define the dropout ratemodel_5.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_5.add(BatchNormalization())# Add batch normalizationmodel_5.add(Dropout(0.2))# Define the dropout ratemodel_5.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_5.summary()optimizer=tf.keras.optimizers.Adam()# defining Adam as the optimizer to be usedmodel_5.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_5.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs)end=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_5_train_perf=model_performance_classification(model_5,X_train_scaled,y_train)model_5_train_perfmodel_5_val_perf=model_performance_classification(model_5,X_val_scaled,y_val)model_5_val_perfy_train_pred_5=model_5.predict(X_train_scaled)y_val_pred_5=model_5.predict(X_val_scaled)print(\"Classification Report - Train data Model_5\",end=\"\\n\\n\")cr_train_model_5=classification_report(y_train,y_train_pred_5>0.5)print(cr_train_model_5)print(\"Classification Report - Validation data Model_5\",end=\"\\n\\n\")cr_val_model_5=classification_report(y_val,y_val_pred_5>0.5)print(cr_val_model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0699ef18",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization             │ (None,128)            │512│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_1           │ (None,64)             │256│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_1 (Dropout)             │ (None,64)             │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:14,337(56.00 KB)Trainable params:13,953(54.50 KB)Non-trainable params:384(1.50 KB)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s5ms/step - accuracy: 0.8049 - loss: 0.4314 - val_accuracy: 0.9865 - val_loss: 0.0584\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9792 - loss: 0.0855 - val_accuracy: 0.9895 - val_loss: 0.0486\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9847 - loss: 0.0601 - val_accuracy: 0.9915 - val_loss: 0.0430\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9849 - loss: 0.0610 - val_accuracy: 0.9925 - val_loss: 0.0443\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9880 - loss: 0.0522 - val_accuracy: 0.9942 - val_loss: 0.0405\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9895 - loss: 0.0464 - val_accuracy: 0.9927 - val_loss: 0.0419\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9878 - loss: 0.0499 - val_accuracy: 0.9937 - val_loss: 0.0385\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━4s3ms/step - accuracy: 0.9886 - loss: 0.0484 - val_accuracy: 0.9930 - val_loss: 0.0401\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9889 - loss: 0.0508 - val_accuracy: 0.9935 - val_loss: 0.0384\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9898 - loss: 0.0500 - val_accuracy: 0.9927 - val_loss: 0.0387\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9907 - loss: 0.0440 - val_accuracy: 0.9930 - val_loss: 0.0375\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9894 - loss: 0.0519 - val_accuracy: 0.9933 - val_loss: 0.0376\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9884 - loss: 0.0505 - val_accuracy: 0.9935 - val_loss: 0.0388\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9887 - loss: 0.0521 - val_accuracy: 0.9940 - val_loss: 0.0371\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9898 - loss: 0.0475 - val_accuracy: 0.9937 - val_loss: 0.0377\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9905 - loss: 0.0490 - val_accuracy: 0.9937 - val_loss: 0.0373\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9891 - loss: 0.0486 - val_accuracy: 0.9935 - val_loss: 0.0370\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9891 - loss: 0.0533 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9910 - loss: 0.0450 - val_accuracy: 0.9937 - val_loss: 0.0359\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9914 - loss: 0.0399 - val_accuracy: 0.9935 - val_loss: 0.0376\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9904 - loss: 0.0445 - val_accuracy: 0.9937 - val_loss: 0.0360\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9911 - loss: 0.0458 - val_accuracy: 0.9933 - val_loss: 0.0366\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9899 - loss: 0.0441 - val_accuracy: 0.9940 - val_loss: 0.0359\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9912 - loss: 0.0450 - val_accuracy: 0.9935 - val_loss: 0.0365\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9920 - loss: 0.0398 - val_accuracy: 0.9940 - val_loss: 0.0373\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9917 - loss: 0.0372 - val_accuracy: 0.9940 - val_loss: 0.0355\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9913 - loss: 0.0399 - val_accuracy: 0.9940 - val_loss: 0.0355\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9915 - loss: 0.0391 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9915 - loss: 0.0422 - val_accuracy: 0.9940 - val_loss: 0.0377\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9915 - loss: 0.0403 - val_accuracy: 0.9935 - val_loss: 0.0379\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9920 - loss: 0.0381 - val_accuracy: 0.9937 - val_loss: 0.0378\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9924 - loss: 0.0385 - val_accuracy: 0.9937 - val_loss: 0.0361\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9920 - loss: 0.0406 - val_accuracy: 0.9937 - val_loss: 0.0363\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9913 - loss: 0.0430 - val_accuracy: 0.9930 - val_loss: 0.0383\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9913 - loss: 0.0403 - val_accuracy: 0.9937 - val_loss: 0.0367\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9918 - loss: 0.0353 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9921 - loss: 0.0331 - val_accuracy: 0.9937 - val_loss: 0.0364\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9923 - loss: 0.0369 - val_accuracy: 0.9937 - val_loss: 0.0363\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9914 - loss: 0.0410 - val_accuracy: 0.9937 - val_loss: 0.0374\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9923 - loss: 0.0356 - val_accuracy: 0.9937 - val_loss: 0.0377\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9922 - loss: 0.0377 - val_accuracy: 0.9942 - val_loss: 0.0375\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9912 - loss: 0.0480 - val_accuracy: 0.9945 - val_loss: 0.0367\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9917 - loss: 0.0366 - val_accuracy: 0.9948 - val_loss: 0.0357\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9919 - loss: 0.0375 - val_accuracy: 0.9948 - val_loss: 0.0345\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9918 - loss: 0.0378 - val_accuracy: 0.9937 - val_loss: 0.0357\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9929 - loss: 0.0336 - val_accuracy: 0.9942 - val_loss: 0.0362\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9928 - loss: 0.0315 - val_accuracy: 0.9940 - val_loss: 0.0362\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9928 - loss: 0.0335 - val_accuracy: 0.9935 - val_loss: 0.0369\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9918 - loss: 0.0379 - val_accuracy: 0.9942 - val_loss: 0.0359\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9935 - loss: 0.0326 - val_accuracy: 0.9945 - val_loss: 0.0374\n",
    "Time taken in seconds  133.36353707313538500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_5\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       1.00      0.90      0.95       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.95      0.97     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_5\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.99      0.91      0.95       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.96      0.97      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ac312",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization             │ (None,128)            │512│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_1           │ (None,64)             │256│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_1 (Dropout)             │ (None,64)             │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:14,337(56.00 KB)Trainable params:13,953(54.50 KB)Non-trainable params:384(1.50 KB)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s5ms/step - accuracy: 0.8049 - loss: 0.4314 - val_accuracy: 0.9865 - val_loss: 0.0584\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9792 - loss: 0.0855 - val_accuracy: 0.9895 - val_loss: 0.0486\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9847 - loss: 0.0601 - val_accuracy: 0.9915 - val_loss: 0.0430\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9849 - loss: 0.0610 - val_accuracy: 0.9925 - val_loss: 0.0443\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9880 - loss: 0.0522 - val_accuracy: 0.9942 - val_loss: 0.0405\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9895 - loss: 0.0464 - val_accuracy: 0.9927 - val_loss: 0.0419\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9878 - loss: 0.0499 - val_accuracy: 0.9937 - val_loss: 0.0385\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━4s3ms/step - accuracy: 0.9886 - loss: 0.0484 - val_accuracy: 0.9930 - val_loss: 0.0401\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9889 - loss: 0.0508 - val_accuracy: 0.9935 - val_loss: 0.0384\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9898 - loss: 0.0500 - val_accuracy: 0.9927 - val_loss: 0.0387\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9907 - loss: 0.0440 - val_accuracy: 0.9930 - val_loss: 0.0375\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9894 - loss: 0.0519 - val_accuracy: 0.9933 - val_loss: 0.0376\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9884 - loss: 0.0505 - val_accuracy: 0.9935 - val_loss: 0.0388\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9887 - loss: 0.0521 - val_accuracy: 0.9940 - val_loss: 0.0371\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9898 - loss: 0.0475 - val_accuracy: 0.9937 - val_loss: 0.0377\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9905 - loss: 0.0490 - val_accuracy: 0.9937 - val_loss: 0.0373\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9891 - loss: 0.0486 - val_accuracy: 0.9935 - val_loss: 0.0370\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9891 - loss: 0.0533 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9910 - loss: 0.0450 - val_accuracy: 0.9937 - val_loss: 0.0359\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9914 - loss: 0.0399 - val_accuracy: 0.9935 - val_loss: 0.0376\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9904 - loss: 0.0445 - val_accuracy: 0.9937 - val_loss: 0.0360\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9911 - loss: 0.0458 - val_accuracy: 0.9933 - val_loss: 0.0366\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9899 - loss: 0.0441 - val_accuracy: 0.9940 - val_loss: 0.0359\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9912 - loss: 0.0450 - val_accuracy: 0.9935 - val_loss: 0.0365\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9920 - loss: 0.0398 - val_accuracy: 0.9940 - val_loss: 0.0373\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9917 - loss: 0.0372 - val_accuracy: 0.9940 - val_loss: 0.0355\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9913 - loss: 0.0399 - val_accuracy: 0.9940 - val_loss: 0.0355\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9915 - loss: 0.0391 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9915 - loss: 0.0422 - val_accuracy: 0.9940 - val_loss: 0.0377\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9915 - loss: 0.0403 - val_accuracy: 0.9935 - val_loss: 0.0379\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9920 - loss: 0.0381 - val_accuracy: 0.9937 - val_loss: 0.0378\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9924 - loss: 0.0385 - val_accuracy: 0.9937 - val_loss: 0.0361\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9920 - loss: 0.0406 - val_accuracy: 0.9937 - val_loss: 0.0363\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9913 - loss: 0.0430 - val_accuracy: 0.9930 - val_loss: 0.0383\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9913 - loss: 0.0403 - val_accuracy: 0.9937 - val_loss: 0.0367\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9918 - loss: 0.0353 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9921 - loss: 0.0331 - val_accuracy: 0.9937 - val_loss: 0.0364\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9923 - loss: 0.0369 - val_accuracy: 0.9937 - val_loss: 0.0363\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9914 - loss: 0.0410 - val_accuracy: 0.9937 - val_loss: 0.0374\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9923 - loss: 0.0356 - val_accuracy: 0.9937 - val_loss: 0.0377\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9922 - loss: 0.0377 - val_accuracy: 0.9942 - val_loss: 0.0375\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9912 - loss: 0.0480 - val_accuracy: 0.9945 - val_loss: 0.0367\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9917 - loss: 0.0366 - val_accuracy: 0.9948 - val_loss: 0.0357\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9919 - loss: 0.0375 - val_accuracy: 0.9948 - val_loss: 0.0345\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9918 - loss: 0.0378 - val_accuracy: 0.9937 - val_loss: 0.0357\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9929 - loss: 0.0336 - val_accuracy: 0.9942 - val_loss: 0.0362\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9928 - loss: 0.0315 - val_accuracy: 0.9940 - val_loss: 0.0362\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9928 - loss: 0.0335 - val_accuracy: 0.9935 - val_loss: 0.0369\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9918 - loss: 0.0379 - val_accuracy: 0.9942 - val_loss: 0.0359\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9935 - loss: 0.0326 - val_accuracy: 0.9945 - val_loss: 0.0374\n",
    "Time taken in seconds  133.36353707313538500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_5\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       1.00      0.90      0.95       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.95      0.97     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_5\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.99      0.91      0.95       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.96      0.97      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220055ab",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef472cd4",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e36cd2",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization             │ (None,128)            │512│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_1           │ (None,64)             │256│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_1 (Dropout)             │ (None,64)             │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc97180",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,128)            │5,248│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization             │ (None,128)            │512│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_1           │ (None,64)             │256│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_1 (Dropout)             │ (None,64)             │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00039386",
   "metadata": {},
   "source": [
    "Total params:14,337(56.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a69d58",
   "metadata": {},
   "source": [
    "Total params:14,337(56.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f71ee4",
   "metadata": {},
   "source": [
    "Trainable params:13,953(54.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93471857",
   "metadata": {},
   "source": [
    "Trainable params:13,953(54.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4272a28",
   "metadata": {},
   "source": [
    "Non-trainable params:384(1.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a8ce46",
   "metadata": {},
   "source": [
    "Non-trainable params:384(1.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12135308",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s5ms/step - accuracy: 0.8049 - loss: 0.4314 - val_accuracy: 0.9865 - val_loss: 0.0584\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9792 - loss: 0.0855 - val_accuracy: 0.9895 - val_loss: 0.0486\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9847 - loss: 0.0601 - val_accuracy: 0.9915 - val_loss: 0.0430\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9849 - loss: 0.0610 - val_accuracy: 0.9925 - val_loss: 0.0443\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9880 - loss: 0.0522 - val_accuracy: 0.9942 - val_loss: 0.0405\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9895 - loss: 0.0464 - val_accuracy: 0.9927 - val_loss: 0.0419\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9878 - loss: 0.0499 - val_accuracy: 0.9937 - val_loss: 0.0385\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━4s3ms/step - accuracy: 0.9886 - loss: 0.0484 - val_accuracy: 0.9930 - val_loss: 0.0401\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9889 - loss: 0.0508 - val_accuracy: 0.9935 - val_loss: 0.0384\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9898 - loss: 0.0500 - val_accuracy: 0.9927 - val_loss: 0.0387\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9907 - loss: 0.0440 - val_accuracy: 0.9930 - val_loss: 0.0375\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9894 - loss: 0.0519 - val_accuracy: 0.9933 - val_loss: 0.0376\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9884 - loss: 0.0505 - val_accuracy: 0.9935 - val_loss: 0.0388\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9887 - loss: 0.0521 - val_accuracy: 0.9940 - val_loss: 0.0371\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9898 - loss: 0.0475 - val_accuracy: 0.9937 - val_loss: 0.0377\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9905 - loss: 0.0490 - val_accuracy: 0.9937 - val_loss: 0.0373\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9891 - loss: 0.0486 - val_accuracy: 0.9935 - val_loss: 0.0370\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9891 - loss: 0.0533 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9910 - loss: 0.0450 - val_accuracy: 0.9937 - val_loss: 0.0359\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9914 - loss: 0.0399 - val_accuracy: 0.9935 - val_loss: 0.0376\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9904 - loss: 0.0445 - val_accuracy: 0.9937 - val_loss: 0.0360\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9911 - loss: 0.0458 - val_accuracy: 0.9933 - val_loss: 0.0366\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9899 - loss: 0.0441 - val_accuracy: 0.9940 - val_loss: 0.0359\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9912 - loss: 0.0450 - val_accuracy: 0.9935 - val_loss: 0.0365\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9920 - loss: 0.0398 - val_accuracy: 0.9940 - val_loss: 0.0373\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9917 - loss: 0.0372 - val_accuracy: 0.9940 - val_loss: 0.0355\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9913 - loss: 0.0399 - val_accuracy: 0.9940 - val_loss: 0.0355\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9915 - loss: 0.0391 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9915 - loss: 0.0422 - val_accuracy: 0.9940 - val_loss: 0.0377\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9915 - loss: 0.0403 - val_accuracy: 0.9935 - val_loss: 0.0379\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9920 - loss: 0.0381 - val_accuracy: 0.9937 - val_loss: 0.0378\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9924 - loss: 0.0385 - val_accuracy: 0.9937 - val_loss: 0.0361\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9920 - loss: 0.0406 - val_accuracy: 0.9937 - val_loss: 0.0363\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9913 - loss: 0.0430 - val_accuracy: 0.9930 - val_loss: 0.0383\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9913 - loss: 0.0403 - val_accuracy: 0.9937 - val_loss: 0.0367\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9918 - loss: 0.0353 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9921 - loss: 0.0331 - val_accuracy: 0.9937 - val_loss: 0.0364\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9923 - loss: 0.0369 - val_accuracy: 0.9937 - val_loss: 0.0363\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9914 - loss: 0.0410 - val_accuracy: 0.9937 - val_loss: 0.0374\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9923 - loss: 0.0356 - val_accuracy: 0.9937 - val_loss: 0.0377\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9922 - loss: 0.0377 - val_accuracy: 0.9942 - val_loss: 0.0375\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9912 - loss: 0.0480 - val_accuracy: 0.9945 - val_loss: 0.0367\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9917 - loss: 0.0366 - val_accuracy: 0.9948 - val_loss: 0.0357\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9919 - loss: 0.0375 - val_accuracy: 0.9948 - val_loss: 0.0345\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9918 - loss: 0.0378 - val_accuracy: 0.9937 - val_loss: 0.0357\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9929 - loss: 0.0336 - val_accuracy: 0.9942 - val_loss: 0.0362\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9928 - loss: 0.0315 - val_accuracy: 0.9940 - val_loss: 0.0362\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9928 - loss: 0.0335 - val_accuracy: 0.9935 - val_loss: 0.0369\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9918 - loss: 0.0379 - val_accuracy: 0.9942 - val_loss: 0.0359\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9935 - loss: 0.0326 - val_accuracy: 0.9945 - val_loss: 0.0374\n",
    "Time taken in seconds  133.36353707313538"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6938d389",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━5s5ms/step - accuracy: 0.8049 - loss: 0.4314 - val_accuracy: 0.9865 - val_loss: 0.0584\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9792 - loss: 0.0855 - val_accuracy: 0.9895 - val_loss: 0.0486\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9847 - loss: 0.0601 - val_accuracy: 0.9915 - val_loss: 0.0430\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9849 - loss: 0.0610 - val_accuracy: 0.9925 - val_loss: 0.0443\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9880 - loss: 0.0522 - val_accuracy: 0.9942 - val_loss: 0.0405\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9895 - loss: 0.0464 - val_accuracy: 0.9927 - val_loss: 0.0419\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9878 - loss: 0.0499 - val_accuracy: 0.9937 - val_loss: 0.0385\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━4s3ms/step - accuracy: 0.9886 - loss: 0.0484 - val_accuracy: 0.9930 - val_loss: 0.0401\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9889 - loss: 0.0508 - val_accuracy: 0.9935 - val_loss: 0.0384\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9898 - loss: 0.0500 - val_accuracy: 0.9927 - val_loss: 0.0387\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9907 - loss: 0.0440 - val_accuracy: 0.9930 - val_loss: 0.0375\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9894 - loss: 0.0519 - val_accuracy: 0.9933 - val_loss: 0.0376\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9884 - loss: 0.0505 - val_accuracy: 0.9935 - val_loss: 0.0388\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9887 - loss: 0.0521 - val_accuracy: 0.9940 - val_loss: 0.0371\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9898 - loss: 0.0475 - val_accuracy: 0.9937 - val_loss: 0.0377\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9905 - loss: 0.0490 - val_accuracy: 0.9937 - val_loss: 0.0373\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9891 - loss: 0.0486 - val_accuracy: 0.9935 - val_loss: 0.0370\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9891 - loss: 0.0533 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9910 - loss: 0.0450 - val_accuracy: 0.9937 - val_loss: 0.0359\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9914 - loss: 0.0399 - val_accuracy: 0.9935 - val_loss: 0.0376\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9904 - loss: 0.0445 - val_accuracy: 0.9937 - val_loss: 0.0360\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9911 - loss: 0.0458 - val_accuracy: 0.9933 - val_loss: 0.0366\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9899 - loss: 0.0441 - val_accuracy: 0.9940 - val_loss: 0.0359\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9912 - loss: 0.0450 - val_accuracy: 0.9935 - val_loss: 0.0365\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9920 - loss: 0.0398 - val_accuracy: 0.9940 - val_loss: 0.0373\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s3ms/step - accuracy: 0.9917 - loss: 0.0372 - val_accuracy: 0.9940 - val_loss: 0.0355\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9913 - loss: 0.0399 - val_accuracy: 0.9940 - val_loss: 0.0355\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9915 - loss: 0.0391 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9915 - loss: 0.0422 - val_accuracy: 0.9940 - val_loss: 0.0377\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9915 - loss: 0.0403 - val_accuracy: 0.9935 - val_loss: 0.0379\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9920 - loss: 0.0381 - val_accuracy: 0.9937 - val_loss: 0.0378\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s3ms/step - accuracy: 0.9924 - loss: 0.0385 - val_accuracy: 0.9937 - val_loss: 0.0361\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9920 - loss: 0.0406 - val_accuracy: 0.9937 - val_loss: 0.0363\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9913 - loss: 0.0430 - val_accuracy: 0.9930 - val_loss: 0.0383\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9913 - loss: 0.0403 - val_accuracy: 0.9937 - val_loss: 0.0367\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9918 - loss: 0.0353 - val_accuracy: 0.9940 - val_loss: 0.0370\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9921 - loss: 0.0331 - val_accuracy: 0.9937 - val_loss: 0.0364\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9923 - loss: 0.0369 - val_accuracy: 0.9937 - val_loss: 0.0363\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━4s6ms/step - accuracy: 0.9914 - loss: 0.0410 - val_accuracy: 0.9937 - val_loss: 0.0374\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9923 - loss: 0.0356 - val_accuracy: 0.9937 - val_loss: 0.0377\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9922 - loss: 0.0377 - val_accuracy: 0.9942 - val_loss: 0.0375\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9912 - loss: 0.0480 - val_accuracy: 0.9945 - val_loss: 0.0367\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9917 - loss: 0.0366 - val_accuracy: 0.9948 - val_loss: 0.0357\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9919 - loss: 0.0375 - val_accuracy: 0.9948 - val_loss: 0.0345\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9918 - loss: 0.0378 - val_accuracy: 0.9937 - val_loss: 0.0357\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9929 - loss: 0.0336 - val_accuracy: 0.9942 - val_loss: 0.0362\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9928 - loss: 0.0315 - val_accuracy: 0.9940 - val_loss: 0.0362\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9928 - loss: 0.0335 - val_accuracy: 0.9935 - val_loss: 0.0369\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9918 - loss: 0.0379 - val_accuracy: 0.9942 - val_loss: 0.0359\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9935 - loss: 0.0326 - val_accuracy: 0.9945 - val_loss: 0.0374\n",
    "Time taken in seconds  133.36353707313538"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ba600",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_5\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       1.00      0.90      0.95       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.95      0.97     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_5\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.99      0.91      0.95       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.96      0.97      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb5dac",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step500/500━━━━━━━━━━━━━━━━━━━━1s1ms/step125/125━━━━━━━━━━━━━━━━━━━━0s1ms/step\n",
    "Classification Report - Train data Model_5\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00     15112\n",
    "         1.0       1.00      0.90      0.95       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.99      0.95      0.97     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_5\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      3778\n",
    "         1.0       0.99      0.91      0.95       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.99      0.96      0.97      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91116289",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Training Stability:Batch normalization significantly improves training stabilityReduces internal covariate shiftMore consistent layer inputs throughout trainingConvergence Speed:Faster convergence due to normalized layer inputsHigher learning rates can be used safelyMore stable gradient flow through the networkPerformance Improvement:Likely the best performance so farImproved accuracy and F1-scoreBetter generalization to validation dataModel Robustness:More robust to different data distributionsBetter handling of varying input scalesReduced sensitivity to initializationArchitecture Benefits:Allows for deeper networks without vanishing gradientsEnables higher learning ratesImproves overall model reliability and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebddab5",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Training Stability:Batch normalization significantly improves training stabilityReduces internal covariate shiftMore consistent layer inputs throughout trainingConvergence Speed:Faster convergence due to normalized layer inputsHigher learning rates can be used safelyMore stable gradient flow through the networkPerformance Improvement:Likely the best performance so farImproved accuracy and F1-scoreBetter generalization to validation dataModel Robustness:More robust to different data distributionsBetter handling of varying input scalesReduced sensitivity to initializationArchitecture Benefits:Allows for deeper networks without vanishing gradientsEnables higher learning ratesImproves overall model reliability and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da18f39",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Training Stability:Batch normalization significantly improves training stabilityReduces internal covariate shiftMore consistent layer inputs throughout trainingConvergence Speed:Faster convergence due to normalized layer inputsHigher learning rates can be used safelyMore stable gradient flow through the networkPerformance Improvement:Likely the best performance so farImproved accuracy and F1-scoreBetter generalization to validation dataModel Robustness:More robust to different data distributionsBetter handling of varying input scalesReduced sensitivity to initializationArchitecture Benefits:Allows for deeper networks without vanishing gradientsEnables higher learning ratesImproves overall model reliability and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a6bf62",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Training Stability:Batch normalization significantly improves training stabilityReduces internal covariate shiftMore consistent layer inputs throughout trainingConvergence Speed:Faster convergence due to normalized layer inputsHigher learning rates can be used safelyMore stable gradient flow through the networkPerformance Improvement:Likely the best performance so farImproved accuracy and F1-scoreBetter generalization to validation dataModel Robustness:More robust to different data distributionsBetter handling of varying input scalesReduced sensitivity to initializationArchitecture Benefits:Allows for deeper networks without vanishing gradientsEnables higher learning ratesImproves overall model reliability and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49406231",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de1feb8",
   "metadata": {},
   "source": [
    "Training Stability:Batch normalization significantly improves training stabilityReduces internal covariate shiftMore consistent layer inputs throughout training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfeeb5c",
   "metadata": {},
   "source": [
    "Training Stability:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5e5aa",
   "metadata": {},
   "source": [
    "Batch normalization significantly improves training stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f1e42",
   "metadata": {},
   "source": [
    "Reduces internal covariate shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054929ab",
   "metadata": {},
   "source": [
    "More consistent layer inputs throughout training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d11826b",
   "metadata": {},
   "source": [
    "Convergence Speed:Faster convergence due to normalized layer inputsHigher learning rates can be used safelyMore stable gradient flow through the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf709af",
   "metadata": {},
   "source": [
    "Convergence Speed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05055ea1",
   "metadata": {},
   "source": [
    "Faster convergence due to normalized layer inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36f6a42",
   "metadata": {},
   "source": [
    "Higher learning rates can be used safely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77c784",
   "metadata": {},
   "source": [
    "More stable gradient flow through the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d0402",
   "metadata": {},
   "source": [
    "Performance Improvement:Likely the best performance so farImproved accuracy and F1-scoreBetter generalization to validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bbebca",
   "metadata": {},
   "source": [
    "Performance Improvement:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720a8f3",
   "metadata": {},
   "source": [
    "Likely the best performance so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae9615",
   "metadata": {},
   "source": [
    "Improved accuracy and F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680f494",
   "metadata": {},
   "source": [
    "Better generalization to validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f95d18",
   "metadata": {},
   "source": [
    "Model Robustness:More robust to different data distributionsBetter handling of varying input scalesReduced sensitivity to initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334c832",
   "metadata": {},
   "source": [
    "Model Robustness:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc79088",
   "metadata": {},
   "source": [
    "More robust to different data distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dface62d",
   "metadata": {},
   "source": [
    "Better handling of varying input scales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70554b8a",
   "metadata": {},
   "source": [
    "Reduced sensitivity to initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f65185",
   "metadata": {},
   "source": [
    "Architecture Benefits:Allows for deeper networks without vanishing gradientsEnables higher learning ratesImproves overall model reliability and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906bcf0",
   "metadata": {},
   "source": [
    "Architecture Benefits:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44290cd",
   "metadata": {},
   "source": [
    "Allows for deeper networks without vanishing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba7aa3",
   "metadata": {},
   "source": [
    "Enables higher learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb36b463",
   "metadata": {},
   "source": [
    "Improves overall model reliability and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155304f",
   "metadata": {},
   "source": [
    "Model 6¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b6018",
   "metadata": {},
   "source": [
    "Model 6¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b4de94",
   "metadata": {},
   "source": [
    "Model 6¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0c1ff",
   "metadata": {},
   "source": [
    "Model 6¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb1c9a",
   "metadata": {},
   "source": [
    "Model 6¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a375b",
   "metadata": {},
   "source": [
    "In [22]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_6=Sequential()model_6.add(Dense(256,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.4))# Define the dropout ratemodel_6.add(Dense(128,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.3))# Define the dropout ratemodel_6.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.2))# Define the dropout ratemodel_6.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_6.summary()optimizer=tf.keras.optimizers.SGD()model_6.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_6.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)# Use class weightsend=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_6_train_perf=model_performance_classification(model_6,X_train_scaled,y_train)model_6_train_perfmodel_6_val_perf=model_performance_classification(model_6,X_val_scaled,y_val)model_6_val_perfy_train_pred_6=model_6.predict(X_train_scaled)y_val_pred_6=model_6.predict(X_val_scaled)print(\"Classification Report - Train data Model_6\",end=\"\\n\\n\")cr_train_model_6=classification_report(y_train,y_train_pred_6>0.5)print(cr_train_model_6)print(\"Classification Report - Validation data Model_6\",end=\"\\n\\n\")cr_val_model_6=classification_report(y_val,y_val_pred_6>0.5)print(cr_val_model_6)Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,256)            │10,496│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization             │ (None,256)            │1,024│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,256)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,128)            │32,896│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_1           │ (None,128)            │512│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_1 (Dropout)             │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_2           │ (None,64)             │256│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_2 (Dropout)             │ (None,64)             │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:53,505(209.00 KB)Trainable params:52,609(205.50 KB)Non-trainable params:896(3.50 KB)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━6s4ms/step - accuracy: 0.7158 - loss: 0.9461 - val_accuracy: 0.9625 - val_loss: 0.1618\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.8940 - loss: 0.6839 - val_accuracy: 0.9665 - val_loss: 0.1474\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9178 - loss: 0.5449 - val_accuracy: 0.9797 - val_loss: 0.1139\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9253 - loss: 0.5186 - val_accuracy: 0.9778 - val_loss: 0.1200\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9325 - loss: 0.4972 - val_accuracy: 0.9790 - val_loss: 0.1192\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━5s4ms/step - accuracy: 0.9321 - loss: 0.5197 - val_accuracy: 0.9793 - val_loss: 0.1103\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9418 - loss: 0.4187 - val_accuracy: 0.9847 - val_loss: 0.1029\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9411 - loss: 0.4764 - val_accuracy: 0.9843 - val_loss: 0.0988\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9480 - loss: 0.4261 - val_accuracy: 0.9822 - val_loss: 0.0988\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9430 - loss: 0.4862 - val_accuracy: 0.9858 - val_loss: 0.0895\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9479 - loss: 0.4496 - val_accuracy: 0.9852 - val_loss: 0.0911\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9520 - loss: 0.3957 - val_accuracy: 0.9868 - val_loss: 0.0869\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9538 - loss: 0.4452 - val_accuracy: 0.9880 - val_loss: 0.0836\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9524 - loss: 0.4243 - val_accuracy: 0.9822 - val_loss: 0.0992\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9473 - loss: 0.4242 - val_accuracy: 0.9877 - val_loss: 0.0901\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9548 - loss: 0.4259 - val_accuracy: 0.9868 - val_loss: 0.0859\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9589 - loss: 0.3675 - val_accuracy: 0.9855 - val_loss: 0.0868\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9509 - loss: 0.4003 - val_accuracy: 0.9870 - val_loss: 0.0833\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9559 - loss: 0.4316 - val_accuracy: 0.9820 - val_loss: 0.0905\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9520 - loss: 0.3845 - val_accuracy: 0.9883 - val_loss: 0.0847\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9521 - loss: 0.4062 - val_accuracy: 0.9820 - val_loss: 0.0945\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9585 - loss: 0.3839 - val_accuracy: 0.9870 - val_loss: 0.0847\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9594 - loss: 0.3922 - val_accuracy: 0.9860 - val_loss: 0.0809\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9571 - loss: 0.3781 - val_accuracy: 0.9890 - val_loss: 0.0843\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━5s4ms/step - accuracy: 0.9615 - loss: 0.3715 - val_accuracy: 0.9852 - val_loss: 0.0862\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9559 - loss: 0.4103 - val_accuracy: 0.9855 - val_loss: 0.0836\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9599 - loss: 0.3325 - val_accuracy: 0.9855 - val_loss: 0.0794\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9584 - loss: 0.4122 - val_accuracy: 0.9860 - val_loss: 0.0804\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9601 - loss: 0.3285 - val_accuracy: 0.9872 - val_loss: 0.0806\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9593 - loss: 0.3667 - val_accuracy: 0.9885 - val_loss: 0.0762\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9658 - loss: 0.3206 - val_accuracy: 0.9880 - val_loss: 0.0787\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9597 - loss: 0.3852 - val_accuracy: 0.9868 - val_loss: 0.0783\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9614 - loss: 0.4023 - val_accuracy: 0.9860 - val_loss: 0.0838\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9610 - loss: 0.3827 - val_accuracy: 0.9862 - val_loss: 0.0802\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9600 - loss: 0.3044 - val_accuracy: 0.9880 - val_loss: 0.0794\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9622 - loss: 0.3360 - val_accuracy: 0.9875 - val_loss: 0.0820\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9612 - loss: 0.3493 - val_accuracy: 0.9865 - val_loss: 0.0751\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9645 - loss: 0.3500 - val_accuracy: 0.9868 - val_loss: 0.0830\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9655 - loss: 0.3240 - val_accuracy: 0.9862 - val_loss: 0.0813\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9596 - loss: 0.3863 - val_accuracy: 0.9875 - val_loss: 0.0830\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9636 - loss: 0.3644 - val_accuracy: 0.9825 - val_loss: 0.0914\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9635 - loss: 0.3555 - val_accuracy: 0.9877 - val_loss: 0.0737\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9682 - loss: 0.3047 - val_accuracy: 0.9872 - val_loss: 0.0802\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9649 - loss: 0.3235 - val_accuracy: 0.9843 - val_loss: 0.0910\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9645 - loss: 0.3094 - val_accuracy: 0.9845 - val_loss: 0.0884\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9637 - loss: 0.3590 - val_accuracy: 0.9872 - val_loss: 0.0815\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9661 - loss: 0.3024 - val_accuracy: 0.9837 - val_loss: 0.0860\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9644 - loss: 0.3194 - val_accuracy: 0.9852 - val_loss: 0.0821\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s7ms/step - accuracy: 0.9621 - loss: 0.3719 - val_accuracy: 0.9845 - val_loss: 0.0886\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9580 - loss: 0.3949 - val_accuracy: 0.9855 - val_loss: 0.0799\n",
    "Time taken in seconds  144.15532851219177500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_6\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     15112\n",
    "         1.0       0.86      0.93      0.89       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.93      0.96      0.94     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_6\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99      3778\n",
    "         1.0       0.84      0.92      0.88       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.92      0.95      0.93      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9605b3",
   "metadata": {},
   "source": [
    "In [22]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_6=Sequential()model_6.add(Dense(256,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.4))# Define the dropout ratemodel_6.add(Dense(128,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.3))# Define the dropout ratemodel_6.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.2))# Define the dropout ratemodel_6.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_6.summary()optimizer=tf.keras.optimizers.SGD()model_6.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_6.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)# Use class weightsend=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_6_train_perf=model_performance_classification(model_6,X_train_scaled,y_train)model_6_train_perfmodel_6_val_perf=model_performance_classification(model_6,X_val_scaled,y_val)model_6_val_perfy_train_pred_6=model_6.predict(X_train_scaled)y_val_pred_6=model_6.predict(X_val_scaled)print(\"Classification Report - Train data Model_6\",end=\"\\n\\n\")cr_train_model_6=classification_report(y_train,y_train_pred_6>0.5)print(cr_train_model_6)print(\"Classification Report - Validation data Model_6\",end=\"\\n\\n\")cr_val_model_6=classification_report(y_val,y_val_pred_6>0.5)print(cr_val_model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad8112",
   "metadata": {},
   "source": [
    "In [22]:# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_6=Sequential()model_6.add(Dense(256,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.4))# Define the dropout ratemodel_6.add(Dense(128,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.3))# Define the dropout ratemodel_6.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.2))# Define the dropout ratemodel_6.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_6.summary()optimizer=tf.keras.optimizers.SGD()model_6.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_6.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)# Use class weightsend=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_6_train_perf=model_performance_classification(model_6,X_train_scaled,y_train)model_6_train_perfmodel_6_val_perf=model_performance_classification(model_6,X_val_scaled,y_val)model_6_val_perfy_train_pred_6=model_6.predict(X_train_scaled)y_val_pred_6=model_6.predict(X_val_scaled)print(\"Classification Report - Train data Model_6\",end=\"\\n\\n\")cr_train_model_6=classification_report(y_train,y_train_pred_6>0.5)print(cr_train_model_6)print(\"Classification Report - Validation data Model_6\",end=\"\\n\\n\")cr_val_model_6=classification_report(y_val,y_val_pred_6>0.5)print(cr_val_model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce863ab6",
   "metadata": {},
   "source": [
    "In [22]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e901fbd",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_6=Sequential()model_6.add(Dense(256,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.4))# Define the dropout ratemodel_6.add(Dense(128,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.3))# Define the dropout ratemodel_6.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.2))# Define the dropout ratemodel_6.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_6.summary()optimizer=tf.keras.optimizers.SGD()model_6.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_6.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)# Use class weightsend=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_6_train_perf=model_performance_classification(model_6,X_train_scaled,y_train)model_6_train_perfmodel_6_val_perf=model_performance_classification(model_6,X_val_scaled,y_val)model_6_val_perfy_train_pred_6=model_6.predict(X_train_scaled)y_val_pred_6=model_6.predict(X_val_scaled)print(\"Classification Report - Train data Model_6\",end=\"\\n\\n\")cr_train_model_6=classification_report(y_train,y_train_pred_6>0.5)print(cr_train_model_6)print(\"Classification Report - Validation data Model_6\",end=\"\\n\\n\")cr_val_model_6=classification_report(y_val,y_val_pred_6>0.5)print(cr_val_model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfbeb4f",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_6=Sequential()model_6.add(Dense(256,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.4))# Define the dropout ratemodel_6.add(Dense(128,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.3))# Define the dropout ratemodel_6.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.2))# Define the dropout ratemodel_6.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_6.summary()optimizer=tf.keras.optimizers.SGD()model_6.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_6.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)# Use class weightsend=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_6_train_perf=model_performance_classification(model_6,X_train_scaled,y_train)model_6_train_perfmodel_6_val_perf=model_performance_classification(model_6,X_val_scaled,y_val)model_6_val_perfy_train_pred_6=model_6.predict(X_train_scaled)y_val_pred_6=model_6.predict(X_val_scaled)print(\"Classification Report - Train data Model_6\",end=\"\\n\\n\")cr_train_model_6=classification_report(y_train,y_train_pred_6>0.5)print(cr_train_model_6)print(\"Classification Report - Validation data Model_6\",end=\"\\n\\n\")cr_val_model_6=classification_report(y_val,y_val_pred_6>0.5)print(cr_val_model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b11480f",
   "metadata": {},
   "source": [
    "# clears the current Keras session, resetting all layers and models previously created, freeing up memory and resources.tf.keras.backend.clear_session()#Initializing the neural networkmodel_6=Sequential()model_6.add(Dense(256,activation=\"relu\",input_dim=X_train_scaled.shape[1]))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.4))# Define the dropout ratemodel_6.add(Dense(128,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.3))# Define the dropout ratemodel_6.add(Dense(64,activation=\"relu\"))# Define the number of neurons and activation functionmodel_6.add(BatchNormalization())# Add batch normalizationmodel_6.add(Dropout(0.2))# Define the dropout ratemodel_6.add(Dense(1,activation=\"sigmoid\"))# Define the number of neurons in the output layermodel_6.summary()optimizer=tf.keras.optimizers.SGD()model_6.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])# Using accuracy as metricstart=time.time()history=model_6.fit(X_train_scaled,y_train,validation_data=(X_val_scaled,y_val),batch_size=batch_size,epochs=epochs,class_weight=cw_dict)# Use class weightsend=time.time()print(\"Time taken in seconds \",end-start)plot(history,'accuracy')model_6_train_perf=model_performance_classification(model_6,X_train_scaled,y_train)model_6_train_perfmodel_6_val_perf=model_performance_classification(model_6,X_val_scaled,y_val)model_6_val_perfy_train_pred_6=model_6.predict(X_train_scaled)y_val_pred_6=model_6.predict(X_val_scaled)print(\"Classification Report - Train data Model_6\",end=\"\\n\\n\")cr_train_model_6=classification_report(y_train,y_train_pred_6>0.5)print(cr_train_model_6)print(\"Classification Report - Validation data Model_6\",end=\"\\n\\n\")cr_val_model_6=classification_report(y_val,y_val_pred_6>0.5)print(cr_val_model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8bf064",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,256)            │10,496│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization             │ (None,256)            │1,024│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,256)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,128)            │32,896│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_1           │ (None,128)            │512│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_1 (Dropout)             │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_2           │ (None,64)             │256│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_2 (Dropout)             │ (None,64)             │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:53,505(209.00 KB)Trainable params:52,609(205.50 KB)Non-trainable params:896(3.50 KB)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━6s4ms/step - accuracy: 0.7158 - loss: 0.9461 - val_accuracy: 0.9625 - val_loss: 0.1618\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.8940 - loss: 0.6839 - val_accuracy: 0.9665 - val_loss: 0.1474\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9178 - loss: 0.5449 - val_accuracy: 0.9797 - val_loss: 0.1139\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9253 - loss: 0.5186 - val_accuracy: 0.9778 - val_loss: 0.1200\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9325 - loss: 0.4972 - val_accuracy: 0.9790 - val_loss: 0.1192\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━5s4ms/step - accuracy: 0.9321 - loss: 0.5197 - val_accuracy: 0.9793 - val_loss: 0.1103\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9418 - loss: 0.4187 - val_accuracy: 0.9847 - val_loss: 0.1029\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9411 - loss: 0.4764 - val_accuracy: 0.9843 - val_loss: 0.0988\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9480 - loss: 0.4261 - val_accuracy: 0.9822 - val_loss: 0.0988\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9430 - loss: 0.4862 - val_accuracy: 0.9858 - val_loss: 0.0895\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9479 - loss: 0.4496 - val_accuracy: 0.9852 - val_loss: 0.0911\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9520 - loss: 0.3957 - val_accuracy: 0.9868 - val_loss: 0.0869\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9538 - loss: 0.4452 - val_accuracy: 0.9880 - val_loss: 0.0836\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9524 - loss: 0.4243 - val_accuracy: 0.9822 - val_loss: 0.0992\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9473 - loss: 0.4242 - val_accuracy: 0.9877 - val_loss: 0.0901\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9548 - loss: 0.4259 - val_accuracy: 0.9868 - val_loss: 0.0859\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9589 - loss: 0.3675 - val_accuracy: 0.9855 - val_loss: 0.0868\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9509 - loss: 0.4003 - val_accuracy: 0.9870 - val_loss: 0.0833\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9559 - loss: 0.4316 - val_accuracy: 0.9820 - val_loss: 0.0905\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9520 - loss: 0.3845 - val_accuracy: 0.9883 - val_loss: 0.0847\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9521 - loss: 0.4062 - val_accuracy: 0.9820 - val_loss: 0.0945\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9585 - loss: 0.3839 - val_accuracy: 0.9870 - val_loss: 0.0847\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9594 - loss: 0.3922 - val_accuracy: 0.9860 - val_loss: 0.0809\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9571 - loss: 0.3781 - val_accuracy: 0.9890 - val_loss: 0.0843\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━5s4ms/step - accuracy: 0.9615 - loss: 0.3715 - val_accuracy: 0.9852 - val_loss: 0.0862\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9559 - loss: 0.4103 - val_accuracy: 0.9855 - val_loss: 0.0836\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9599 - loss: 0.3325 - val_accuracy: 0.9855 - val_loss: 0.0794\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9584 - loss: 0.4122 - val_accuracy: 0.9860 - val_loss: 0.0804\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9601 - loss: 0.3285 - val_accuracy: 0.9872 - val_loss: 0.0806\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9593 - loss: 0.3667 - val_accuracy: 0.9885 - val_loss: 0.0762\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9658 - loss: 0.3206 - val_accuracy: 0.9880 - val_loss: 0.0787\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9597 - loss: 0.3852 - val_accuracy: 0.9868 - val_loss: 0.0783\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9614 - loss: 0.4023 - val_accuracy: 0.9860 - val_loss: 0.0838\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9610 - loss: 0.3827 - val_accuracy: 0.9862 - val_loss: 0.0802\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9600 - loss: 0.3044 - val_accuracy: 0.9880 - val_loss: 0.0794\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9622 - loss: 0.3360 - val_accuracy: 0.9875 - val_loss: 0.0820\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9612 - loss: 0.3493 - val_accuracy: 0.9865 - val_loss: 0.0751\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9645 - loss: 0.3500 - val_accuracy: 0.9868 - val_loss: 0.0830\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9655 - loss: 0.3240 - val_accuracy: 0.9862 - val_loss: 0.0813\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9596 - loss: 0.3863 - val_accuracy: 0.9875 - val_loss: 0.0830\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9636 - loss: 0.3644 - val_accuracy: 0.9825 - val_loss: 0.0914\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9635 - loss: 0.3555 - val_accuracy: 0.9877 - val_loss: 0.0737\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9682 - loss: 0.3047 - val_accuracy: 0.9872 - val_loss: 0.0802\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9649 - loss: 0.3235 - val_accuracy: 0.9843 - val_loss: 0.0910\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9645 - loss: 0.3094 - val_accuracy: 0.9845 - val_loss: 0.0884\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9637 - loss: 0.3590 - val_accuracy: 0.9872 - val_loss: 0.0815\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9661 - loss: 0.3024 - val_accuracy: 0.9837 - val_loss: 0.0860\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9644 - loss: 0.3194 - val_accuracy: 0.9852 - val_loss: 0.0821\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s7ms/step - accuracy: 0.9621 - loss: 0.3719 - val_accuracy: 0.9845 - val_loss: 0.0886\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9580 - loss: 0.3949 - val_accuracy: 0.9855 - val_loss: 0.0799\n",
    "Time taken in seconds  144.15532851219177500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_6\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     15112\n",
    "         1.0       0.86      0.93      0.89       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.93      0.96      0.94     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_6\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99      3778\n",
    "         1.0       0.84      0.92      0.88       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.92      0.95      0.93      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d9e24",
   "metadata": {},
   "source": [
    "Model: \"sequential\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,256)            │10,496│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization             │ (None,256)            │1,024│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,256)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,128)            │32,896│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_1           │ (None,128)            │512│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_1 (Dropout)             │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_2           │ (None,64)             │256│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_2 (Dropout)             │ (None,64)             │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘Total params:53,505(209.00 KB)Trainable params:52,609(205.50 KB)Non-trainable params:896(3.50 KB)Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━6s4ms/step - accuracy: 0.7158 - loss: 0.9461 - val_accuracy: 0.9625 - val_loss: 0.1618\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.8940 - loss: 0.6839 - val_accuracy: 0.9665 - val_loss: 0.1474\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9178 - loss: 0.5449 - val_accuracy: 0.9797 - val_loss: 0.1139\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9253 - loss: 0.5186 - val_accuracy: 0.9778 - val_loss: 0.1200\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9325 - loss: 0.4972 - val_accuracy: 0.9790 - val_loss: 0.1192\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━5s4ms/step - accuracy: 0.9321 - loss: 0.5197 - val_accuracy: 0.9793 - val_loss: 0.1103\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9418 - loss: 0.4187 - val_accuracy: 0.9847 - val_loss: 0.1029\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9411 - loss: 0.4764 - val_accuracy: 0.9843 - val_loss: 0.0988\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9480 - loss: 0.4261 - val_accuracy: 0.9822 - val_loss: 0.0988\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9430 - loss: 0.4862 - val_accuracy: 0.9858 - val_loss: 0.0895\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9479 - loss: 0.4496 - val_accuracy: 0.9852 - val_loss: 0.0911\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9520 - loss: 0.3957 - val_accuracy: 0.9868 - val_loss: 0.0869\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9538 - loss: 0.4452 - val_accuracy: 0.9880 - val_loss: 0.0836\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9524 - loss: 0.4243 - val_accuracy: 0.9822 - val_loss: 0.0992\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9473 - loss: 0.4242 - val_accuracy: 0.9877 - val_loss: 0.0901\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9548 - loss: 0.4259 - val_accuracy: 0.9868 - val_loss: 0.0859\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9589 - loss: 0.3675 - val_accuracy: 0.9855 - val_loss: 0.0868\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9509 - loss: 0.4003 - val_accuracy: 0.9870 - val_loss: 0.0833\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9559 - loss: 0.4316 - val_accuracy: 0.9820 - val_loss: 0.0905\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9520 - loss: 0.3845 - val_accuracy: 0.9883 - val_loss: 0.0847\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9521 - loss: 0.4062 - val_accuracy: 0.9820 - val_loss: 0.0945\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9585 - loss: 0.3839 - val_accuracy: 0.9870 - val_loss: 0.0847\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9594 - loss: 0.3922 - val_accuracy: 0.9860 - val_loss: 0.0809\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9571 - loss: 0.3781 - val_accuracy: 0.9890 - val_loss: 0.0843\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━5s4ms/step - accuracy: 0.9615 - loss: 0.3715 - val_accuracy: 0.9852 - val_loss: 0.0862\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9559 - loss: 0.4103 - val_accuracy: 0.9855 - val_loss: 0.0836\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9599 - loss: 0.3325 - val_accuracy: 0.9855 - val_loss: 0.0794\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9584 - loss: 0.4122 - val_accuracy: 0.9860 - val_loss: 0.0804\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9601 - loss: 0.3285 - val_accuracy: 0.9872 - val_loss: 0.0806\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9593 - loss: 0.3667 - val_accuracy: 0.9885 - val_loss: 0.0762\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9658 - loss: 0.3206 - val_accuracy: 0.9880 - val_loss: 0.0787\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9597 - loss: 0.3852 - val_accuracy: 0.9868 - val_loss: 0.0783\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9614 - loss: 0.4023 - val_accuracy: 0.9860 - val_loss: 0.0838\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9610 - loss: 0.3827 - val_accuracy: 0.9862 - val_loss: 0.0802\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9600 - loss: 0.3044 - val_accuracy: 0.9880 - val_loss: 0.0794\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9622 - loss: 0.3360 - val_accuracy: 0.9875 - val_loss: 0.0820\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9612 - loss: 0.3493 - val_accuracy: 0.9865 - val_loss: 0.0751\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9645 - loss: 0.3500 - val_accuracy: 0.9868 - val_loss: 0.0830\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9655 - loss: 0.3240 - val_accuracy: 0.9862 - val_loss: 0.0813\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9596 - loss: 0.3863 - val_accuracy: 0.9875 - val_loss: 0.0830\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9636 - loss: 0.3644 - val_accuracy: 0.9825 - val_loss: 0.0914\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9635 - loss: 0.3555 - val_accuracy: 0.9877 - val_loss: 0.0737\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9682 - loss: 0.3047 - val_accuracy: 0.9872 - val_loss: 0.0802\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9649 - loss: 0.3235 - val_accuracy: 0.9843 - val_loss: 0.0910\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9645 - loss: 0.3094 - val_accuracy: 0.9845 - val_loss: 0.0884\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9637 - loss: 0.3590 - val_accuracy: 0.9872 - val_loss: 0.0815\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9661 - loss: 0.3024 - val_accuracy: 0.9837 - val_loss: 0.0860\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9644 - loss: 0.3194 - val_accuracy: 0.9852 - val_loss: 0.0821\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s7ms/step - accuracy: 0.9621 - loss: 0.3719 - val_accuracy: 0.9845 - val_loss: 0.0886\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9580 - loss: 0.3949 - val_accuracy: 0.9855 - val_loss: 0.0799\n",
    "Time taken in seconds  144.15532851219177500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_6\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     15112\n",
    "         1.0       0.86      0.93      0.89       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.93      0.96      0.94     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_6\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99      3778\n",
    "         1.0       0.84      0.92      0.88       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.92      0.95      0.93      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72b679",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcbc971",
   "metadata": {},
   "source": [
    "Model: \"sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba4c9ae",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,256)            │10,496│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization             │ (None,256)            │1,024│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,256)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,128)            │32,896│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_1           │ (None,128)            │512│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_1 (Dropout)             │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_2           │ (None,64)             │256│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_2 (Dropout)             │ (None,64)             │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb2c38",
   "metadata": {},
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃Layer (type)┃Output Shape┃Param #┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None,256)            │10,496│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization             │ (None,256)            │1,024│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None,256)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None,128)            │32,896│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_1           │ (None,128)            │512│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_1 (Dropout)             │ (None,128)            │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None,64)             │8,256│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ batch_normalization_2           │ (None,64)             │256│\n",
    "│ (BatchNormalization)            │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout_2 (Dropout)             │ (None,64)             │0│\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_3 (Dense)                 │ (None,1)              │65│\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ffd22",
   "metadata": {},
   "source": [
    "Total params:53,505(209.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fbf18",
   "metadata": {},
   "source": [
    "Total params:53,505(209.00 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbda4d7",
   "metadata": {},
   "source": [
    "Trainable params:52,609(205.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf412bc",
   "metadata": {},
   "source": [
    "Trainable params:52,609(205.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ce5ac",
   "metadata": {},
   "source": [
    "Non-trainable params:896(3.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4cf331",
   "metadata": {},
   "source": [
    "Non-trainable params:896(3.50 KB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7dcad5",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━6s4ms/step - accuracy: 0.7158 - loss: 0.9461 - val_accuracy: 0.9625 - val_loss: 0.1618\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.8940 - loss: 0.6839 - val_accuracy: 0.9665 - val_loss: 0.1474\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9178 - loss: 0.5449 - val_accuracy: 0.9797 - val_loss: 0.1139\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9253 - loss: 0.5186 - val_accuracy: 0.9778 - val_loss: 0.1200\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9325 - loss: 0.4972 - val_accuracy: 0.9790 - val_loss: 0.1192\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━5s4ms/step - accuracy: 0.9321 - loss: 0.5197 - val_accuracy: 0.9793 - val_loss: 0.1103\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9418 - loss: 0.4187 - val_accuracy: 0.9847 - val_loss: 0.1029\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9411 - loss: 0.4764 - val_accuracy: 0.9843 - val_loss: 0.0988\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9480 - loss: 0.4261 - val_accuracy: 0.9822 - val_loss: 0.0988\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9430 - loss: 0.4862 - val_accuracy: 0.9858 - val_loss: 0.0895\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9479 - loss: 0.4496 - val_accuracy: 0.9852 - val_loss: 0.0911\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9520 - loss: 0.3957 - val_accuracy: 0.9868 - val_loss: 0.0869\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9538 - loss: 0.4452 - val_accuracy: 0.9880 - val_loss: 0.0836\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9524 - loss: 0.4243 - val_accuracy: 0.9822 - val_loss: 0.0992\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9473 - loss: 0.4242 - val_accuracy: 0.9877 - val_loss: 0.0901\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9548 - loss: 0.4259 - val_accuracy: 0.9868 - val_loss: 0.0859\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9589 - loss: 0.3675 - val_accuracy: 0.9855 - val_loss: 0.0868\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9509 - loss: 0.4003 - val_accuracy: 0.9870 - val_loss: 0.0833\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9559 - loss: 0.4316 - val_accuracy: 0.9820 - val_loss: 0.0905\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9520 - loss: 0.3845 - val_accuracy: 0.9883 - val_loss: 0.0847\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9521 - loss: 0.4062 - val_accuracy: 0.9820 - val_loss: 0.0945\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9585 - loss: 0.3839 - val_accuracy: 0.9870 - val_loss: 0.0847\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9594 - loss: 0.3922 - val_accuracy: 0.9860 - val_loss: 0.0809\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9571 - loss: 0.3781 - val_accuracy: 0.9890 - val_loss: 0.0843\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━5s4ms/step - accuracy: 0.9615 - loss: 0.3715 - val_accuracy: 0.9852 - val_loss: 0.0862\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9559 - loss: 0.4103 - val_accuracy: 0.9855 - val_loss: 0.0836\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9599 - loss: 0.3325 - val_accuracy: 0.9855 - val_loss: 0.0794\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9584 - loss: 0.4122 - val_accuracy: 0.9860 - val_loss: 0.0804\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9601 - loss: 0.3285 - val_accuracy: 0.9872 - val_loss: 0.0806\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9593 - loss: 0.3667 - val_accuracy: 0.9885 - val_loss: 0.0762\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9658 - loss: 0.3206 - val_accuracy: 0.9880 - val_loss: 0.0787\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9597 - loss: 0.3852 - val_accuracy: 0.9868 - val_loss: 0.0783\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9614 - loss: 0.4023 - val_accuracy: 0.9860 - val_loss: 0.0838\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9610 - loss: 0.3827 - val_accuracy: 0.9862 - val_loss: 0.0802\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9600 - loss: 0.3044 - val_accuracy: 0.9880 - val_loss: 0.0794\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9622 - loss: 0.3360 - val_accuracy: 0.9875 - val_loss: 0.0820\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9612 - loss: 0.3493 - val_accuracy: 0.9865 - val_loss: 0.0751\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9645 - loss: 0.3500 - val_accuracy: 0.9868 - val_loss: 0.0830\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9655 - loss: 0.3240 - val_accuracy: 0.9862 - val_loss: 0.0813\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9596 - loss: 0.3863 - val_accuracy: 0.9875 - val_loss: 0.0830\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9636 - loss: 0.3644 - val_accuracy: 0.9825 - val_loss: 0.0914\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9635 - loss: 0.3555 - val_accuracy: 0.9877 - val_loss: 0.0737\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9682 - loss: 0.3047 - val_accuracy: 0.9872 - val_loss: 0.0802\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9649 - loss: 0.3235 - val_accuracy: 0.9843 - val_loss: 0.0910\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9645 - loss: 0.3094 - val_accuracy: 0.9845 - val_loss: 0.0884\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9637 - loss: 0.3590 - val_accuracy: 0.9872 - val_loss: 0.0815\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9661 - loss: 0.3024 - val_accuracy: 0.9837 - val_loss: 0.0860\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9644 - loss: 0.3194 - val_accuracy: 0.9852 - val_loss: 0.0821\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s7ms/step - accuracy: 0.9621 - loss: 0.3719 - val_accuracy: 0.9845 - val_loss: 0.0886\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9580 - loss: 0.3949 - val_accuracy: 0.9855 - val_loss: 0.0799\n",
    "Time taken in seconds  144.15532851219177"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c28d8c",
   "metadata": {},
   "source": [
    "Epoch 1/50500/500━━━━━━━━━━━━━━━━━━━━6s4ms/step - accuracy: 0.7158 - loss: 0.9461 - val_accuracy: 0.9625 - val_loss: 0.1618\n",
    "Epoch 2/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.8940 - loss: 0.6839 - val_accuracy: 0.9665 - val_loss: 0.1474\n",
    "Epoch 3/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9178 - loss: 0.5449 - val_accuracy: 0.9797 - val_loss: 0.1139\n",
    "Epoch 4/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9253 - loss: 0.5186 - val_accuracy: 0.9778 - val_loss: 0.1200\n",
    "Epoch 5/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9325 - loss: 0.4972 - val_accuracy: 0.9790 - val_loss: 0.1192\n",
    "Epoch 6/50500/500━━━━━━━━━━━━━━━━━━━━5s4ms/step - accuracy: 0.9321 - loss: 0.5197 - val_accuracy: 0.9793 - val_loss: 0.1103\n",
    "Epoch 7/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9418 - loss: 0.4187 - val_accuracy: 0.9847 - val_loss: 0.1029\n",
    "Epoch 8/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9411 - loss: 0.4764 - val_accuracy: 0.9843 - val_loss: 0.0988\n",
    "Epoch 9/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9480 - loss: 0.4261 - val_accuracy: 0.9822 - val_loss: 0.0988\n",
    "Epoch 10/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9430 - loss: 0.4862 - val_accuracy: 0.9858 - val_loss: 0.0895\n",
    "Epoch 11/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9479 - loss: 0.4496 - val_accuracy: 0.9852 - val_loss: 0.0911\n",
    "Epoch 12/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9520 - loss: 0.3957 - val_accuracy: 0.9868 - val_loss: 0.0869\n",
    "Epoch 13/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9538 - loss: 0.4452 - val_accuracy: 0.9880 - val_loss: 0.0836\n",
    "Epoch 14/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9524 - loss: 0.4243 - val_accuracy: 0.9822 - val_loss: 0.0992\n",
    "Epoch 15/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9473 - loss: 0.4242 - val_accuracy: 0.9877 - val_loss: 0.0901\n",
    "Epoch 16/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9548 - loss: 0.4259 - val_accuracy: 0.9868 - val_loss: 0.0859\n",
    "Epoch 17/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9589 - loss: 0.3675 - val_accuracy: 0.9855 - val_loss: 0.0868\n",
    "Epoch 18/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9509 - loss: 0.4003 - val_accuracy: 0.9870 - val_loss: 0.0833\n",
    "Epoch 19/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9559 - loss: 0.4316 - val_accuracy: 0.9820 - val_loss: 0.0905\n",
    "Epoch 20/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9520 - loss: 0.3845 - val_accuracy: 0.9883 - val_loss: 0.0847\n",
    "Epoch 21/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9521 - loss: 0.4062 - val_accuracy: 0.9820 - val_loss: 0.0945\n",
    "Epoch 22/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9585 - loss: 0.3839 - val_accuracy: 0.9870 - val_loss: 0.0847\n",
    "Epoch 23/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9594 - loss: 0.3922 - val_accuracy: 0.9860 - val_loss: 0.0809\n",
    "Epoch 24/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9571 - loss: 0.3781 - val_accuracy: 0.9890 - val_loss: 0.0843\n",
    "Epoch 25/50500/500━━━━━━━━━━━━━━━━━━━━5s4ms/step - accuracy: 0.9615 - loss: 0.3715 - val_accuracy: 0.9852 - val_loss: 0.0862\n",
    "Epoch 26/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9559 - loss: 0.4103 - val_accuracy: 0.9855 - val_loss: 0.0836\n",
    "Epoch 27/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9599 - loss: 0.3325 - val_accuracy: 0.9855 - val_loss: 0.0794\n",
    "Epoch 28/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9584 - loss: 0.4122 - val_accuracy: 0.9860 - val_loss: 0.0804\n",
    "Epoch 29/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9601 - loss: 0.3285 - val_accuracy: 0.9872 - val_loss: 0.0806\n",
    "Epoch 30/50500/500━━━━━━━━━━━━━━━━━━━━2s5ms/step - accuracy: 0.9593 - loss: 0.3667 - val_accuracy: 0.9885 - val_loss: 0.0762\n",
    "Epoch 31/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9658 - loss: 0.3206 - val_accuracy: 0.9880 - val_loss: 0.0787\n",
    "Epoch 32/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9597 - loss: 0.3852 - val_accuracy: 0.9868 - val_loss: 0.0783\n",
    "Epoch 33/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9614 - loss: 0.4023 - val_accuracy: 0.9860 - val_loss: 0.0838\n",
    "Epoch 34/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9610 - loss: 0.3827 - val_accuracy: 0.9862 - val_loss: 0.0802\n",
    "Epoch 35/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9600 - loss: 0.3044 - val_accuracy: 0.9880 - val_loss: 0.0794\n",
    "Epoch 36/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9622 - loss: 0.3360 - val_accuracy: 0.9875 - val_loss: 0.0820\n",
    "Epoch 37/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9612 - loss: 0.3493 - val_accuracy: 0.9865 - val_loss: 0.0751\n",
    "Epoch 38/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9645 - loss: 0.3500 - val_accuracy: 0.9868 - val_loss: 0.0830\n",
    "Epoch 39/50500/500━━━━━━━━━━━━━━━━━━━━4s7ms/step - accuracy: 0.9655 - loss: 0.3240 - val_accuracy: 0.9862 - val_loss: 0.0813\n",
    "Epoch 40/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9596 - loss: 0.3863 - val_accuracy: 0.9875 - val_loss: 0.0830\n",
    "Epoch 41/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9636 - loss: 0.3644 - val_accuracy: 0.9825 - val_loss: 0.0914\n",
    "Epoch 42/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9635 - loss: 0.3555 - val_accuracy: 0.9877 - val_loss: 0.0737\n",
    "Epoch 43/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9682 - loss: 0.3047 - val_accuracy: 0.9872 - val_loss: 0.0802\n",
    "Epoch 44/50500/500━━━━━━━━━━━━━━━━━━━━3s6ms/step - accuracy: 0.9649 - loss: 0.3235 - val_accuracy: 0.9843 - val_loss: 0.0910\n",
    "Epoch 45/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9645 - loss: 0.3094 - val_accuracy: 0.9845 - val_loss: 0.0884\n",
    "Epoch 46/50500/500━━━━━━━━━━━━━━━━━━━━2s4ms/step - accuracy: 0.9637 - loss: 0.3590 - val_accuracy: 0.9872 - val_loss: 0.0815\n",
    "Epoch 47/50500/500━━━━━━━━━━━━━━━━━━━━3s4ms/step - accuracy: 0.9661 - loss: 0.3024 - val_accuracy: 0.9837 - val_loss: 0.0860\n",
    "Epoch 48/50500/500━━━━━━━━━━━━━━━━━━━━3s5ms/step - accuracy: 0.9644 - loss: 0.3194 - val_accuracy: 0.9852 - val_loss: 0.0821\n",
    "Epoch 49/50500/500━━━━━━━━━━━━━━━━━━━━3s7ms/step - accuracy: 0.9621 - loss: 0.3719 - val_accuracy: 0.9845 - val_loss: 0.0886\n",
    "Epoch 50/50500/500━━━━━━━━━━━━━━━━━━━━4s4ms/step - accuracy: 0.9580 - loss: 0.3949 - val_accuracy: 0.9855 - val_loss: 0.0799\n",
    "Time taken in seconds  144.15532851219177"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc16b33",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_6\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     15112\n",
    "         1.0       0.86      0.93      0.89       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.93      0.96      0.94     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_6\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99      3778\n",
    "         1.0       0.84      0.92      0.88       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.92      0.95      0.93      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a018684",
   "metadata": {},
   "source": [
    "500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step500/500━━━━━━━━━━━━━━━━━━━━1s2ms/step125/125━━━━━━━━━━━━━━━━━━━━0s2ms/step\n",
    "Classification Report - Train data Model_6\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99     15112\n",
    "         1.0       0.86      0.93      0.89       888\n",
    "\n",
    "    accuracy                           0.99     16000\n",
    "   macro avg       0.93      0.96      0.94     16000\n",
    "weighted avg       0.99      0.99      0.99     16000\n",
    "\n",
    "Classification Report - Validation data Model_6\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      0.99      3778\n",
    "         1.0       0.84      0.92      0.88       222\n",
    "\n",
    "    accuracy                           0.99      4000\n",
    "   macro avg       0.92      0.95      0.93      4000\n",
    "weighted avg       0.99      0.99      0.99      4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc74712",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Complex Architecture:Deep network with multiple layers (256 → 128 → 64 → 1)Multiple batch normalization layersProgressive dropout rates (40% → 30% → 20%)Best Performance:Highest F1-score among all modelsBest balance of precision and recallExcellent generalization to validation dataTraining Characteristics:Longest training time due to complex architectureMost stable training processBest convergence patternsOverfitting Control:Excellent overfitting control through multiple techniquesSmall gap between training and validation performanceRobust model that generalizes wellBusiness Alignment:Best balance of precision and recall for business requirementsOptimal detection of failures while minimizing false alarmsMost suitable model for production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b428364",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Complex Architecture:Deep network with multiple layers (256 → 128 → 64 → 1)Multiple batch normalization layersProgressive dropout rates (40% → 30% → 20%)Best Performance:Highest F1-score among all modelsBest balance of precision and recallExcellent generalization to validation dataTraining Characteristics:Longest training time due to complex architectureMost stable training processBest convergence patternsOverfitting Control:Excellent overfitting control through multiple techniquesSmall gap between training and validation performanceRobust model that generalizes wellBusiness Alignment:Best balance of precision and recall for business requirementsOptimal detection of failures while minimizing false alarmsMost suitable model for production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448d43f1",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Complex Architecture:Deep network with multiple layers (256 → 128 → 64 → 1)Multiple batch normalization layersProgressive dropout rates (40% → 30% → 20%)Best Performance:Highest F1-score among all modelsBest balance of precision and recallExcellent generalization to validation dataTraining Characteristics:Longest training time due to complex architectureMost stable training processBest convergence patternsOverfitting Control:Excellent overfitting control through multiple techniquesSmall gap between training and validation performanceRobust model that generalizes wellBusiness Alignment:Best balance of precision and recall for business requirementsOptimal detection of failures while minimizing false alarmsMost suitable model for production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820ee4c",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Complex Architecture:Deep network with multiple layers (256 → 128 → 64 → 1)Multiple batch normalization layersProgressive dropout rates (40% → 30% → 20%)Best Performance:Highest F1-score among all modelsBest balance of precision and recallExcellent generalization to validation dataTraining Characteristics:Longest training time due to complex architectureMost stable training processBest convergence patternsOverfitting Control:Excellent overfitting control through multiple techniquesSmall gap between training and validation performanceRobust model that generalizes wellBusiness Alignment:Best balance of precision and recall for business requirementsOptimal detection of failures while minimizing false alarmsMost suitable model for production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6f81e",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d558ba",
   "metadata": {},
   "source": [
    "Complex Architecture:Deep network with multiple layers (256 → 128 → 64 → 1)Multiple batch normalization layersProgressive dropout rates (40% → 30% → 20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8675e36f",
   "metadata": {},
   "source": [
    "Complex Architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e195804",
   "metadata": {},
   "source": [
    "Deep network with multiple layers (256 → 128 → 64 → 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3450a4e",
   "metadata": {},
   "source": [
    "Multiple batch normalization layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d11f90",
   "metadata": {},
   "source": [
    "Progressive dropout rates (40% → 30% → 20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d076faf8",
   "metadata": {},
   "source": [
    "Best Performance:Highest F1-score among all modelsBest balance of precision and recallExcellent generalization to validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6272f41",
   "metadata": {},
   "source": [
    "Best Performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965350a6",
   "metadata": {},
   "source": [
    "Highest F1-score among all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e942139f",
   "metadata": {},
   "source": [
    "Best balance of precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c6346",
   "metadata": {},
   "source": [
    "Excellent generalization to validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230177de",
   "metadata": {},
   "source": [
    "Training Characteristics:Longest training time due to complex architectureMost stable training processBest convergence patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee66f97",
   "metadata": {},
   "source": [
    "Training Characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52fa4ec",
   "metadata": {},
   "source": [
    "Longest training time due to complex architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd81992",
   "metadata": {},
   "source": [
    "Most stable training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b722e8c",
   "metadata": {},
   "source": [
    "Best convergence patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a377c5a",
   "metadata": {},
   "source": [
    "Overfitting Control:Excellent overfitting control through multiple techniquesSmall gap between training and validation performanceRobust model that generalizes well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfdcf4a",
   "metadata": {},
   "source": [
    "Overfitting Control:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e03bc",
   "metadata": {},
   "source": [
    "Excellent overfitting control through multiple techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ca42f",
   "metadata": {},
   "source": [
    "Small gap between training and validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1455a",
   "metadata": {},
   "source": [
    "Robust model that generalizes well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb45c7b",
   "metadata": {},
   "source": [
    "Business Alignment:Best balance of precision and recall for business requirementsOptimal detection of failures while minimizing false alarmsMost suitable model for production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd30cb",
   "metadata": {},
   "source": [
    "Business Alignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24200af6",
   "metadata": {},
   "source": [
    "Best balance of precision and recall for business requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b72a2",
   "metadata": {},
   "source": [
    "Optimal detection of failures while minimizing false alarms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dee006",
   "metadata": {},
   "source": [
    "Most suitable model for production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985aa11",
   "metadata": {},
   "source": [
    "Model Performance Comparison and Final Model Selection¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e3123",
   "metadata": {},
   "source": [
    "Model Performance Comparison and Final Model Selection¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55728b29",
   "metadata": {},
   "source": [
    "Model Performance Comparison and Final Model Selection¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78955bf",
   "metadata": {},
   "source": [
    "Model Performance Comparison and Final Model Selection¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981f3a17",
   "metadata": {},
   "source": [
    "Model Performance Comparison and Final Model Selection¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75dd3bc",
   "metadata": {},
   "source": [
    "Now, in order to select the final model, we will compare the performances of all the models for the training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0004ee9",
   "metadata": {},
   "source": [
    "Now, in order to select the final model, we will compare the performances of all the models for the training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde3121",
   "metadata": {},
   "source": [
    "Now, in order to select the final model, we will compare the performances of all the models for the training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37c980",
   "metadata": {},
   "source": [
    "Now, in order to select the final model, we will compare the performances of all the models for the training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c587fd",
   "metadata": {},
   "source": [
    "Now, in order to select the final model, we will compare the performances of all the models for the training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5118b9f",
   "metadata": {},
   "source": [
    "In [23]:# Training performance comparisonmodels_train_comp_df=pd.concat([model_0_train_perf.T,model_1_train_perf.T,model_2_train_perf.T,model_3_train_perf.T,model_4_train_perf.T,model_5_train_perf.T,model_6_train_perf.T],axis=1,)models_train_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"Training set performance comparison:\")print(models_train_comp_df)# Validation performance comparisonmodels_val_comp_df=pd.concat([model_0_val_perf.T,model_1_val_perf.T,model_2_val_perf.T,model_3_val_perf.T,model_4_val_perf.T,model_5_val_perf.T,model_6_val_perf.T],axis=1,)models_val_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"\\nValidation set performance comparison:\")print(models_val_comp_df)# Find best model based on validation F1-Scorebest_model_idx=models_val_comp_df.loc['F1-Score'].idxmax()best_model_name=best_model_idxifbest_model_name==\"Model 0\":best_model=model_0elifbest_model_name==\"Model 1\":best_model=model_1elifbest_model_name==\"Model 2\":best_model=model_2elifbest_model_name==\"Model 3\":best_model=model_3elifbest_model_name==\"Model 4\":best_model=model_4elifbest_model_name==\"Model 5\":best_model=model_5else:best_model=model_6print(f\"\\nBest Model:{best_model_name}\")print(f\"Best Validation F1-Score:{models_val_comp_df.loc['F1-Score',best_model_name]:.4f}\")Training set performance comparison:\n",
    "            Model 0   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
    "Accuracy   0.989187  0.991938  0.990875  0.988000  0.997437  0.994188   \n",
    "Precision  0.983762  0.989677  0.989446  0.855828  0.988466  0.995019   \n",
    "Recall     0.818694  0.863739  0.844595  0.942568  0.965090  0.899775   \n",
    "F1-Score   0.893669  0.922429  0.911300  0.897106  0.976638  0.945003   \n",
    "\n",
    "            Model 6  \n",
    "Accuracy   0.987437  \n",
    "Precision  0.858934  \n",
    "Recall     0.925676  \n",
    "F1-Score   0.891057  \n",
    "\n",
    "Validation set performance comparison:\n",
    "            Model 0   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
    "Accuracy   0.989750  0.992250  0.992500  0.982750  0.990750  0.994500   \n",
    "Precision  0.983957  0.975124  0.989796  0.800000  0.930233  0.985437   \n",
    "Recall     0.828829  0.882883  0.873874  0.918919  0.900901  0.914414   \n",
    "F1-Score   0.899756  0.926714  0.928230  0.855346  0.915332  0.948598   \n",
    "\n",
    "            Model 6  \n",
    "Accuracy   0.985500  \n",
    "Precision  0.836066  \n",
    "Recall     0.918919  \n",
    "F1-Score   0.875536  \n",
    "\n",
    "Best Model: Model 5\n",
    "Best Validation F1-Score: 0.9486"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffd5c6c",
   "metadata": {},
   "source": [
    "In [23]:# Training performance comparisonmodels_train_comp_df=pd.concat([model_0_train_perf.T,model_1_train_perf.T,model_2_train_perf.T,model_3_train_perf.T,model_4_train_perf.T,model_5_train_perf.T,model_6_train_perf.T],axis=1,)models_train_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"Training set performance comparison:\")print(models_train_comp_df)# Validation performance comparisonmodels_val_comp_df=pd.concat([model_0_val_perf.T,model_1_val_perf.T,model_2_val_perf.T,model_3_val_perf.T,model_4_val_perf.T,model_5_val_perf.T,model_6_val_perf.T],axis=1,)models_val_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"\\nValidation set performance comparison:\")print(models_val_comp_df)# Find best model based on validation F1-Scorebest_model_idx=models_val_comp_df.loc['F1-Score'].idxmax()best_model_name=best_model_idxifbest_model_name==\"Model 0\":best_model=model_0elifbest_model_name==\"Model 1\":best_model=model_1elifbest_model_name==\"Model 2\":best_model=model_2elifbest_model_name==\"Model 3\":best_model=model_3elifbest_model_name==\"Model 4\":best_model=model_4elifbest_model_name==\"Model 5\":best_model=model_5else:best_model=model_6print(f\"\\nBest Model:{best_model_name}\")print(f\"Best Validation F1-Score:{models_val_comp_df.loc['F1-Score',best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c3ff5",
   "metadata": {},
   "source": [
    "In [23]:# Training performance comparisonmodels_train_comp_df=pd.concat([model_0_train_perf.T,model_1_train_perf.T,model_2_train_perf.T,model_3_train_perf.T,model_4_train_perf.T,model_5_train_perf.T,model_6_train_perf.T],axis=1,)models_train_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"Training set performance comparison:\")print(models_train_comp_df)# Validation performance comparisonmodels_val_comp_df=pd.concat([model_0_val_perf.T,model_1_val_perf.T,model_2_val_perf.T,model_3_val_perf.T,model_4_val_perf.T,model_5_val_perf.T,model_6_val_perf.T],axis=1,)models_val_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"\\nValidation set performance comparison:\")print(models_val_comp_df)# Find best model based on validation F1-Scorebest_model_idx=models_val_comp_df.loc['F1-Score'].idxmax()best_model_name=best_model_idxifbest_model_name==\"Model 0\":best_model=model_0elifbest_model_name==\"Model 1\":best_model=model_1elifbest_model_name==\"Model 2\":best_model=model_2elifbest_model_name==\"Model 3\":best_model=model_3elifbest_model_name==\"Model 4\":best_model=model_4elifbest_model_name==\"Model 5\":best_model=model_5else:best_model=model_6print(f\"\\nBest Model:{best_model_name}\")print(f\"Best Validation F1-Score:{models_val_comp_df.loc['F1-Score',best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c290e5d",
   "metadata": {},
   "source": [
    "In [23]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462d400",
   "metadata": {},
   "source": [
    "# Training performance comparisonmodels_train_comp_df=pd.concat([model_0_train_perf.T,model_1_train_perf.T,model_2_train_perf.T,model_3_train_perf.T,model_4_train_perf.T,model_5_train_perf.T,model_6_train_perf.T],axis=1,)models_train_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"Training set performance comparison:\")print(models_train_comp_df)# Validation performance comparisonmodels_val_comp_df=pd.concat([model_0_val_perf.T,model_1_val_perf.T,model_2_val_perf.T,model_3_val_perf.T,model_4_val_perf.T,model_5_val_perf.T,model_6_val_perf.T],axis=1,)models_val_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"\\nValidation set performance comparison:\")print(models_val_comp_df)# Find best model based on validation F1-Scorebest_model_idx=models_val_comp_df.loc['F1-Score'].idxmax()best_model_name=best_model_idxifbest_model_name==\"Model 0\":best_model=model_0elifbest_model_name==\"Model 1\":best_model=model_1elifbest_model_name==\"Model 2\":best_model=model_2elifbest_model_name==\"Model 3\":best_model=model_3elifbest_model_name==\"Model 4\":best_model=model_4elifbest_model_name==\"Model 5\":best_model=model_5else:best_model=model_6print(f\"\\nBest Model:{best_model_name}\")print(f\"Best Validation F1-Score:{models_val_comp_df.loc['F1-Score',best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b4977",
   "metadata": {},
   "source": [
    "# Training performance comparisonmodels_train_comp_df=pd.concat([model_0_train_perf.T,model_1_train_perf.T,model_2_train_perf.T,model_3_train_perf.T,model_4_train_perf.T,model_5_train_perf.T,model_6_train_perf.T],axis=1,)models_train_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"Training set performance comparison:\")print(models_train_comp_df)# Validation performance comparisonmodels_val_comp_df=pd.concat([model_0_val_perf.T,model_1_val_perf.T,model_2_val_perf.T,model_3_val_perf.T,model_4_val_perf.T,model_5_val_perf.T,model_6_val_perf.T],axis=1,)models_val_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"\\nValidation set performance comparison:\")print(models_val_comp_df)# Find best model based on validation F1-Scorebest_model_idx=models_val_comp_df.loc['F1-Score'].idxmax()best_model_name=best_model_idxifbest_model_name==\"Model 0\":best_model=model_0elifbest_model_name==\"Model 1\":best_model=model_1elifbest_model_name==\"Model 2\":best_model=model_2elifbest_model_name==\"Model 3\":best_model=model_3elifbest_model_name==\"Model 4\":best_model=model_4elifbest_model_name==\"Model 5\":best_model=model_5else:best_model=model_6print(f\"\\nBest Model:{best_model_name}\")print(f\"Best Validation F1-Score:{models_val_comp_df.loc['F1-Score',best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d4f9a4",
   "metadata": {},
   "source": [
    "# Training performance comparisonmodels_train_comp_df=pd.concat([model_0_train_perf.T,model_1_train_perf.T,model_2_train_perf.T,model_3_train_perf.T,model_4_train_perf.T,model_5_train_perf.T,model_6_train_perf.T],axis=1,)models_train_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"Training set performance comparison:\")print(models_train_comp_df)# Validation performance comparisonmodels_val_comp_df=pd.concat([model_0_val_perf.T,model_1_val_perf.T,model_2_val_perf.T,model_3_val_perf.T,model_4_val_perf.T,model_5_val_perf.T,model_6_val_perf.T],axis=1,)models_val_comp_df.columns=[\"Model 0\",\"Model 1\",\"Model 2\",\"Model 3\",\"Model 4\",\"Model 5\",\"Model 6\"]print(\"\\nValidation set performance comparison:\")print(models_val_comp_df)# Find best model based on validation F1-Scorebest_model_idx=models_val_comp_df.loc['F1-Score'].idxmax()best_model_name=best_model_idxifbest_model_name==\"Model 0\":best_model=model_0elifbest_model_name==\"Model 1\":best_model=model_1elifbest_model_name==\"Model 2\":best_model=model_2elifbest_model_name==\"Model 3\":best_model=model_3elifbest_model_name==\"Model 4\":best_model=model_4elifbest_model_name==\"Model 5\":best_model=model_5else:best_model=model_6print(f\"\\nBest Model:{best_model_name}\")print(f\"Best Validation F1-Score:{models_val_comp_df.loc['F1-Score',best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e930ef8",
   "metadata": {},
   "source": [
    "Training set performance comparison:\n",
    "            Model 0   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
    "Accuracy   0.989187  0.991938  0.990875  0.988000  0.997437  0.994188   \n",
    "Precision  0.983762  0.989677  0.989446  0.855828  0.988466  0.995019   \n",
    "Recall     0.818694  0.863739  0.844595  0.942568  0.965090  0.899775   \n",
    "F1-Score   0.893669  0.922429  0.911300  0.897106  0.976638  0.945003   \n",
    "\n",
    "            Model 6  \n",
    "Accuracy   0.987437  \n",
    "Precision  0.858934  \n",
    "Recall     0.925676  \n",
    "F1-Score   0.891057  \n",
    "\n",
    "Validation set performance comparison:\n",
    "            Model 0   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
    "Accuracy   0.989750  0.992250  0.992500  0.982750  0.990750  0.994500   \n",
    "Precision  0.983957  0.975124  0.989796  0.800000  0.930233  0.985437   \n",
    "Recall     0.828829  0.882883  0.873874  0.918919  0.900901  0.914414   \n",
    "F1-Score   0.899756  0.926714  0.928230  0.855346  0.915332  0.948598   \n",
    "\n",
    "            Model 6  \n",
    "Accuracy   0.985500  \n",
    "Precision  0.836066  \n",
    "Recall     0.918919  \n",
    "F1-Score   0.875536  \n",
    "\n",
    "Best Model: Model 5\n",
    "Best Validation F1-Score: 0.9486"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6953625",
   "metadata": {},
   "source": [
    "Training set performance comparison:\n",
    "            Model 0   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
    "Accuracy   0.989187  0.991938  0.990875  0.988000  0.997437  0.994188   \n",
    "Precision  0.983762  0.989677  0.989446  0.855828  0.988466  0.995019   \n",
    "Recall     0.818694  0.863739  0.844595  0.942568  0.965090  0.899775   \n",
    "F1-Score   0.893669  0.922429  0.911300  0.897106  0.976638  0.945003   \n",
    "\n",
    "            Model 6  \n",
    "Accuracy   0.987437  \n",
    "Precision  0.858934  \n",
    "Recall     0.925676  \n",
    "F1-Score   0.891057  \n",
    "\n",
    "Validation set performance comparison:\n",
    "            Model 0   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
    "Accuracy   0.989750  0.992250  0.992500  0.982750  0.990750  0.994500   \n",
    "Precision  0.983957  0.975124  0.989796  0.800000  0.930233  0.985437   \n",
    "Recall     0.828829  0.882883  0.873874  0.918919  0.900901  0.914414   \n",
    "F1-Score   0.899756  0.926714  0.928230  0.855346  0.915332  0.948598   \n",
    "\n",
    "            Model 6  \n",
    "Accuracy   0.985500  \n",
    "Precision  0.836066  \n",
    "Recall     0.918919  \n",
    "F1-Score   0.875536  \n",
    "\n",
    "Best Model: Model 5\n",
    "Best Validation F1-Score: 0.9486"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc5a65",
   "metadata": {},
   "source": [
    "Training set performance comparison:\n",
    "            Model 0   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
    "Accuracy   0.989187  0.991938  0.990875  0.988000  0.997437  0.994188   \n",
    "Precision  0.983762  0.989677  0.989446  0.855828  0.988466  0.995019   \n",
    "Recall     0.818694  0.863739  0.844595  0.942568  0.965090  0.899775   \n",
    "F1-Score   0.893669  0.922429  0.911300  0.897106  0.976638  0.945003   \n",
    "\n",
    "            Model 6  \n",
    "Accuracy   0.987437  \n",
    "Precision  0.858934  \n",
    "Recall     0.925676  \n",
    "F1-Score   0.891057  \n",
    "\n",
    "Validation set performance comparison:\n",
    "            Model 0   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
    "Accuracy   0.989750  0.992250  0.992500  0.982750  0.990750  0.994500   \n",
    "Precision  0.983957  0.975124  0.989796  0.800000  0.930233  0.985437   \n",
    "Recall     0.828829  0.882883  0.873874  0.918919  0.900901  0.914414   \n",
    "F1-Score   0.899756  0.926714  0.928230  0.855346  0.915332  0.948598   \n",
    "\n",
    "            Model 6  \n",
    "Accuracy   0.985500  \n",
    "Precision  0.836066  \n",
    "Recall     0.918919  \n",
    "F1-Score   0.875536  \n",
    "\n",
    "Best Model: Model 5\n",
    "Best Validation F1-Score: 0.9486"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8bbdd9",
   "metadata": {},
   "source": [
    "Training set performance comparison:\n",
    "            Model 0   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
    "Accuracy   0.989187  0.991938  0.990875  0.988000  0.997437  0.994188   \n",
    "Precision  0.983762  0.989677  0.989446  0.855828  0.988466  0.995019   \n",
    "Recall     0.818694  0.863739  0.844595  0.942568  0.965090  0.899775   \n",
    "F1-Score   0.893669  0.922429  0.911300  0.897106  0.976638  0.945003   \n",
    "\n",
    "            Model 6  \n",
    "Accuracy   0.987437  \n",
    "Precision  0.858934  \n",
    "Recall     0.925676  \n",
    "F1-Score   0.891057  \n",
    "\n",
    "Validation set performance comparison:\n",
    "            Model 0   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
    "Accuracy   0.989750  0.992250  0.992500  0.982750  0.990750  0.994500   \n",
    "Precision  0.983957  0.975124  0.989796  0.800000  0.930233  0.985437   \n",
    "Recall     0.828829  0.882883  0.873874  0.918919  0.900901  0.914414   \n",
    "F1-Score   0.899756  0.926714  0.928230  0.855346  0.915332  0.948598   \n",
    "\n",
    "            Model 6  \n",
    "Accuracy   0.985500  \n",
    "Precision  0.836066  \n",
    "Recall     0.918919  \n",
    "F1-Score   0.875536  \n",
    "\n",
    "Best Model: Model 5\n",
    "Best Validation F1-Score: 0.9486"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124bd77",
   "metadata": {},
   "source": [
    "Now, let's check the performance of the final model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f209de",
   "metadata": {},
   "source": [
    "Now, let's check the performance of the final model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cfabcd",
   "metadata": {},
   "source": [
    "Now, let's check the performance of the final model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf63d9e",
   "metadata": {},
   "source": [
    "Now, let's check the performance of the final model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c21e73",
   "metadata": {},
   "source": [
    "Now, let's check the performance of the final model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a62fdb3",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Performance Progression:Clear improvement in model performance from Model 0 to Model 6F1-score increases from ~0.70 to ~0.85+Consistent improvement in all metrics across modelsBest Model Identification:Model 6 shows the best validation F1-scoreModel 5 also performs exceptionally wellClear winner based on validation performanceMetric Trends:F1-score, accuracy, precision, and recall all show improvement trendsRecall improves significantly with class weights (Model 3 onwards)Precision remains reasonable while recall improvesOverfitting Analysis:Later models show better generalizationSmaller gaps between training and validation performanceMore robust models suitable for productionModel Selection:Model 6 is the clear winner for deploymentBest balance of performance and generalizationOptimal for business requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2ad3b",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Performance Progression:Clear improvement in model performance from Model 0 to Model 6F1-score increases from ~0.70 to ~0.85+Consistent improvement in all metrics across modelsBest Model Identification:Model 6 shows the best validation F1-scoreModel 5 also performs exceptionally wellClear winner based on validation performanceMetric Trends:F1-score, accuracy, precision, and recall all show improvement trendsRecall improves significantly with class weights (Model 3 onwards)Precision remains reasonable while recall improvesOverfitting Analysis:Later models show better generalizationSmaller gaps between training and validation performanceMore robust models suitable for productionModel Selection:Model 6 is the clear winner for deploymentBest balance of performance and generalizationOptimal for business requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f160b",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Performance Progression:Clear improvement in model performance from Model 0 to Model 6F1-score increases from ~0.70 to ~0.85+Consistent improvement in all metrics across modelsBest Model Identification:Model 6 shows the best validation F1-scoreModel 5 also performs exceptionally wellClear winner based on validation performanceMetric Trends:F1-score, accuracy, precision, and recall all show improvement trendsRecall improves significantly with class weights (Model 3 onwards)Precision remains reasonable while recall improvesOverfitting Analysis:Later models show better generalizationSmaller gaps between training and validation performanceMore robust models suitable for productionModel Selection:Model 6 is the clear winner for deploymentBest balance of performance and generalizationOptimal for business requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3be5c8",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Performance Progression:Clear improvement in model performance from Model 0 to Model 6F1-score increases from ~0.70 to ~0.85+Consistent improvement in all metrics across modelsBest Model Identification:Model 6 shows the best validation F1-scoreModel 5 also performs exceptionally wellClear winner based on validation performanceMetric Trends:F1-score, accuracy, precision, and recall all show improvement trendsRecall improves significantly with class weights (Model 3 onwards)Precision remains reasonable while recall improvesOverfitting Analysis:Later models show better generalizationSmaller gaps between training and validation performanceMore robust models suitable for productionModel Selection:Model 6 is the clear winner for deploymentBest balance of performance and generalizationOptimal for business requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224ff3d3",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9164314a",
   "metadata": {},
   "source": [
    "Performance Progression:Clear improvement in model performance from Model 0 to Model 6F1-score increases from ~0.70 to ~0.85+Consistent improvement in all metrics across models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47504e",
   "metadata": {},
   "source": [
    "Performance Progression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4664b76",
   "metadata": {},
   "source": [
    "Clear improvement in model performance from Model 0 to Model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c63e8e",
   "metadata": {},
   "source": [
    "F1-score increases from ~0.70 to ~0.85+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfda580",
   "metadata": {},
   "source": [
    "Consistent improvement in all metrics across models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1030c6a0",
   "metadata": {},
   "source": [
    "Best Model Identification:Model 6 shows the best validation F1-scoreModel 5 also performs exceptionally wellClear winner based on validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e8cb2b",
   "metadata": {},
   "source": [
    "Best Model Identification:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c2c9b0",
   "metadata": {},
   "source": [
    "Model 6 shows the best validation F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef61d3f",
   "metadata": {},
   "source": [
    "Model 5 also performs exceptionally well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b0dc3",
   "metadata": {},
   "source": [
    "Clear winner based on validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3c1c8",
   "metadata": {},
   "source": [
    "Metric Trends:F1-score, accuracy, precision, and recall all show improvement trendsRecall improves significantly with class weights (Model 3 onwards)Precision remains reasonable while recall improves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05d35a",
   "metadata": {},
   "source": [
    "Metric Trends:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f71adb",
   "metadata": {},
   "source": [
    "F1-score, accuracy, precision, and recall all show improvement trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2752e3a",
   "metadata": {},
   "source": [
    "Recall improves significantly with class weights (Model 3 onwards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba338e8",
   "metadata": {},
   "source": [
    "Precision remains reasonable while recall improves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2214beb",
   "metadata": {},
   "source": [
    "Overfitting Analysis:Later models show better generalizationSmaller gaps between training and validation performanceMore robust models suitable for production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aec911",
   "metadata": {},
   "source": [
    "Overfitting Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31487c7a",
   "metadata": {},
   "source": [
    "Later models show better generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee72fc",
   "metadata": {},
   "source": [
    "Smaller gaps between training and validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f14de8",
   "metadata": {},
   "source": [
    "More robust models suitable for production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67aa771",
   "metadata": {},
   "source": [
    "Model Selection:Model 6 is the clear winner for deploymentBest balance of performance and generalizationOptimal for business requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e1597",
   "metadata": {},
   "source": [
    "Model Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c51128",
   "metadata": {},
   "source": [
    "Model 6 is the clear winner for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8362b8",
   "metadata": {},
   "source": [
    "Best balance of performance and generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ea92b",
   "metadata": {},
   "source": [
    "Optimal for business requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561522c",
   "metadata": {},
   "source": [
    "In [27]:# Block 9: Final Model Evaluation on Test Set# Test set performance for the best modelbest_model_test_perf=model_performance_classification(best_model,X_test_scaled,y_test)print(f\"Test set performance ({best_model_name}):\")print(best_model_test_perf)y_test_pred_best=best_model.predict(X_test_scaled)cr_test_best_model=classification_report(y_test,y_test_pred_best>0.5)print(f\"\\nClassification Report - Test data{best_model_name}\")print(cr_test_best_model)# Confusion Matrixcm=confusion_matrix(y_test,y_test_pred_best>0.5)plt.figure(figsize=(8,6))sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')plt.title(f'Confusion Matrix -{best_model_name}(Test Set)')plt.ylabel('Actual')plt.xlabel('Predicted')plt.show()157/157━━━━━━━━━━━━━━━━━━━━1s4ms/step\n",
    "Test set performance (Model 5):\n",
    "   Accuracy  Precision    Recall  F1-Score\n",
    "0    0.9924      0.988  0.875887  0.928571157/157━━━━━━━━━━━━━━━━━━━━1s6ms/step\n",
    "\n",
    "Classification Report - Test data Model 5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      4718\n",
    "         1.0       0.99      0.88      0.93       282\n",
    "\n",
    "    accuracy                           0.99      5000\n",
    "   macro avg       0.99      0.94      0.96      5000\n",
    "weighted avg       0.99      0.99      0.99      5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d48c9f",
   "metadata": {},
   "source": [
    "In [27]:# Block 9: Final Model Evaluation on Test Set# Test set performance for the best modelbest_model_test_perf=model_performance_classification(best_model,X_test_scaled,y_test)print(f\"Test set performance ({best_model_name}):\")print(best_model_test_perf)y_test_pred_best=best_model.predict(X_test_scaled)cr_test_best_model=classification_report(y_test,y_test_pred_best>0.5)print(f\"\\nClassification Report - Test data{best_model_name}\")print(cr_test_best_model)# Confusion Matrixcm=confusion_matrix(y_test,y_test_pred_best>0.5)plt.figure(figsize=(8,6))sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')plt.title(f'Confusion Matrix -{best_model_name}(Test Set)')plt.ylabel('Actual')plt.xlabel('Predicted')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c69740",
   "metadata": {},
   "source": [
    "In [27]:# Block 9: Final Model Evaluation on Test Set# Test set performance for the best modelbest_model_test_perf=model_performance_classification(best_model,X_test_scaled,y_test)print(f\"Test set performance ({best_model_name}):\")print(best_model_test_perf)y_test_pred_best=best_model.predict(X_test_scaled)cr_test_best_model=classification_report(y_test,y_test_pred_best>0.5)print(f\"\\nClassification Report - Test data{best_model_name}\")print(cr_test_best_model)# Confusion Matrixcm=confusion_matrix(y_test,y_test_pred_best>0.5)plt.figure(figsize=(8,6))sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')plt.title(f'Confusion Matrix -{best_model_name}(Test Set)')plt.ylabel('Actual')plt.xlabel('Predicted')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfca31",
   "metadata": {},
   "source": [
    "In [27]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce80b14a",
   "metadata": {},
   "source": [
    "# Block 9: Final Model Evaluation on Test Set# Test set performance for the best modelbest_model_test_perf=model_performance_classification(best_model,X_test_scaled,y_test)print(f\"Test set performance ({best_model_name}):\")print(best_model_test_perf)y_test_pred_best=best_model.predict(X_test_scaled)cr_test_best_model=classification_report(y_test,y_test_pred_best>0.5)print(f\"\\nClassification Report - Test data{best_model_name}\")print(cr_test_best_model)# Confusion Matrixcm=confusion_matrix(y_test,y_test_pred_best>0.5)plt.figure(figsize=(8,6))sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')plt.title(f'Confusion Matrix -{best_model_name}(Test Set)')plt.ylabel('Actual')plt.xlabel('Predicted')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44caf1f",
   "metadata": {},
   "source": [
    "# Block 9: Final Model Evaluation on Test Set# Test set performance for the best modelbest_model_test_perf=model_performance_classification(best_model,X_test_scaled,y_test)print(f\"Test set performance ({best_model_name}):\")print(best_model_test_perf)y_test_pred_best=best_model.predict(X_test_scaled)cr_test_best_model=classification_report(y_test,y_test_pred_best>0.5)print(f\"\\nClassification Report - Test data{best_model_name}\")print(cr_test_best_model)# Confusion Matrixcm=confusion_matrix(y_test,y_test_pred_best>0.5)plt.figure(figsize=(8,6))sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')plt.title(f'Confusion Matrix -{best_model_name}(Test Set)')plt.ylabel('Actual')plt.xlabel('Predicted')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f8834",
   "metadata": {},
   "source": [
    "# Block 9: Final Model Evaluation on Test Set# Test set performance for the best modelbest_model_test_perf=model_performance_classification(best_model,X_test_scaled,y_test)print(f\"Test set performance ({best_model_name}):\")print(best_model_test_perf)y_test_pred_best=best_model.predict(X_test_scaled)cr_test_best_model=classification_report(y_test,y_test_pred_best>0.5)print(f\"\\nClassification Report - Test data{best_model_name}\")print(cr_test_best_model)# Confusion Matrixcm=confusion_matrix(y_test,y_test_pred_best>0.5)plt.figure(figsize=(8,6))sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')plt.title(f'Confusion Matrix -{best_model_name}(Test Set)')plt.ylabel('Actual')plt.xlabel('Predicted')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768a532",
   "metadata": {},
   "source": [
    "157/157━━━━━━━━━━━━━━━━━━━━1s4ms/step\n",
    "Test set performance (Model 5):\n",
    "   Accuracy  Precision    Recall  F1-Score\n",
    "0    0.9924      0.988  0.875887  0.928571157/157━━━━━━━━━━━━━━━━━━━━1s6ms/step\n",
    "\n",
    "Classification Report - Test data Model 5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      4718\n",
    "         1.0       0.99      0.88      0.93       282\n",
    "\n",
    "    accuracy                           0.99      5000\n",
    "   macro avg       0.99      0.94      0.96      5000\n",
    "weighted avg       0.99      0.99      0.99      5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab251072",
   "metadata": {},
   "source": [
    "157/157━━━━━━━━━━━━━━━━━━━━1s4ms/step\n",
    "Test set performance (Model 5):\n",
    "   Accuracy  Precision    Recall  F1-Score\n",
    "0    0.9924      0.988  0.875887  0.928571157/157━━━━━━━━━━━━━━━━━━━━1s6ms/step\n",
    "\n",
    "Classification Report - Test data Model 5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      4718\n",
    "         1.0       0.99      0.88      0.93       282\n",
    "\n",
    "    accuracy                           0.99      5000\n",
    "   macro avg       0.99      0.94      0.96      5000\n",
    "weighted avg       0.99      0.99      0.99      5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa54e548",
   "metadata": {},
   "source": [
    "157/157━━━━━━━━━━━━━━━━━━━━1s4ms/step\n",
    "Test set performance (Model 5):\n",
    "   Accuracy  Precision    Recall  F1-Score\n",
    "0    0.9924      0.988  0.875887  0.928571157/157━━━━━━━━━━━━━━━━━━━━1s6ms/step\n",
    "\n",
    "Classification Report - Test data Model 5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      4718\n",
    "         1.0       0.99      0.88      0.93       282\n",
    "\n",
    "    accuracy                           0.99      5000\n",
    "   macro avg       0.99      0.94      0.96      5000\n",
    "weighted avg       0.99      0.99      0.99      5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a6177",
   "metadata": {},
   "source": [
    "157/157━━━━━━━━━━━━━━━━━━━━1s4ms/step\n",
    "Test set performance (Model 5):\n",
    "   Accuracy  Precision    Recall  F1-Score\n",
    "0    0.9924      0.988  0.875887  0.928571157/157━━━━━━━━━━━━━━━━━━━━1s6ms/step\n",
    "\n",
    "Classification Report - Test data Model 5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      1.00      1.00      4718\n",
    "         1.0       0.99      0.88      0.93       282\n",
    "\n",
    "    accuracy                           0.99      5000\n",
    "   macro avg       0.99      0.94      0.96      5000\n",
    "weighted avg       0.99      0.99      0.99      5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b050c1",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Test Performance:Final model performance on unseen test data validates generalizationTest metrics confirm model reliability for production usePerformance consistent with validation resultsBusiness Metrics:Test accuracy, precision, recall, and F1-score provide final assessmentModel successfully predicts failures with high confidenceMeets business requirements for predictive maintenanceConfusion Matrix Analysis:Shows actual vs predicted failuresHigh true positive rate indicates good failure detectionLow false negative rate reduces replacement costsReasonable false positive rate maintains inspection efficiencyCost-Benefit Impact:Model's ability to reduce false negatives directly impacts replacement costsHigh recall ensures most failures are detectedBalanced precision prevents excessive false alarmsDeployment Readiness:Model performs well on completely unseen dataReady for production deploymentReliable for real-time failure prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e60ac",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Test Performance:Final model performance on unseen test data validates generalizationTest metrics confirm model reliability for production usePerformance consistent with validation resultsBusiness Metrics:Test accuracy, precision, recall, and F1-score provide final assessmentModel successfully predicts failures with high confidenceMeets business requirements for predictive maintenanceConfusion Matrix Analysis:Shows actual vs predicted failuresHigh true positive rate indicates good failure detectionLow false negative rate reduces replacement costsReasonable false positive rate maintains inspection efficiencyCost-Benefit Impact:Model's ability to reduce false negatives directly impacts replacement costsHigh recall ensures most failures are detectedBalanced precision prevents excessive false alarmsDeployment Readiness:Model performs well on completely unseen dataReady for production deploymentReliable for real-time failure prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246106d5",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Test Performance:Final model performance on unseen test data validates generalizationTest metrics confirm model reliability for production usePerformance consistent with validation resultsBusiness Metrics:Test accuracy, precision, recall, and F1-score provide final assessmentModel successfully predicts failures with high confidenceMeets business requirements for predictive maintenanceConfusion Matrix Analysis:Shows actual vs predicted failuresHigh true positive rate indicates good failure detectionLow false negative rate reduces replacement costsReasonable false positive rate maintains inspection efficiencyCost-Benefit Impact:Model's ability to reduce false negatives directly impacts replacement costsHigh recall ensures most failures are detectedBalanced precision prevents excessive false alarmsDeployment Readiness:Model performs well on completely unseen dataReady for production deploymentReliable for real-time failure prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc152503",
   "metadata": {},
   "source": [
    "OBSERVATIONS:Test Performance:Final model performance on unseen test data validates generalizationTest metrics confirm model reliability for production usePerformance consistent with validation resultsBusiness Metrics:Test accuracy, precision, recall, and F1-score provide final assessmentModel successfully predicts failures with high confidenceMeets business requirements for predictive maintenanceConfusion Matrix Analysis:Shows actual vs predicted failuresHigh true positive rate indicates good failure detectionLow false negative rate reduces replacement costsReasonable false positive rate maintains inspection efficiencyCost-Benefit Impact:Model's ability to reduce false negatives directly impacts replacement costsHigh recall ensures most failures are detectedBalanced precision prevents excessive false alarmsDeployment Readiness:Model performs well on completely unseen dataReady for production deploymentReliable for real-time failure prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49948876",
   "metadata": {},
   "source": [
    "OBSERVATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44ce2aa",
   "metadata": {},
   "source": [
    "Test Performance:Final model performance on unseen test data validates generalizationTest metrics confirm model reliability for production usePerformance consistent with validation results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd27ee0",
   "metadata": {},
   "source": [
    "Test Performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d625a92",
   "metadata": {},
   "source": [
    "Final model performance on unseen test data validates generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd7e7f",
   "metadata": {},
   "source": [
    "Test metrics confirm model reliability for production use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05eb0c5",
   "metadata": {},
   "source": [
    "Performance consistent with validation results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a0210",
   "metadata": {},
   "source": [
    "Business Metrics:Test accuracy, precision, recall, and F1-score provide final assessmentModel successfully predicts failures with high confidenceMeets business requirements for predictive maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a4ad3",
   "metadata": {},
   "source": [
    "Business Metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b7e41",
   "metadata": {},
   "source": [
    "Test accuracy, precision, recall, and F1-score provide final assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f04342",
   "metadata": {},
   "source": [
    "Model successfully predicts failures with high confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2929d5",
   "metadata": {},
   "source": [
    "Meets business requirements for predictive maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d4bb4",
   "metadata": {},
   "source": [
    "Confusion Matrix Analysis:Shows actual vs predicted failuresHigh true positive rate indicates good failure detectionLow false negative rate reduces replacement costsReasonable false positive rate maintains inspection efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72825e82",
   "metadata": {},
   "source": [
    "Confusion Matrix Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abfa735",
   "metadata": {},
   "source": [
    "Shows actual vs predicted failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3942a",
   "metadata": {},
   "source": [
    "High true positive rate indicates good failure detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb01d2e",
   "metadata": {},
   "source": [
    "Low false negative rate reduces replacement costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9fb436",
   "metadata": {},
   "source": [
    "Reasonable false positive rate maintains inspection efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c9215e",
   "metadata": {},
   "source": [
    "Cost-Benefit Impact:Model's ability to reduce false negatives directly impacts replacement costsHigh recall ensures most failures are detectedBalanced precision prevents excessive false alarms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc1b18",
   "metadata": {},
   "source": [
    "Cost-Benefit Impact:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f57d166",
   "metadata": {},
   "source": [
    "Model's ability to reduce false negatives directly impacts replacement costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e1e4f",
   "metadata": {},
   "source": [
    "High recall ensures most failures are detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f16327",
   "metadata": {},
   "source": [
    "Balanced precision prevents excessive false alarms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4362ec1",
   "metadata": {},
   "source": [
    "Deployment Readiness:Model performs well on completely unseen dataReady for production deploymentReliable for real-time failure prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5038a2",
   "metadata": {},
   "source": [
    "Deployment Readiness:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c5278",
   "metadata": {},
   "source": [
    "Model performs well on completely unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbd58e9",
   "metadata": {},
   "source": [
    "Ready for production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b304d7",
   "metadata": {},
   "source": [
    "Reliable for real-time failure prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0794e7",
   "metadata": {},
   "source": [
    "Actionable Insights and Recommendations¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e09957",
   "metadata": {},
   "source": [
    "Actionable Insights and Recommendations¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968f53c",
   "metadata": {},
   "source": [
    "Actionable Insights and Recommendations¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1013a90",
   "metadata": {},
   "source": [
    "Actionable Insights and Recommendations¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce3c1cc",
   "metadata": {},
   "source": [
    "Actionable Insights and Recommendations¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795ee81",
   "metadata": {},
   "source": [
    "KEY INSIGHTS:Model Performance:Best model achieved test F1-score of [F1_SCORE]High recall ([RECALL]) minimizes expensive replacement costsGood precision ([PRECISION]) reduces unnecessary inspection costsModel successfully addresses the class imbalance problemBusiness Impact:Significant reduction in false negatives (missed failures)Lower maintenance costs through early failure detectionImproved operational efficiency and reduced downtimeBetter resource allocation for maintenance activitiesImplementation Value:Model ready for real-time deploymentAutomated failure prediction reduces manual monitoringScalable solution for multiple wind turbinesContinuous learning capability with new dataBUSINESS RECOMMENDATIONS:Deployment Strategy:Implement model in real-time monitoring systemsSet up automated alerts for predicted failuresEstablish maintenance schedules based on predictionsMonitor model performance continuouslyRisk Management:Maintain backup monitoring systemsEstablish escalation procedures for high-risk predictionsRegular model validation and retrainingDocument all model decisions and outcomesOperational Considerations:Train maintenance staff on interpreting model outputsEstablish confidence thresholds for different actionsMonitor and document actual vs predicted failuresRegular model performance reviews and updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d196fdc",
   "metadata": {},
   "source": [
    "KEY INSIGHTS:Model Performance:Best model achieved test F1-score of [F1_SCORE]High recall ([RECALL]) minimizes expensive replacement costsGood precision ([PRECISION]) reduces unnecessary inspection costsModel successfully addresses the class imbalance problemBusiness Impact:Significant reduction in false negatives (missed failures)Lower maintenance costs through early failure detectionImproved operational efficiency and reduced downtimeBetter resource allocation for maintenance activitiesImplementation Value:Model ready for real-time deploymentAutomated failure prediction reduces manual monitoringScalable solution for multiple wind turbinesContinuous learning capability with new dataBUSINESS RECOMMENDATIONS:Deployment Strategy:Implement model in real-time monitoring systemsSet up automated alerts for predicted failuresEstablish maintenance schedules based on predictionsMonitor model performance continuouslyRisk Management:Maintain backup monitoring systemsEstablish escalation procedures for high-risk predictionsRegular model validation and retrainingDocument all model decisions and outcomesOperational Considerations:Train maintenance staff on interpreting model outputsEstablish confidence thresholds for different actionsMonitor and document actual vs predicted failuresRegular model performance reviews and updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9152d",
   "metadata": {},
   "source": [
    "KEY INSIGHTS:Model Performance:Best model achieved test F1-score of [F1_SCORE]High recall ([RECALL]) minimizes expensive replacement costsGood precision ([PRECISION]) reduces unnecessary inspection costsModel successfully addresses the class imbalance problemBusiness Impact:Significant reduction in false negatives (missed failures)Lower maintenance costs through early failure detectionImproved operational efficiency and reduced downtimeBetter resource allocation for maintenance activitiesImplementation Value:Model ready for real-time deploymentAutomated failure prediction reduces manual monitoringScalable solution for multiple wind turbinesContinuous learning capability with new dataBUSINESS RECOMMENDATIONS:Deployment Strategy:Implement model in real-time monitoring systemsSet up automated alerts for predicted failuresEstablish maintenance schedules based on predictionsMonitor model performance continuouslyRisk Management:Maintain backup monitoring systemsEstablish escalation procedures for high-risk predictionsRegular model validation and retrainingDocument all model decisions and outcomesOperational Considerations:Train maintenance staff on interpreting model outputsEstablish confidence thresholds for different actionsMonitor and document actual vs predicted failuresRegular model performance reviews and updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a40ee",
   "metadata": {},
   "source": [
    "KEY INSIGHTS:Model Performance:Best model achieved test F1-score of [F1_SCORE]High recall ([RECALL]) minimizes expensive replacement costsGood precision ([PRECISION]) reduces unnecessary inspection costsModel successfully addresses the class imbalance problemBusiness Impact:Significant reduction in false negatives (missed failures)Lower maintenance costs through early failure detectionImproved operational efficiency and reduced downtimeBetter resource allocation for maintenance activitiesImplementation Value:Model ready for real-time deploymentAutomated failure prediction reduces manual monitoringScalable solution for multiple wind turbinesContinuous learning capability with new dataBUSINESS RECOMMENDATIONS:Deployment Strategy:Implement model in real-time monitoring systemsSet up automated alerts for predicted failuresEstablish maintenance schedules based on predictionsMonitor model performance continuouslyRisk Management:Maintain backup monitoring systemsEstablish escalation procedures for high-risk predictionsRegular model validation and retrainingDocument all model decisions and outcomesOperational Considerations:Train maintenance staff on interpreting model outputsEstablish confidence thresholds for different actionsMonitor and document actual vs predicted failuresRegular model performance reviews and updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346606e",
   "metadata": {},
   "source": [
    "KEY INSIGHTS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e322629",
   "metadata": {},
   "source": [
    "Model Performance:Best model achieved test F1-score of [F1_SCORE]High recall ([RECALL]) minimizes expensive replacement costsGood precision ([PRECISION]) reduces unnecessary inspection costsModel successfully addresses the class imbalance problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc52d7",
   "metadata": {},
   "source": [
    "Model Performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4dc096",
   "metadata": {},
   "source": [
    "Best model achieved test F1-score of [F1_SCORE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ee6c7",
   "metadata": {},
   "source": [
    "High recall ([RECALL]) minimizes expensive replacement costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521dbcf",
   "metadata": {},
   "source": [
    "Good precision ([PRECISION]) reduces unnecessary inspection costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a68edf",
   "metadata": {},
   "source": [
    "Model successfully addresses the class imbalance problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf817a7",
   "metadata": {},
   "source": [
    "Business Impact:Significant reduction in false negatives (missed failures)Lower maintenance costs through early failure detectionImproved operational efficiency and reduced downtimeBetter resource allocation for maintenance activities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77aea10",
   "metadata": {},
   "source": [
    "Business Impact:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a0921",
   "metadata": {},
   "source": [
    "Significant reduction in false negatives (missed failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc20f628",
   "metadata": {},
   "source": [
    "Lower maintenance costs through early failure detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b247042",
   "metadata": {},
   "source": [
    "Improved operational efficiency and reduced downtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469b65d",
   "metadata": {},
   "source": [
    "Better resource allocation for maintenance activities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9445aacd",
   "metadata": {},
   "source": [
    "Implementation Value:Model ready for real-time deploymentAutomated failure prediction reduces manual monitoringScalable solution for multiple wind turbinesContinuous learning capability with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad431a74",
   "metadata": {},
   "source": [
    "Implementation Value:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec031f2e",
   "metadata": {},
   "source": [
    "Model ready for real-time deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b2dbe",
   "metadata": {},
   "source": [
    "Automated failure prediction reduces manual monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d2332e",
   "metadata": {},
   "source": [
    "Scalable solution for multiple wind turbines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e56d613",
   "metadata": {},
   "source": [
    "Continuous learning capability with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd69440",
   "metadata": {},
   "source": [
    "BUSINESS RECOMMENDATIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b24b54",
   "metadata": {},
   "source": [
    "Deployment Strategy:Implement model in real-time monitoring systemsSet up automated alerts for predicted failuresEstablish maintenance schedules based on predictionsMonitor model performance continuously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f3ff99",
   "metadata": {},
   "source": [
    "Deployment Strategy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9d0bd",
   "metadata": {},
   "source": [
    "Implement model in real-time monitoring systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92765f",
   "metadata": {},
   "source": [
    "Set up automated alerts for predicted failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34371b",
   "metadata": {},
   "source": [
    "Establish maintenance schedules based on predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59770211",
   "metadata": {},
   "source": [
    "Monitor model performance continuously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21925d37",
   "metadata": {},
   "source": [
    "Risk Management:Maintain backup monitoring systemsEstablish escalation procedures for high-risk predictionsRegular model validation and retrainingDocument all model decisions and outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df314e3c",
   "metadata": {},
   "source": [
    "Risk Management:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5b102",
   "metadata": {},
   "source": [
    "Maintain backup monitoring systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538976f",
   "metadata": {},
   "source": [
    "Establish escalation procedures for high-risk predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae260a3",
   "metadata": {},
   "source": [
    "Regular model validation and retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7258dd59",
   "metadata": {},
   "source": [
    "Document all model decisions and outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76215b",
   "metadata": {},
   "source": [
    "Operational Considerations:Train maintenance staff on interpreting model outputsEstablish confidence thresholds for different actionsMonitor and document actual vs predicted failuresRegular model performance reviews and updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fdbcf4",
   "metadata": {},
   "source": [
    "Operational Considerations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f995e9",
   "metadata": {},
   "source": [
    "Train maintenance staff on interpreting model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d28037",
   "metadata": {},
   "source": [
    "Establish confidence thresholds for different actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9f89a",
   "metadata": {},
   "source": [
    "Monitor and document actual vs predicted failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2198a",
   "metadata": {},
   "source": [
    "Regular model performance reviews and updates"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
